
R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> rm(list=ls())
> my.seed=10
> set.seed(my.seed)
> 
> pdf("model10_sim1.tapered.pdf")
> 
> library(ergm)
Loading required package: network

‘network’ 1.18.0 (2022-10-05), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information


‘ergm’ 4.3-6983 (2022-08-20), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(doRNG)
Loading required package: foreach
Loading required package: rngtools
> library(mfergm)
> library(optimx)     # mfergm likelihood
> library(R.utils)    # set time on ergm
Loading required package: R.oo
Loading required package: R.methodsS3
R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.
R.oo v1.25.0 (2022-06-12 02:20:02 UTC) successfully loaded. See ?R.oo for help.

Attaching package: ‘R.oo’

The following object is masked from ‘package:R.methodsS3’:

    throw

The following objects are masked from ‘package:methods’:

    getClasses, getMethods

The following objects are masked from ‘package:base’:

    attach, detach, load, save

R.utils v2.12.0 (2022-06-28 03:20:05 UTC) successfully loaded. See ?R.utils for help.

Attaching package: ‘R.utils’

The following object is masked from ‘package:utils’:

    timestamp

The following objects are masked from ‘package:base’:

    cat, commandArgs, getOption, isOpen, nullfile, parse, warnings

> library(doParallel) # parallel loops using 'foreach'
Loading required package: iterators
Loading required package: parallel
> 
> #####################################################################
> #                                                                   #
> #     Create High Transitivity ERGM Params (using ERGM fitting)     #
> #                                                                   #
> #####################################################################
> 
> nsims       =  200                               # number of networks simulated
> n           =  100                               # number of nodes
> mv_1 <- c(400.31, 349.88, 3254.42,     126.28)   # mean-value parameters standard model
> mv_1 <- c(393.0512, 341.0188, 3092.0576, 117.4754) # Long-run estimate
> theta       =  c(-2,1,1,1) * c(2,2,1/n,1/n)      # true parameters for model 2
> ##################
> #                #
> #     Set-up     #
> #                #
> ##################
> 
> g <- initialize.network(theta, n, directed = FALSE)
> x <- rbinom(n, 1, 0.5) # attributes
> set.vertex.attribute(g, # the name of the network object
+                      "x", # the name we want to reference the variable by in that object
+                      x # the value we are giving that variable
+ ) 
> 
> formula <- g ~ edges + nodematch("x") + kstar(2) + triangles
> names(mv_1) <- names(summary(formula))
> 
> load("sim10.RData")
> theta
[1] -4.00  2.00  0.01  0.01
> set.seed(my.seed)
> registerDoParallel(10)
> a = foreach(i = 1:10) %dorng% {
+  simulate(sim ~ edges + nodematch("x") + kstar(2) + triangles, 
+                   nsim = nsims/10,
+                   coef = theta,
+ 		  control=control.simulate.formula(MCMC.burnin=1000000, MCMC.interval=1000000)
+                               )
+ }
> sim <- a[[1]][[nsims/10]]
> g_sim <- NULL
> for(i in 1:10){
+   g_sim <- c(g_sim, a[[i]])
+ }
> rm(a)
> #save(sim, file="sim10.RData")
> 
> # Extract summary stats from 'g_sim'
> g_sim_stats = foreach(i = 1:(nsims), .combine = rbind) %dorng% {
+  as.vector(summary_formula(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles))
+ }
> 
> a = foreach(i = 2:10, .combine = rbind) %dorng% {
+  simulate(sim ~ edges + nodematch("x") + kstar(2) + triangles, 
+                   nsim = nsims,
+                   coef = theta,
+                   output = "stats",
+ 		  control=control.simulate.formula(MCMC.burnin=1000000, MCMC.interval=100000)
+                               )
+ }
> g_sim_stats <- rbind(g_sim_stats, a)
> rm(a)
> 
> pairs(g_sim_stats)
> dev.off()
null device 
          1 
> 
> mv_s <- apply(g_sim_stats,2,mean)
> mv_s
      edges nodematch.x      kstar2    triangle 
   392.5495    340.6510   3083.5500    117.0405 
> #names(mv_s) <- names(fit$tapering.coefficients)
> names(mv_s) <- c("edges", "x", "kstar2", "triangles")
> cbind(mv_1, mv_s)
                 mv_1      mv_s
edges        393.0512  392.5495
nodematch.x  341.0188  340.6510
kstar2      3092.0576 3083.5500
triangle     117.4754  117.0405
> 
> mv_s <- mv_1
> 
> t.test(g_sim_stats[,2], mu=mv_1[2])

	One Sample t-test

data:  g_sim_stats[, 2]
t = -0.87075, df = 1999, p-value = 0.384
alternative hypothesis: true mean is not equal to 341.0188
95 percent confidence interval:
 339.8226 341.4794
sample estimates:
mean of x 
  340.651 

> t.test(g_sim_stats[,3], mu=mv_1[3])

	One Sample t-test

data:  g_sim_stats[, 3]
t = -1.1596, df = 1999, p-value = 0.2464
alternative hypothesis: true mean is not equal to 3092.058
95 percent confidence interval:
 3069.161 3097.939
sample estimates:
mean of x 
  3083.55 

> t.test(g_sim_stats[,4], mu=mv_1[4])

	One Sample t-test

data:  g_sim_stats[, 4]
t = -0.89394, df = 1999, p-value = 0.3715
alternative hypothesis: true mean is not equal to 117.4754
95 percent confidence interval:
 116.0864 117.9946
sample estimates:
mean of x 
 117.0405 

> #q()
> # Initialize the parameters at MPLE
> #init_params = matrix(nrow = nsims, ncol = length(theta))
> init_params = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+   ergm(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles, 
+                estimate = "MPLE")$coefficients
+ }
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Finished MPLE.
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.

Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Finished MPLE.



Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.

Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Finished MPLE.
Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Finished MPLE.

Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.

Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Finished MPLE.
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 


Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 


Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.


Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Finished MPLE.
Finished MPLE.

Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
> 
> ##########################
> #                        #
> #     ERGM (Default)     #
> #                        #
> ##########################
> 
> ### Compute ERGM Results
> #stopImplicitCluster()
> #registerDoParallel(5)
> 
> ### Compute ERGM Results
> ergm_sim_list_tapered = foreach(i = 1:nsims) %dorng% {
+   # cat("***********************************\n")
+   # cat(paste("estimating sample" ,i, "\n"))
+   # cat("***********************************\n")
+   skip_to_next <- FALSE
+   formula <- g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = 
+     tryCatch(withTimeout(
+                           ergm(formula, eval.loglik=FALSE,
+                                control=control.ergm(init = init_params[i,], MCMC.samplesize=10000)),
+                timeout = 5*60, onTimeout = "error"),
+                error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0624.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0117.
The log-likelihood improved by 0.0239.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0220.
The log-likelihood improved by 0.1322.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0055.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0076.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.2084.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0028.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0658.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0748.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0399.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0031.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0223.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0099.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0030.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0717.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0150.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0101.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0746.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0165.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0176.
The log-likelihood improved by 0.0042.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0355.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1003.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0040.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0452.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0021.
The log-likelihood improved by 0.0120.
The log-likelihood improved by 0.0541.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0055.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0057.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0077.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0037.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0090.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0293.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0047.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0236.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0547.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0356.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2162.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0483.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0236.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0049.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0057.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0391.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0098.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0048.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0363.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0559.
The log-likelihood improved by 0.0016.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0088.
The log-likelihood improved by 0.0130.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1407.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0109.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0313.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0039.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0194.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0207.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0133.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0367.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0008.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0057.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0008.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0771.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0336.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0151.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0088.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0086.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0063.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0471.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0075.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0247.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0301.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0107.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0168.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0180.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0017.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0056.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0339.
The log-likelihood improved by 0.0542.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0123.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0339.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2117.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0019.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0092.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0376.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0725.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0086.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0519.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0134.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0043.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0074.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0041.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0069.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0124.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0062.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0012.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0515.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1259.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0015.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0055.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0107.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0151.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0371.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0113.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0108.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0865.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0021.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0202.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.2033.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0111.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0051.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.1130.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0183.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1514.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0252.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0039.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0343.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0009.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0211.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0006.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0221.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0230.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0326.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0068.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0007.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0182.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0667.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1031.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0017.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0067.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0099.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0025.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0351.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0123.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0355.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0066.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0050.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0161.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0348.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0127.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0268.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0269.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0056.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1126.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0007.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0150.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0515.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0015.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0107.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0137.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0441.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0008.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0193.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0018.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0295.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0222.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0860.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0048.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0056.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0054.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0319.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0531.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0339.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0027.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0024.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0230.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0419.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0344.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0073.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0460.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0305.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0051.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0038.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0108.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0271.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0035.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0487.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1529.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0116.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0049.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0009.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0055.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0138.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0279.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0150.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0859.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0463.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0004.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0075.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0021.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0242.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0209.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0047.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0011.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0434.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0062.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0283.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0024.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0162.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0121.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0825.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0504.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1395.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0055.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0523.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0265.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0021.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0145.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0019.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
> 
> ergm_sim_estim_tapered = matrix(0, nrow = nsims, ncol = 4)
> for(i in 1:nsims)
+ {
+   if(!is.null(ergm_sim_list_tapered[[i]]))
+   {
+     est.params <- ergm_sim_list_tapered[[i]]$coefficients
+     ergm_sim_estim_tapered[i,] <- est.params
+   }
+   else {ergm_sim_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
> 
> #### DEGENERACIES
> degen_tapered = which(!complete.cases(ergm_sim_estim_tapered))
> # 58 of em
> degen_tapered
[1] 99
> 
> if(length(degen_tapered) > 0 ){
+ #degen_list_tapered = ergm_sim_list_tapered[[]]
+ #ergm_degen_list_tapered = foreach(i = 1:length(degen_tapered)) %dorng% {
+ #  skip_to_next <- FALSE
+ #  formula <- g_sim[[degen_tapered[i]]] ~ edges + nodematch("x") + kstar(2) + triangles
+ #  ergm_sim_tapered = tryCatch(withTimeout(ergm(formula, eval.loglik=FALSE,
+ #                                        control=control.ergm(init=theta, MCMLE.confidence=0.95
+ #                                       #   # MCMC.burnin=100000,
+ #                                       #   # MCMC.interval=1000,
+ #                                       #   # MCMC.samplesize = 5000,
+ #                                          )
+ #  ), timeout = 5*60, onTimeout = "error"),
+ #  error = function(e) {skip_to_next <<- NULL})
+ #  ergm_sim_tapered
+ #}
+ #ergm_degen_list_tapered
+ 
+ ergm_degen_estim_tapered = matrix(0, nrow = length(degen_tapered), ncol = 4)
+ for(i in 1:length(degen_tapered))
+ {
+  #if(!is.null(ergm_degen_list_tapered[[i]]))
+  #{
+    # est.params <- ergm_degen_list_tapered[[i]]$coefficients
+    # ergm_degen_estim_tapered[i,] <- est.params
+    # ergm_sim_estim_tapered[degen_tapered[i],] <- est.params
+      ergm_sim_estim_tapered[degen_tapered[i],] <- init_params[degen_tapered[i],]
+  #}
+  #else {ergm_degen_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
+ }
> 
> ergm_result_tapered = apply(ergm_sim_estim_tapered, 2, mean, na.rm = T)
> ergm_result_tapered
[1] -3.896487670  1.993673711  0.003448024  0.006311561
> 
> ergm_sim_estim_tapered
            [,1]     [,2]          [,3]          [,4]
  [1,] -3.517389 1.813926 -1.004191e-02  0.0497026170
  [2,] -3.748677 1.765328  8.897948e-03  0.0716291683
  [3,] -4.380348 2.429109  2.469977e-02 -0.1716079493
  [4,] -4.067035 1.820041  2.351419e-02  0.0481869396
  [5,] -3.911665 1.862350  1.585742e-03  0.1093415709
  [6,] -3.485635 1.649886 -1.168205e-02  0.1468560857
  [7,] -4.116289 1.990918  1.516744e-02  0.0870487201
  [8,] -3.689446 2.179916 -1.965830e-02  0.1695826727
  [9,] -4.454060 2.321195  3.014337e-02 -0.1796986560
 [10,] -3.133413 2.099675 -5.601172e-02  0.0475380347
 [11,] -3.817080 1.986213 -1.490417e-03  0.0529344729
 [12,] -4.508672 1.956835  4.768819e-02 -0.0643007945
 [13,] -4.044196 1.754301  1.737545e-02  0.0620029489
 [14,] -4.062024 1.826688  2.966158e-02 -0.1364458397
 [15,] -4.419333 2.174570  2.809288e-02 -0.0522871900
 [16,] -3.237253 2.092694 -3.680763e-02 -0.0003197169
 [17,] -3.615006 1.901139 -1.907643e-03 -0.0475821649
 [18,] -3.934624 1.921815  1.519125e-02 -0.0593154449
 [19,] -3.960343 1.954419  1.003518e-02  0.0456108255
 [20,] -4.584236 2.275279  4.553412e-02 -0.2698859871
 [21,] -3.326024 1.900300 -3.639886e-02  0.1961011582
 [22,] -3.897272 1.838602 -1.028412e-03  0.1776065020
 [23,] -3.219322 1.848825 -2.760782e-02  0.0265686282
 [24,] -4.062355 2.059308  1.463516e-03  0.1077325406
 [25,] -3.697419 1.963960 -7.476897e-03  0.0421822683
 [26,] -3.941140 2.222953  6.211717e-03 -0.1484540225
 [27,] -3.548242 1.701675 -1.242624e-02  0.1832345449
 [28,] -4.235928 2.142891  1.543455e-02  0.0689015893
 [29,] -4.488950 2.219897  3.943744e-02 -0.1658330738
 [30,] -3.633702 2.084709 -1.445731e-02  0.0451186600
 [31,] -3.751583 2.192898 -1.575481e-02  0.0626770517
 [32,] -3.521244 2.001656 -1.381545e-02  0.0183805284
 [33,] -3.808346 2.170619 -1.223193e-02  0.0385307506
 [34,] -3.717076 2.103373 -7.398809e-03 -0.0933768844
 [35,] -3.317393 1.728807 -2.730387e-02  0.0848703558
 [36,] -3.782451 2.243373 -2.005836e-02 -0.0431048099
 [37,] -4.028901 1.862517  2.421279e-02 -0.0367389366
 [38,] -3.533036 1.679536 -1.408975e-02  0.1990544396
 [39,] -3.882627 1.925683  9.790304e-03  0.0201909631
 [40,] -4.047020 1.833089  1.499973e-02  0.0790027227
 [41,] -3.278912 1.747659 -2.772318e-02 -0.0615050142
 [42,] -4.148361 2.091209  1.269419e-02 -0.0288051220
 [43,] -3.753442 1.889745 -9.947617e-03  0.1413267990
 [44,] -4.173439 2.085998  2.583635e-02 -0.1833527253
 [45,] -4.501123 2.483697  1.453063e-02 -0.0036026691
 [46,] -3.083272 2.009522 -4.127864e-02 -0.0124608825
 [47,] -4.065882 1.835765  2.486852e-02 -0.1398935786
 [48,] -3.168093 2.255347 -6.849209e-02  0.0985250151
 [49,] -4.506040 2.222973  4.124508e-02 -0.1896318237
 [50,] -3.972287 1.906901 -1.563696e-03  0.1880544412
 [51,] -4.406313 2.229539  3.277578e-02 -0.1143000241
 [52,] -4.224317 1.855237  3.612788e-02 -0.1073965753
 [53,] -4.256575 2.049659  2.318341e-02 -0.0046181533
 [54,] -3.896204 1.936137  1.329840e-02 -0.0475957633
 [55,] -4.148468 2.109519  1.391877e-02 -0.0301012843
 [56,] -4.070950 1.976469  2.187121e-02 -0.0840735253
 [57,] -4.128038 1.836275  2.653932e-02  0.0264198601
 [58,] -3.547201 1.893643 -1.220448e-02 -0.0532548753
 [59,] -4.253625 1.949080  2.781933e-02  0.0077849862
 [60,] -3.828644 2.026750 -9.465307e-03  0.0960147913
 [61,] -3.329464 1.911021 -2.446603e-02  0.0826964899
 [62,] -2.783577 2.028467 -7.313176e-02 -0.0083623174
 [63,] -3.785957 2.107177 -1.024320e-02 -0.0292262387
 [64,] -3.503294 2.218297 -2.856721e-02 -0.1911600814
 [65,] -3.980969 2.331136  6.848130e-03 -0.1349997915
 [66,] -4.224634 2.271389  1.764537e-02 -0.2322014450
 [67,] -4.051636 1.755164  3.382020e-02 -0.0502680946
 [68,] -4.167917 1.892329  2.413028e-02  0.0713978309
 [69,] -3.892016 1.951293  1.294023e-02 -0.0461797131
 [70,] -4.221281 2.349525  9.300025e-03 -0.1280748576
 [71,] -4.038186 2.190095 -1.248136e-02  0.1284807361
 [72,] -4.153462 1.876132  2.418954e-02  0.0407323824
 [73,] -3.680884 1.905691  3.826367e-03 -0.0807805388
 [74,] -3.862942 2.075088 -1.191074e-03 -0.0902500892
 [75,] -4.459411 2.184930  3.011278e-02 -0.0419543041
 [76,] -3.921817 2.241596  2.936260e-03 -0.1873733123
 [77,] -4.420358 2.287025  2.684206e-02 -0.0759303594
 [78,] -4.117496 2.189210  1.006555e-02 -0.0306380720
 [79,] -4.556459 2.350623  2.761257e-02 -0.0313889979
 [80,] -3.633188 1.937863 -1.129189e-02  0.1026869679
 [81,] -3.317810 1.968503 -2.777436e-02 -0.0231569684
 [82,] -4.108313 2.233063  1.752310e-02 -0.2138606289
 [83,] -4.255765 2.066837  2.953841e-02 -0.0631286414
 [84,] -3.794796 1.787434 -2.928707e-03  0.0471999651
 [85,] -4.224503 2.247731  2.284714e-02 -0.2234170869
 [86,] -3.958594 2.120516  5.419099e-03 -0.0421861342
 [87,] -4.165156 2.250107  1.040067e-02  0.0096784666
 [88,] -4.220673 1.942202  2.567711e-02  0.0561326887
 [89,] -3.903220 1.675781  4.576196e-03  0.2289407864
 [90,] -3.952088 2.068918  1.041533e-02  0.0013006703
 [91,] -3.017197 1.918749 -6.023501e-02  0.1887729104
 [92,] -3.578705 1.928303 -5.016306e-03 -0.1079957787
 [93,] -4.179658 2.141584  7.062473e-03  0.0693183497
 [94,] -3.151914 1.707954 -3.741563e-02  0.1029969023
 [95,] -4.039477 1.758490  2.566947e-02  0.0410173442
 [96,] -3.736744 1.931141 -2.569540e-03  0.0307013893
 [97,] -4.330992 2.163376  1.841222e-02  0.0547245048
 [98,] -3.882636 2.140387 -1.365670e-02  0.1341756072
 [99,] -4.234107 1.831905  1.880653e-02  0.2229783023
[100,] -3.933443 1.647317  1.189936e-02  0.1605306003
[101,] -3.542973 1.969563 -1.115360e-02 -0.0967108860
[102,] -4.338734 2.007737  3.561820e-02 -0.1895856940
[103,] -3.577456 1.922959 -1.250841e-02  0.0484943747
[104,] -3.598097 1.707207 -7.928601e-03  0.1724831663
[105,] -3.340302 1.817531 -1.784262e-02  0.1103093303
[106,] -4.022772 1.867022  2.163535e-03  0.1263383823
[107,] -3.753820 1.731648 -4.218182e-03  0.2109086977
[108,] -3.818753 1.634100  1.053036e-02  0.0960093097
[109,] -3.724633 1.877808 -8.989965e-03  0.1407357447
[110,] -4.244920 2.039018  2.798763e-02 -0.1295961743
[111,] -4.168832 1.744343  4.168347e-02 -0.1808043035
[112,] -3.446746 2.077901 -2.459518e-02  0.0442680050
[113,] -3.709134 2.039625 -9.474989e-03 -0.0239765433
[114,] -4.454119 2.077934  3.162493e-02  0.0081604356
[115,] -3.811791 1.888262  8.291079e-03 -0.0560978053
[116,] -3.229089 1.568112 -2.509880e-02  0.1762843494
[117,] -4.368383 2.304658  2.923612e-02 -0.1839176553
[118,] -3.957654 1.937859  6.659491e-03  0.1293451880
[119,] -3.573392 1.916203 -4.780613e-03 -0.0250286766
[120,] -4.535901 2.092518  4.408217e-02 -0.1718357021
[121,] -3.441743 1.691703 -1.632589e-05 -0.0223601452
[122,] -4.600653 2.205166  5.382954e-02 -0.2499089372
[123,] -3.648581 2.048314 -1.995391e-02 -0.0479559614
[124,] -3.736338 1.719468  1.801152e-02 -0.1994128551
[125,] -3.543307 2.039714 -3.640900e-02  0.2084066384
[126,] -4.206820 2.081356  3.869386e-02 -0.3405615437
[127,] -4.258129 1.948369  3.278952e-02 -0.0448500667
[128,] -4.373079 1.842214  4.823094e-02 -0.1004990621
[129,] -4.148287 2.023120  9.630051e-03  0.0877215182
[130,] -4.143330 2.308443 -4.089434e-03  0.0770153918
[131,] -4.778840 2.291624  5.068641e-02 -0.1121995539
[132,] -4.141665 2.146397  9.686976e-03 -0.1376819699
[133,] -3.681046 1.712813  1.486629e-03 -0.0766602091
[134,] -4.372731 2.054793  3.719464e-02 -0.1165455283
[135,] -3.790547 1.732658 -1.231776e-02  0.2838359688
[136,] -3.212153 1.812344 -4.461675e-02  0.2593503363
[137,] -3.973108 2.207621 -6.746633e-03  0.0909391169
[138,] -3.565210 1.735276  8.736103e-05  0.0067024548
[139,] -3.788251 1.844103 -2.476328e-03  0.1328353227
[140,] -3.576748 1.910192 -2.525622e-02  0.2227450439
[141,] -4.091194 1.997856  9.635091e-03  0.0877351764
[142,] -3.042638 1.903770 -4.801038e-02  0.0326760308
[143,] -3.691625 2.002754 -1.636026e-02  0.1841347634
[144,] -3.708474 2.051738 -9.524079e-03  0.0919030182
[145,] -4.086419 2.062700  1.695154e-02 -0.0073464607
[146,] -3.665304 1.806516 -3.883012e-04 -0.0198030585
[147,] -3.948158 2.168884 -4.799085e-03  0.0319546148
[148,] -3.899799 1.777215  1.801642e-02 -0.0376984306
[149,] -4.119613 1.988812  1.475623e-02  0.0513729742
[150,] -3.183234 2.015816 -5.316946e-02  0.0926026976
[151,] -4.658398 2.125951  5.812887e-02 -0.1928143948
[152,] -3.909959 1.772701  1.532813e-02 -0.0034605823
[153,] -3.984224 1.825817  2.456982e-02 -0.0930558491
[154,] -3.973998 1.923835 -4.052438e-03  0.1703695702
[155,] -3.761268 2.244790 -1.991955e-02  0.0741631169
[156,] -3.766018 1.815574  9.714597e-03 -0.0902698171
[157,] -3.382664 1.889235 -1.567479e-02  0.0054273387
[158,] -4.299453 2.161247  2.525079e-02 -0.0245131942
[159,] -3.971762 1.754104  1.943952e-02  0.0538717257
[160,] -3.729038 2.108848 -5.337196e-03 -0.0836908270
[161,] -4.072074 2.089673  1.003418e-02 -0.0191671709
[162,] -3.726402 2.350778 -2.614489e-02  0.0192340312
[163,] -4.271362 2.171828  8.733168e-03  0.0620623598
[164,] -4.141373 2.031672  9.607776e-03  0.0112017746
[165,] -3.660877 1.976406 -1.564615e-02  0.0531483877
[166,] -3.994615 2.008611  1.296949e-02 -0.0855021644
[167,] -3.682432 1.917970 -9.389878e-03  0.0975080593
[168,] -3.712435 1.967671 -1.293232e-02  0.0980822416
[169,] -3.602417 1.686933 -8.635301e-03  0.1599597742
[170,] -4.042045 1.972223  1.135082e-02  0.0679132101
[171,] -3.923126 1.959767  3.821107e-03  0.0266927543
[172,] -3.708147 2.180345 -2.021972e-02  0.0492925296
[173,] -3.231069 1.879184 -3.027010e-02 -0.0467780434
[174,] -4.170552 2.097939  1.495251e-02  0.0339674881
[175,] -3.977441 2.069193  9.149238e-03 -0.0343744390
[176,] -2.918763 1.861498 -5.087048e-02  0.1109926996
[177,] -3.825964 2.136737 -1.007372e-02 -0.0889649110
[178,] -4.012678 1.913433  1.959579e-02 -0.0750959528
[179,] -3.487779 1.789610 -1.535217e-02  0.0208746653
[180,] -4.117304 1.844894  2.004815e-02  0.0880333643
[181,] -3.942283 2.012438  9.346536e-03 -0.0834828653
[182,] -3.734137 2.027397 -2.145237e-02  0.1420088805
[183,] -4.483311 2.188642  3.366753e-02 -0.0301291688
[184,] -3.838530 1.668071  1.754700e-02  0.0583062928
[185,] -4.012181 1.844684  1.113130e-02  0.1206024235
[186,] -3.626336 1.794206 -9.053122e-03  0.1690885934
[187,] -4.436413 2.445604  2.081198e-02 -0.1195249551
[188,] -3.397241 1.994561 -1.869806e-02 -0.1071045964
[189,] -3.471909 1.795838 -1.269041e-02  0.0374633111
[190,] -4.590055 2.227085  3.555907e-02  0.0056764109
[191,] -3.579845 2.002842 -1.810414e-02  0.1169015711
[192,] -4.552549 2.075705  4.842211e-02 -0.1451576280
[193,] -4.464329 2.076222  3.918276e-02 -0.0808833632
[194,] -3.449458 1.791139 -1.612597e-02  0.0871687556
[195,] -4.054341 2.211736  1.727949e-03 -0.0326121725
[196,] -3.932856 2.064632  4.642995e-03  0.0456466509
[197,] -4.252220 1.675334  4.307806e-02 -0.0183576612
[198,] -3.922157 2.091423 -9.370502e-03  0.1169922018
[199,] -3.570241 1.930075 -2.057593e-02  0.0149000826
[200,] -4.328309 2.458444  2.473266e-03 -0.0456277237
> 
> # compare mean-values
> ergm_mv_est_tapered = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+ #ergm_mv_est_tapered <- simulate(g_sim[[1]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+ simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                control=control.simulate.formula(MCMC.burnin=100000, MCMC.interval=10000),
+                coef = ergm_sim_estim_tapered[i,],         
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
      edges nodematch.x      kstar2    triangle 
   392.5495    340.6510   3083.5500    117.0405 
> ergm_mv_tapered = colMeans(ergm_mv_est_tapered)
> ergm_mv_tapered
      edges nodematch.x      kstar2    triangle 
   416.0875    351.2240   5490.2580    917.6405 
> 
> # Model statistics ‘kstar2’ and ‘triangle’ are not varying. This may indicate 
> # that the observed data occupies an extreme point in the sample space or that 
> # the estimation has reached a dead-end configuration.
> # Warning: Model statistics ‘nodematch.x’ are linear combinations of some set of 
> # preceding statistics at the current stage of the estimation. This may indicate 
> # that the model is nonidentifiable.
> # Error in ergm.MCMLE(init, nw, model, initialfit = (initialfit <- NULL),  : 
> # Unconstrained MCMC sampling did not mix at all. Optimization cannot continue.
> # In addition: Warning message:
> # In ergm_MCMC_sample(s, control, theta = mcmc.init, verbose = max(verbose -  :
> # Unable to reach target effective size in iterations alotted.
> 
> 
> ##################
> #                #
> #     MFERGM     #
> #                #
> ##################
> 
> # Use "theta" on mfergm instead
> tobs <- data.frame(matrix(NA, ncol = 4, nrow = nsims))
> names(tobs) <- c("edges", "x", "kstar2", "triangles")
> for (i in 1:nsims) 
+ {
+   tobs[i,] = g_sim_stats[i,] / (c((n^2)/2, (n^2)/2, (n^3)/2 , (n^3)/2 ))  
+ }
> 
> ### Compute MFERGM Results
> mfergm_estim <- NULL
> # Double loop to reduce memory use
> for(j in 1:(nsims/100)){
+  mfergm_estim_j = foreach(i = (100*(j-1)+(1:100)), .combine = rbind) %dorng% {
+   pars <- init_params[i,] * c(.5,.5,n,n)
+   addpars <- list(n=n, tobs = tobs[i,], x=x, ninit=1)
+   cd.est <- tryCatch(optimx(pars, fn = loglikmf.model5, 
+                             method = "BFGS", 
+                             control = list(fnscale = -1), addpars = addpars), 
+                      error = function(e) {return(c(NA, NA, NA, NA))})
+   as.numeric(cd.est[1:4])
+  }
+  mfergm_estim <- rbind(mfergm_estim, mfergm_estim_j)
+ }
> mfergm_estim = matrix(c(mfergm_estim[,1]*2, mfergm_estim[,2]*2, mfergm_estim[,3]/n, mfergm_estim[,4]/n),
+                nrow = nsims)
> mfergm_result_med = apply(mfergm_estim, 2, median, na.rm = T) 
> mfergm_result = apply(mfergm_estim, 2, mean, na.rm = T) 
> cbind(theta,mfergm_result_med,mfergm_result)
     theta mfergm_result_med mfergm_result
[1,] -4.00      -4.032378782   -21.9675010
[2,]  2.00       2.124024238     4.5847922
[3,]  0.01      -0.003394538    -0.2545582
[4,]  0.01      -0.009045980    -0.3182294
> 
> #### DEGENERACIES
> degen_mfergm = which(!complete.cases(mfergm_estim))
> # 58 of em
> degen_mfergm
 [1]  10  50  69  70  92 126 129 144 155 185
> 
> if(length(degen_mfergm) > 0){
+ # Replace with MPLE
+ for(i in 1:length(degen_mfergm)){
+   mfergm_estim[degen_mfergm[i],] <- init_params[degen_mfergm[i],]
+ }
+ }
> 
> # compare mean values
> mf_mv_est = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                control=control.simulate.formula(MCMC.burnin=100000, MCMC.interval=10000),
+                coef =  mfergm_estim[i,],    
+                output = "stats"
+ )
+ }
> mfergm_mv = colMeans(mf_mv_est)
> mfergm_mv
      edges nodematch.x      kstar2    triangle 
    777.964     597.823   22949.436    4652.697 
> 
> # compare mean values
> MPLE_mv_est = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = init_params[i,],    
+                control=control.simulate.formula(MCMC.burnin=100000, MCMC.interval=10000),
+                output = "stats"
+ )
+ }
> stopImplicitCluster()
> colMeans(g_sim_stats)
      edges nodematch.x      kstar2    triangle 
   392.5495    340.6510   3083.5500    117.0405 
> MPLE_mv = colMeans(MPLE_mv_est)
> MPLE_result = apply(init_params, 2, mean, na.rm = T) 
> 
> mean_est <- cbind(theta, ergm_result_tapered, MPLE_result, mfergm_result)
> rownames(mean_est) <- names(ergm_mv_tapered)
> colnames(mean_est) <- c("true", "MCMC-MLE","MPLE","MFVLE")
> mean_est
             true     MCMC-MLE         MPLE       MFVLE
edges       -4.00 -3.896487670 -3.886134504 -21.9675010
nodematch.x  2.00  1.993673711  1.992488914   4.5847922
kstar2       0.01  0.003448024  0.002693065  -0.2545582
triangle     0.01  0.006311561  0.008738063  -0.3182294
> 
> mean_mv_est <- cbind(round(colMeans(g_sim_stats), 2), round(ergm_mv_tapered,2), round(MPLE_mv,2), round(mfergm_mv, 2))
> rownames(mean_mv_est) <- names(ergm_mv_tapered)
> colnames(mean_mv_est) <- c("true", "MCMC-MLE","MPLE", "MFVLE")
> mean_mv_est
               true MCMC-MLE    MPLE    MFVLE
edges        392.55   416.09  393.08   777.96
nodematch.x  340.65   351.22  340.30   597.82
kstar2      3083.55  5490.26 3092.21 22949.44
triangle     117.04   917.64  117.68  4652.70
> 
> hist(ergm_sim_estim_tapered[,4], main = NULL, xlab = "Triangle")
> hist(mfergm_estim[,4], main = NULL, xlab = "Triangle")
> 
> 
> outliers <- function(x, field = 1.5, na.rm = TRUE) 
+ {
+   qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm)
+   H <- field * IQR(x, na.rm = na.rm)
+   which(x < (qnt[1] - H) | x > (qnt[2] + H))
+ }
> 
> 
> 
> a  = is.na(ergm_sim_estim_tapered[,4])
> b  = is.na(mfergm_estim[,4])
> c = mfergm_estim[(!a)&(!b),]
> c1 = c[,4]
> d = ergm_sim_estim_tapered[(!a)&(!b),]
> d1 = d[,4]
> c1[c1 < -2] = d1[c1 < -2]
> plot(c1~d1, col = (c1 == d1) + 1, pch = 16)
> sum(c1 == d1)
[1] 6
> 
> f = c[-Reduce(union, list(outliers(c[,1], 0.6), outliers(c[,2], 0.3), outliers(c[,3], 1.5), outliers(c[,4], 1.5))),]
> 
> 
> 
> gtest_mf = matrix(nrow = nrow(c), ncol = 4)
> for (i in 1:nrow(c))
+ {
+   gtest_mf[i,] = simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1,
+                           coef = c[i,],        
+                           output = "stats")
+ }
> gtest_mc_tapered = matrix(nrow = nrow(d), ncol = 4)
> for (i in 1:nrow(d))
+ {
+   gtest_mc_tapered[i,] = as.vector(simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1,
+                           coef = d[i,],        
+                           output = "stats"))
+ }
> colMeans(gtest_mf)
[1]   706.395   545.480 16629.165  2593.340
> colMeans(gtest_mc_tapered)
[1]  393.495  341.265 3100.220  118.090
> 
> summary(ergm_sim_estim_tapered)
       V1               V2              V3                  V4           
 Min.   :-4.779   Min.   :1.568   Min.   :-0.073132   Min.   :-0.340562  
 1st Qu.:-4.156   1st Qu.:1.848   1st Qu.:-0.012253   1st Qu.:-0.067000  
 Median :-3.928   Median :1.988   Median : 0.005031   Median : 0.010440  
 Mean   :-3.896   Mean   :1.994   Mean   : 0.003448   Mean   : 0.006312  
 3rd Qu.:-3.658   3rd Qu.:2.122   3rd Qu.: 0.019709   3rd Qu.: 0.087307  
 Max.   :-2.784   Max.   :2.484   Max.   : 0.058129   Max.   : 0.283836  
> summary(gtest_mf)
       V1               V2               V3               V4          
 Min.   :   4.0   Min.   :   0.0   Min.   :     0   Min.   :    0.00  
 1st Qu.: 375.8   1st Qu.: 288.2   1st Qu.:  2794   1st Qu.:   84.25  
 Median : 489.0   Median : 366.0   Median :  4676   Median :  155.50  
 Mean   : 706.4   Mean   : 545.5   Mean   : 16629   Mean   : 2593.34  
 3rd Qu.: 932.5   3rd Qu.: 777.0   3rd Qu.: 17039   3rd Qu.: 1428.50  
 Max.   :3555.0   Max.   :2066.0   Max.   :249845   Max.   :59490.00  
> summary(gtest_mc_tapered)
       V1              V2              V3             V4       
 Min.   :306.0   Min.   :264.0   Min.   :1810   Min.   : 41.0  
 1st Qu.:375.0   1st Qu.:325.0   1st Qu.:2780   1st Qu.: 97.0  
 Median :395.0   Median :342.5   Median :3094   Median :115.5  
 Mean   :393.5   Mean   :341.3   Mean   :3100   Mean   :118.1  
 3rd Qu.:411.0   3rd Qu.:358.2   3rd Qu.:3387   3rd Qu.:141.0  
 Max.   :490.0   Max.   :421.0   Max.   :4685   Max.   :256.0  
> summary(g_sim_stats)
     edges        nodematch.x        kstar2        triangle    
 Min.   :327.0   Min.   :277.0   Min.   :2050   Min.   : 57.0  
 1st Qu.:379.0   1st Qu.:328.0   1st Qu.:2852   1st Qu.:101.0  
 Median :393.0   Median :341.0   Median :3076   Median :116.0  
 Mean   :392.5   Mean   :340.7   Mean   :3084   Mean   :117.0  
 3rd Qu.:406.0   3rd Qu.:353.0   3rd Qu.:3298   3rd Qu.:130.2  
 Max.   :479.0   Max.   :420.0   Max.   :4531   Max.   :211.0  
> 
> 
> gtest_mf_tri = gtest_mf[gtest_mf[,4]<60, 4]
> 
> hist(ergm_sim_estim_tapered[,1])
> hist(ergm_sim_estim_tapered[,2])
> hist(ergm_sim_estim_tapered[,3])
> hist(ergm_sim_estim_tapered[,4])
> hist(f[,1])
> hist(f[,2])
> hist(f[,3])
> hist(f[,4])
> 
> 
> gtest_mf_rm = gtest_mf[-Reduce(union, list(outliers(gtest_mf[,1], 0.7), outliers(gtest_mf[,2], 1), 
+                                            outliers(gtest_mf[,3], 0.001), outliers(gtest_mf[,4], 0.001))),]
> hist(gtest_mf[,1])
> hist(gtest_mf[,2])
> hist(gtest_mf[,3])
> hist(gtest_mf[,4])
> 
> hist(ergm_sim_estim_tapered[,1])
> hist(ergm_sim_estim_tapered[,2])
> hist(ergm_sim_estim_tapered[,3])
> hist(ergm_sim_estim_tapered[,4])
> 
> # First natural params
> complete_mf_results = mfergm_estim[complete.cases(mfergm_estim),]
> complete_tapered_results = ergm_sim_estim_tapered[complete.cases(ergm_sim_estim_tapered),]
> complete_MPLE_results = init_params[complete.cases(init_params),]
> 
> bdrmse <- function(comp, theta, degen){
+  outliers1 = union(outliers((comp[,1] - theta[1])^2), degen)
+  outliers2 = union(outliers((comp[,2] - theta[2])^2), degen)
+  outliers3 = union(outliers((comp[,3] - theta[3])^2), degen)
+  outliers4 = union(outliers((comp[,4] - theta[4])^2), degen)
+  rmse1 <- ((comp[,1] - theta[1])^2)
+  rmse1[outliers1] <- max(rmse1[-outliers1])
+  rmse2 <- ((comp[,2] - theta[2])^2)
+  rmse2[outliers2] <- max(rmse2[-outliers2])
+  rmse3 <- ((comp[,3] - theta[3])^2)
+  rmse3[outliers3] <- max(rmse3[-outliers3])
+  rmse4 <- ((comp[,4] - theta[4])^2)
+  rmse4[outliers4] <- max(rmse4[-outliers4])
+  c(sqrt(mean(rmse1)), sqrt(mean(rmse2)), sqrt(mean(rmse3)), sqrt(mean(rmse4)) ) 
+ }
> bdmad <- function(comp, theta, degen){
+  outliers1 = union(outliers(abs(comp[,1] - theta[1])),degen)
+  outliers2 = union(outliers(abs(comp[,2] - theta[2])),degen)
+  outliers3 = union(outliers(abs(comp[,3] - theta[3])),degen)
+  outliers4 = union(outliers(abs(comp[,4] - theta[4])),degen)
+  mad1 <- (abs(comp[,1] - theta[1]))
+  mad1[outliers1] <- max(mad1[-outliers1])
+  mad2 <- (abs(comp[,2] - theta[2]))
+  mad2[outliers2] <- max(mad2[-outliers2])
+  mad3 <- (abs(comp[,3] - theta[3]))
+  mad3[outliers3] <- max(mad3[-outliers3])
+  mad4 <- (abs(comp[,4] - theta[4]))
+  mad4[outliers4] <- max(mad4[-outliers4])
+  c((mean(mad1)), (mean(mad2)), (mean(mad3)), (mean(mad4)) ) 
+ }
> 
> # Degeneracy
> length(intersect(which(is.na(mfergm_estim[,1])), which(is.na(ergm_sim_estim_tapered[,1]))))
[1] 0
> 
> # RMSE
> 
> MPLE_rmse <- bdrmse(complete_MPLE_results, theta,degen=NULL)
> mf_rmse <- bdrmse(complete_mf_results, theta, degen_mfergm)
> tapered_rmse <- bdrmse(complete_tapered_results, theta, degen_tapered)
> 
> # MAD
> MPLE_mad <- bdmad(complete_MPLE_results, theta,degen=NULL)
> mf_mad <- bdmad(complete_mf_results, theta, degen_mfergm)
> tapered_mad <- bdmad(complete_tapered_results, theta, degen_tapered)
> 
> RMSE_natural_parameter <- cbind(round(tapered_rmse, 3), round(MPLE_rmse, 3), round(mf_rmse, 3))
> rownames(RMSE_natural_parameter) <- names(mv_1)
> colnames(RMSE_natural_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the RMSE of natural parameter estimates
> RMSE_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.366 0.369 3.354
nodematch.x    0.181 0.182 3.844
kstar2         0.022 0.022 0.048
triangle       0.108 0.108 0.134
> 
> MAD_natural_parameter <- cbind(round(tapered_mad, 3), round(MPLE_mad, 3), round(mf_mad, 3))
> rownames(MAD_natural_parameter) <- names(mv_1)
> colnames(MAD_natural_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the MAD of natural parameter estimates
> MAD_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.315 0.316 2.766
nodematch.x    0.156 0.155 3.514
kstar2         0.019 0.020 0.044
triangle       0.092 0.092 0.118
> 
> 
> outliers1 = outliers((complete_tapered_results[,1] - theta[1])^2)
> outliers2 = outliers((complete_tapered_results[,2] - theta[2])^2)
> outliers3 = outliers((complete_tapered_results[,3] - theta[3])^2)
> outliers4 = outliers((complete_tapered_results[,4] - theta[4])^2)
> plot((complete_mf_results[,1] - theta[1])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,2] - theta[2])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,3] - theta[3])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,4] - theta[4])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,1] - theta[1])^2)[-outliers1], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,2] - theta[2])^2)[-outliers2], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,3] - theta[3])^2)[-outliers3], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,4] - theta[4])^2)[-outliers4], pch = 19, ylab = "", xlab = "Simulated Networks")
> 
> 
> outliers1 = head(order((complete_mf_results[,1] - theta[1])^2, decreasing = T), n = 100)
> outliers2 = head(order((complete_mf_results[,2] - theta[2])^2, decreasing = T), n = 100)
> outliers3 = head(order((complete_mf_results[,3] - theta[3])^2, decreasing = T), n = 100)
> outliers4 = head(order((complete_mf_results[,4] - theta[4])^2, decreasing = T), n = 100)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> 
> 
> plot(density(complete_mf_results[,1]), main = "")
> plot(density(complete_mf_results[,2]), main = "")
> plot(density(complete_mf_results[,3]), main = "")
> plot(density(complete_mf_results[,4]), main = "")
> 
> 
> # Now the mean values
> complete_mf_results = mf_mv_est[complete.cases(mf_mv_est),]
> complete_tapered_results = ergm_mv_est_tapered[complete.cases(ergm_mv_est_tapered),]
> complete_MPLE_results = MPLE_mv_est[complete.cases(MPLE_mv_est),]
> 
> 
> # Degeneracy
> length(intersect(which(is.na(mf_mv_est[,1])), which(is.na(ergm_mv_est_tapered[,1]))))
[1] 0
> 
> # MFERGM RMSE
> 
> outliers1 = outliers((complete_tapered_results[,1] - mv_s[1])^2)
> outliers2 = outliers((complete_tapered_results[,2] - mv_s[2])^2)
> outliers3 = outliers((complete_tapered_results[,3] - mv_s[3])^2)
> outliers4 = outliers((complete_tapered_results[,4] - mv_s[4])^2)
> plot((complete_mf_results[,1] - mv_s[1])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,2] - mv_s[2])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,3] - mv_s[3])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,4] - mv_s[4])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,1] - mv_s[1])^2)[-outliers1], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,2] - mv_s[2])^2)[-outliers2], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,3] - mv_s[3])^2)[-outliers3], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,4] - mv_s[4])^2)[-outliers4], pch = 19, ylab = "", xlab = "Simulated Networks")
> 
> plot(density(complete_mf_results[,1]), main = "")
> plot(density(complete_mf_results[,2]), main = "")
> plot(density(complete_mf_results[,3]), main = "")
> plot(density(complete_mf_results[,4]), main = "")
> 
> # RMSE
> 
> MPLE_rmse <- bdrmse(complete_MPLE_results, mv_s, degen=NULL)
> mf_rmse <- bdrmse(complete_mf_results, mv_s, degen_mfergm)
> tapered_rmse <- bdrmse(complete_tapered_results, mv_s, degen_tapered)
> 
> # MAD
> MPLE_mad <- bdmad(complete_MPLE_results, mv_s, degen=NULL)
> mf_mad <- bdmad(complete_mf_results, mv_s, degen_mfergm)
> tapered_mad <- bdmad(complete_tapered_results, mv_s, degen_tapered)
> 
> RMSE_mean_value_parameter <- cbind(round(tapered_rmse, 3), round(MPLE_rmse, 3), round(mf_rmse, 3))
> rownames(RMSE_mean_value_parameter) <- names(mv_1)
> colnames(RMSE_mean_value_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the RMSE of mean-value parameter estimates
> RMSE_mean_value_parameter
            MCMC-MLE    MPLE     MFVLE
edges         26.906  27.318   449.019
nodematch.x   25.081  24.655   400.648
kstar2       426.319 433.429 11741.099
triangle      27.410  27.835  1032.674
> 
> MAD_mean_value_parameter <- cbind(round(tapered_mad, 3), round(MPLE_mad, 3), round(mf_mad, 3))
> rownames(MAD_mean_value_parameter) <- names(mv_1)
> colnames(MAD_mean_value_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the MAD of mean-value parameter estimates
> MAD_mean_value_parameter
            MCMC-MLE    MPLE    MFVLE
edges         22.875  23.167  358.150
nodematch.x   21.099  21.076  337.751
kstar2       364.858 368.609 9494.516
triangle      23.581  23.749  799.466
> 
> plot(mfergm_estim[,4],ergm_sim_estim_tapered[,4])
> 
> rm(ergm_sim_list_tapered)
> rm(g_sim)
> save.image("mfergm_params10_n1000.RData")
> 
> # Summary
> length(degen_tapered) / nsims
[1] 0.005
> length(degen_mfergm) / nsims
[1] 0.05
> # These are the RMSE of natural parameter estimates
> RMSE_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.366 0.369 3.354
nodematch.x    0.181 0.182 3.844
kstar2         0.022 0.022 0.048
triangle       0.108 0.108 0.134
> # These are the MAD of natural parameter estimates
> MAD_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.315 0.316 2.766
nodematch.x    0.156 0.155 3.514
kstar2         0.019 0.020 0.044
triangle       0.092 0.092 0.118
> # These are the RMSE of mean-value parameter estimates
> RMSE_mean_value_parameter
            MCMC-MLE    MPLE     MFVLE
edges         26.906  27.318   449.019
nodematch.x   25.081  24.655   400.648
kstar2       426.319 433.429 11741.099
triangle      27.410  27.835  1032.674
> # These are the RMSE of mean-value parameter estimates
> MAD_mean_value_parameter
            MCMC-MLE    MPLE    MFVLE
edges         22.875  23.167  358.150
nodematch.x   21.099  21.076  337.751
kstar2       364.858 368.609 9494.516
triangle      23.581  23.749  799.466
> 
> proc.time()
    user   system  elapsed 
2146.365   58.495  737.501 
