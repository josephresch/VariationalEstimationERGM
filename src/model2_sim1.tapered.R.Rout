> rm(list=ls())
> my.seed=1000
> set.seed(my.seed)
> 
> pdf("model2_sim1.tapered.pdf")
> 
> library(ergm.tapered)
Loading required package: ergm
Loading required package: network

‘network’ 1.18.0 (2022-10-05), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information


‘ergm’ 4.3-6983 (2022-08-20), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(mfergm)
> library(optimx)     # mfergm likelihood
> library(R.utils)    # set time on ergm
Loading required package: R.oo
Loading required package: R.methodsS3
R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.
R.oo v1.25.0 (2022-06-12 02:20:02 UTC) successfully loaded. See ?R.oo for help.

Attaching package: ‘R.oo’

The following object is masked from ‘package:R.methodsS3’:

    throw

The following objects are masked from ‘package:methods’:

    getClasses, getMethods

The following objects are masked from ‘package:base’:

    attach, detach, load, save

R.utils v2.12.0 (2022-06-28 03:20:05 UTC) successfully loaded. See ?R.utils for help.

Attaching package: ‘R.utils’

The following object is masked from ‘package:utils’:

    timestamp

The following objects are masked from ‘package:base’:

    cat, commandArgs, getOption, isOpen, nullfile, parse, warnings

> library(doParallel) # parallel loops using 'foreach'
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
> 
> #####################################################################
> #                                                                   #
> #     Create High Transitivity ERGM Params (using ERGM fitting)     #
> #                                                                   #
> #####################################################################
> 
> nsims       =  100                              # number of networks simulated
> n           =  100                                # number of nodes
> theta       =  c(-3,2,1,3) * c(2,2,1/n,1/n)      # true parameters for model 2
> 
> 
> ##################
> #                #
> #     Set-up     #
> #                #
> ##################
> 
> g <- initialize.network(theta, n, directed = FALSE)
> x <- rbinom(n, 1, 0.5) # attributes
> set.vertex.attribute(g, # the name of the network object
+                      "x", # the name we want to reference the variable by in that object
+                      x # the value we are giving that variable
+ ) 
> 
> # Simulated networks 'g_sim' used for both ERGM and MFERGM
> g_sim <- simulate(g ~ edges + nodematch("x") + kstar(2) + triangles, 
+                   nsim = nsims,
+                   coef = theta
+ )
> 
> # Extract summary stats from 'g_sim'
> g_sim_stats = matrix(nrow = nsims, ncol = 4)
> for (i in 1:nsims)
+ {
+   g_sim_stats[i,] = summary_formula(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles)
+ }
> 
> 
> # asdf_index = g_sim_stats[,1] > mean(g_sim_stats[,1]) - sd(g_sim_stats[,1]) & g_sim_stats[,1] < mean(g_sim_stats[,1]) + sd(g_sim_stats[,1]) &
> #              g_sim_stats[,2] > mean(g_sim_stats[,2]) - sd(g_sim_stats[,2]) & g_sim_stats[,2] < mean(g_sim_stats[,2]) + sd(g_sim_stats[,2]) &
> #              g_sim_stats[,3] > mean(g_sim_stats[,3]) - sd(g_sim_stats[,3]) & g_sim_stats[,3] < mean(g_sim_stats[,3]) + sd(g_sim_stats[,3]) &
> #              g_sim_stats[,4] > mean(g_sim_stats[,4]) - sd(g_sim_stats[,4]) & g_sim_stats[,4] < mean(g_sim_stats[,4]) + sd(g_sim_stats[,4])
> # 
> # asdf = g_sim_stats[asdf_index,]
> # g_sim_stats = asdf
> # nsims = nrow(asdf)
> # g_sim = g_sim[which(asdf_index)]
> 
> 
> 
> # Initialize the parameters at MPLE
> init_params = matrix(nrow = nsims, ncol = length(theta))
> for (i in 1:nsims)
+ {
+   init_params[i,] = ergm(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles, 
+                          estimate = "MPLE")$coefficients
+ }
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
> 
> 
> ##########################
> #                        #
> #     ERGM (Default)     #
> #                        #
> ##########################
> 
> ### Compute ERGM Results
> #registerDoParallel(detectCores())
> registerDoParallel(10)
> ergm_sim_list = foreach(i = 1:nsims) %dopar% {
+   # cat("***********************************\n")
+   # cat(paste("estimating sample" ,i, "\n"))
+   # cat("***********************************\n")
+   skip_to_next <- FALSE
+   formula <- g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = 
+     tryCatch(withTimeout(
+                           ergm(formula, eval.loglik=FALSE,
+                                control=control.ergm(init = init_params[i,], MCMLE.confidence=0.95)),
+                timeout = 5*60, onTimeout = "error"),
+                error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2245.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1005.
Estimating equations are not within tolerance region.
Optimizing with step length 1.0000.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0490.
The log-likelihood improved by 0.0687.
The log-likelihood improved by 0.0268.
The log-likelihood improved by 0.0381.
Convergence test p-value: 0.1707. Convergence test p-value: 0.1896. Not converged with 95% confidence; increasing sample size.
Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Iteration 2 of at most 60:
Convergence test p-value: 0.1690. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.2172. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2211.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.5566.
Estimating equations are not within tolerance region.
The log-likelihood improved by 0.1030.
Iteration 2 of at most 60:
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0412.
Convergence test p-value: 0.3823. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0700.
Convergence test p-value: 0.4318. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2089.
Optimizing with step length 1.0000.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0056.
Convergence test p-value: 0.0816. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0471.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3678. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0194.
Convergence test p-value: 0.0532. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0560.
Convergence test p-value: 0.2666. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0110.
The log-likelihood improved by 0.1931.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Convergence test p-value: 0.3617. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0243.
Convergence test p-value: 0.0053. Converged with 95% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0385.
Convergence test p-value: 0.1474. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0241.
Convergence test p-value: 0.5009. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0227.
Convergence test p-value: 0.0096. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0221.
The log-likelihood improved by 0.0671.
Convergence test p-value: 0.1657. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.2675. Not converged with 95% confidence; increasing sample size.
Iteration 1 of at most 60:
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1707.
Estimating equations are not within tolerance region.
Iteration 4 of at most 60:
The log-likelihood improved by 0.1348.
Estimating equations are not within tolerance region.
Estimating equations did not move closer to tolerance region more than 1 time(s) in 4 steps; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0741.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1246. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0040.
Convergence test p-value: 0.2462. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0115.
The log-likelihood improved by 0.0241.
Convergence test p-value: 0.2204. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Convergence test p-value: 0.1246. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0092.
Convergence test p-value: 0.1137. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0451.
Convergence test p-value: 0.3566. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0209.
Convergence test p-value: 0.0104. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0161.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1474. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0202.
Convergence test p-value: 0.0720. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0601.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2770. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0229.
Convergence test p-value: 0.0233. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0246.
Convergence test p-value: 0.0176. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0243.
Convergence test p-value: 0.0003. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0074.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0548. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0668.
Convergence test p-value: 0.0004. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1451.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0730.
Optimizing with step length 1.0000.
Convergence test p-value: 0.5088. Not converged with 95% confidence; increasing sample size.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0197.
Convergence test p-value: 0.1182. Not converged with 95% confidence; increasing sample size.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0187.
Convergence test p-value: 0.0978. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0073.
Convergence test p-value: 0.0655. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0259.
Convergence test p-value: 0.6157. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0568.
Convergence test p-value: 0.4256. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0092.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0133. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0319.
Convergence test p-value: 0.0016. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0649.
Convergence test p-value: 0.0048. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0347.
Iteration 1 of at most 60:
Convergence test p-value: 0.6009. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1260.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0494.
Convergence test p-value: 0.2639. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0480.
Convergence test p-value: 0.0376. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0131.
Convergence test p-value: 0.0003. Converged with 95% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0613.
Convergence test p-value: 0.1469. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0601.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2081. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0158.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0421. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0825.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Convergence test p-value: 0.4688. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.3612.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0231.
Convergence test p-value: 0.0312. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0694.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.2720. Not converged with 95% confidence; increasing sample size.
Iteration 1 of at most 60:
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1219.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0356.
Convergence test p-value: 0.0204. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0434.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2684.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: 0.0258. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0588.
Convergence test p-value: 0.0118. Converged with 95% confidence.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1037.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0222.
Convergence test p-value: 0.0457. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0432.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Convergence test p-value: 0.0776. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0757.
Convergence test p-value: 0.2007. Not converged with 95% confidence; increasing sample size.
The log-likelihood improved by 0.0124.
Iteration 4 of at most 60:
Convergence test p-value: 0.1205. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1044.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1814.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0820.
Convergence test p-value: 0.4355. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0922.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.7553. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0674.
The log-likelihood improved by 0.0304.
Convergence test p-value: 0.5283. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0869. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0741.
The log-likelihood improved by 0.0024.
Convergence test p-value: 0.4772. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.2025. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0282.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0011.
Convergence test p-value: 0.2833. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0201.
Convergence test p-value: 0.3103. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0102.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1067.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: 0.0613. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0866.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3079. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0186.
Convergence test p-value: 0.0795. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0154.
The log-likelihood improved by 0.0186.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0193. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0118.
Convergence test p-value: 0.0483. Optimizing with step length 1.0000.
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0550.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1274. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0277.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0089.
Convergence test p-value: 0.0132. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0483. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0172.
Convergence test p-value: 0.0322. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1765.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0119.
Iteration 1 of at most 60:
Convergence test p-value: 0.1739. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0329.
Convergence test p-value: 0.3627. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Convergence test p-value: 0.1078. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0534.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1251. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0352.
Convergence test p-value: 0.2235. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0093.
Convergence test p-value: 0.0033. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0449.
The log-likelihood improved by 0.0302.
Convergence test p-value: 0.0016. Converged with 95% confidence.
Finished MCMLE.
Convergence test p-value: 0.4332. This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Not converged with 95% confidence; increasing sample size.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 3 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0421.
Convergence test p-value: 0.3586. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0238.
Convergence test p-value: 0.0005. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0331.
Convergence test p-value: 0.1072. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0292.
Convergence test p-value: 0.0308. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0034.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0251.
The log-likelihood improved by 0.0890.
Convergence test p-value: 0.0011. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.4850. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1746.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0344.
Convergence test p-value: 0.0207. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0903.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.1306. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0259.
Convergence test p-value: 0.4252. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0013.
The log-likelihood improved by 0.0698.
Convergence test p-value: 0.0071. Converged with 95% confidence.
Finished MCMLE.
Convergence test p-value: 0.5425. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0512.
Convergence test p-value: 0.3457. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0053.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0221.
Convergence test p-value: 0.0036. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0995. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1240.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0168.
Convergence test p-value: 0.0488. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0109.
Convergence test p-value: 0.3312. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2942.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0266.
Convergence test p-value: 0.0437. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0792.
Convergence test p-value: 0.0994. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0406.
Convergence test p-value: 0.1940. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0654.
Convergence test p-value: 0.6165. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1466.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0460.
Convergence test p-value: 0.0607. Not converged with 95% confidence; increasing sample size.
Optimizing with step length 1.0000.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0368.
Convergence test p-value: 0.0219. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2566.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0254.
Convergence test p-value: 0.0567. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0225.
Convergence test p-value: 0.1019. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0359.
Convergence test p-value: 0.2758. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0122.
Convergence test p-value: 0.0021. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0594.
Convergence test p-value: 0.6309. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0242.
The log-likelihood improved by 0.0385.
Convergence test p-value: 0.0101. Converged with 95% confidence.
Convergence test p-value: 0.5534. Finished MCMLE.
Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0213.
Convergence test p-value: 0.3379. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0129.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0752. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.1492.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0472.
Convergence test p-value: 0.1374. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0584.
Convergence test p-value: 0.0063. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0666.
Convergence test p-value: 0.2568. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0291.
Convergence test p-value: 0.0810. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0174.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0669. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0071.
The log-likelihood improved by 0.0593.
The log-likelihood improved by 0.0834.
Convergence test p-value: 0.4144. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.7081. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.1829. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0167.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2131. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0402.
Convergence test p-value: 0.0125. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0206.
Convergence test p-value: 0.0520. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1193.
Estimating equations are not within tolerance region.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0684.
Convergence test p-value: 0.0788. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0079.
Convergence test p-value: 0.0001. Optimizing with step length 1.0000.
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0110.
Convergence test p-value: 0.0073. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0056.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0043. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1549.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0281.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0051.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0059. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2389.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0736.
The log-likelihood improved by 0.0270.
Convergence test p-value: 0.3839. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.1090. Not converged with 95% confidence; increasing sample size.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0576.
The log-likelihood improved by 0.0788.
Convergence test p-value: 0.7040. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.2969. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0265.
The log-likelihood improved by 0.1283.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Convergence test p-value: 0.3867. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0616.
Convergence test p-value: 0.3573. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0363.
Convergence test p-value: 0.1295. Not converged with 95% confidence; increasing sample size.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0039.
Convergence test p-value: 0.0014. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0515.
The log-likelihood improved by 0.0297.
Convergence test p-value: 0.1482. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.6167. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0091.
Convergence test p-value: 0.1113. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1249.
Estimating equations are not within tolerance region.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0311.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0022. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0507.
Convergence test p-value: 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0402.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.1023. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0490.
Convergence test p-value: 0.0957. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0209.
Convergence test p-value: 0.0035. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0299.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Convergence test p-value: 0.0970. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0196.
Convergence test p-value: 0.0023. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0045.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1209. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0285.
Convergence test p-value: 0.5886. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0028.
The log-likelihood improved by 0.0085.
Convergence test p-value: 0.0347. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0179. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0841.
Convergence test p-value: 0.0132. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3395.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3214.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1253.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0338.
The log-likelihood improved by 0.0430.
Convergence test p-value: 0.1709. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.5710. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0296.
Convergence test p-value: 0.1178. Not converged with 95% confidence; increasing sample size.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0814.
Optimizing with step length 1.0000.
Convergence test p-value: 0.4784. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0283.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1688. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0015.
The log-likelihood improved by 0.0492.
Convergence test p-value: 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0233. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0150.
Convergence test p-value: 0.0201. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0161.
Convergence test p-value: 0.2699. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0048.
Convergence test p-value: 0.0004. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0567.
Convergence test p-value: 0.3405. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0171.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3544. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0466.
Convergence test p-value: 0.0156. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0707.
The log-likelihood improved by 0.1468.
Estimating equations are not within tolerance region.
Estimating equations did not move closer to tolerance region more than 1 time(s) in 4 steps; increasing sample size.
Iteration 7 of at most 60:
Convergence test p-value: 0.0209. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0416.
Convergence test p-value: 0.2608. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0550.
Convergence test p-value: 0.3005. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0103.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1069. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0429.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3580. The log-likelihood improved by 0.0428.
Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Convergence test p-value: 0.3969. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0292.
Convergence test p-value: 0.0559. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0162.
The log-likelihood improved by 0.0213.
Convergence test p-value: 0.0372. Convergence test p-value: 0.0002. Converged with 95% confidence.
Converged with 95% confidence.
Finished MCMLE.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0343.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1470.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0103.
The log-likelihood improved by 0.0301.
Convergence test p-value: 0.2846. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.1532. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0723.
Convergence test p-value: 0.5197. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0094.
Convergence test p-value: 0.0998. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0600.
Convergence test p-value: 0.0008. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0100.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.1878. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0119.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0341. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0158.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0027. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0179.
Iteration 1 of at most 60:
Convergence test p-value: 0.0920. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0205.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1780. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0570.
Convergence test p-value: 0.4537. The log-likelihood improved by 0.0532.
Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.0924. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0063.
Convergence test p-value: 0.1473. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0194.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0350.
Convergence test p-value: 0.3114. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.0015. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0110.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0009.
Convergence test p-value: 0.0081. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0590.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0128. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0069.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0003. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0223.
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Convergence test p-value: 0.0634. Not converged with 95% confidence; increasing sample size.
The log-likelihood improved by 0.0245.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0172.
Convergence test p-value: 0.2272. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.0476. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0408.
The log-likelihood improved by 0.0424.
Convergence test p-value: 0.0573. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Convergence test p-value: 0.2449. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0221.
Convergence test p-value: 0.0609. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
Convergence test p-value: 0.0932. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0322.
Convergence test p-value: 0.1159. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0458.
The log-likelihood improved by 0.0356.
Convergence test p-value: 0.0109. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0611. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0239.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0134. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0248.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.1304. Iteration 1 of at most 60:
Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0089.
Convergence test p-value: 0.0309. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0163.
Convergence test p-value: 0.0045. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0983.
The log-likelihood improved by 0.0354.
Convergence test p-value: 0.4076. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.6015. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1528.
Estimating equations are not within tolerance region.
The log-likelihood improved by 0.0257.
Iteration 2 of at most 60:
Convergence test p-value: 0.2223. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0171.
Convergence test p-value: 0.0218. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0332.
Convergence test p-value: 0.2035. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0182.
Convergence test p-value: 0.0163. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0257.
Convergence test p-value: 0.0002. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0834.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.4255. Not converged with 95% confidence; increasing sample size.
Iteration 1 of at most 60:
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0602.
Convergence test p-value: 0.0137. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0077.
Convergence test p-value: 0.0675. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0312.
Convergence test p-value: 0.0299. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0557.
The log-likelihood improved by 0.0233.
Convergence test p-value: 0.0704. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.0119. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0133.
The log-likelihood improved by 0.0146.
The log-likelihood improved by 0.0186.
Convergence test p-value: 0.0071. Converged with 95% confidence.
Finished MCMLE.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Convergence test p-value: 0.2754. Not converged with 95% confidence; increasing sample size.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 2 of at most 60:
Convergence test p-value: 0.0419. Converged with 95% confidence.
Finished MCMLE.
Iteration 1 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0239.
Convergence test p-value: 0.0057. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0077.
Convergence test p-value: 0.5570. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0164.
Convergence test p-value: 0.5638. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0331.
Convergence test p-value: 0.0541. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0193.
The log-likelihood improved by 0.0307.
Convergence test p-value: 0.2203. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Convergence test p-value: 0.0634. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0257.
Convergence test p-value: 0.0111. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0349.
Convergence test p-value: 0.0439. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1100.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0227.
Convergence test p-value: 0.0023. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1907.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0142.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1776.
Estimating equations are not within tolerance region.
Estimating equations did not move closer to tolerance region more than 1 time(s) in 4 steps; increasing sample size.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0277.
Convergence test p-value: 0.0467. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0137.
Convergence test p-value: 0.2743. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0134.
The log-likelihood improved by 0.0649.
Convergence test p-value: 0.0158. Converged with 95% confidence.
Finished MCMLE.
Convergence test p-value: 0.7636. Not converged with 95% confidence; increasing sample size.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0143.
The log-likelihood improved by 0.0219.
Convergence test p-value: 0.1693. Convergence test p-value: 0.0223. Not converged with 95% confidence; increasing sample size.
Converged with 95% confidence.
Iteration 3 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2092.
Estimating equations are not within tolerance region.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0243.
Convergence test p-value: 0.0205. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0258.
The log-likelihood improved by 0.0337.
Iteration 1 of at most 60:
Convergence test p-value: 0.1169. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.2716. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0840.
Convergence test p-value: 0.1620. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0476.
Convergence test p-value: 0.0474. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3326.
Estimating equations are not within tolerance region.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0545.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2368. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0452.
Convergence test p-value: 0.3263. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0371.
Convergence test p-value: 0.0412. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0339.
Convergence test p-value: 0.1224. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0186.
Convergence test p-value: 0.0330. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0481.
The log-likelihood improved by 0.0182.
Convergence test p-value: 0.0086. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0075. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0235.
Convergence test p-value: 0.0009. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0117.
Convergence test p-value: 0.0512. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0271.
Convergence test p-value: 0.3634. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0092.
Convergence test p-value: 0.0811. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0351.
Convergence test p-value: 0.0968. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0412.
Convergence test p-value: 0.0403. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
> 
> 
> ergm_sim_estim = matrix(0, nrow = nsims, ncol = 4)
> for(i in 1:nsims)
+ {
+   if(!is.null(ergm_sim_list[[i]]))
+   {
+     est.params <- ergm_sim_list[[i]]$coefficients
+     ergm_sim_estim[i,] <- est.params
+   }
+   else {ergm_sim_estim[i,] = c(NA, NA, NA, NA)}
+ }
> 
> ergm_result = apply(ergm_sim_estim, 2, median, na.rm = T)
> ergm_result
[1] -6.04579868  4.08533562  0.01081382  0.01527323
> theta
[1] -6.00  4.00  0.01  0.03
> ergm_q = apply(ergm_sim_estim, 2, quantile, c(0.01,0.99), na.rm = T)
> 
> #### DEGENERACIES
> degen = which(!complete.cases(ergm_sim_estim))
> # 58 of em
> degen
integer(0)
> 
> if(length(degen) > 0 ){
+ degen_list = ergm_sim_list[[]]
+ ergm_degen_list = foreach(i = 1:length(degen)) %dopar% {
+   skip_to_next <- FALSE
+   formula <- g_sim[[degen[i]]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = tryCatch(withTimeout(ergm(formula, eval.loglik=FALSE,
+                                         control=control.ergm(init=theta, MCMLE.confidence=0.95
+                                        #   # MCMC.burnin=100000,
+                                        #   # MCMC.interval=1000,
+                                        #   # MCMC.samplesize = 5000,
+                                           )
+   ), timeout = 5*60, onTimeout = "error"),
+   error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
+ 
+ ergm_degen_estim = matrix(0, nrow = length(degen), ncol = 4)
+ for(i in 1:length(degen))
+ {
+   if(!is.null(ergm_degen_list[[i]]))
+   {
+     est.params <- ergm_degen_list[[i]]$coefficients
+     ergm_degen_estim[i,] <- est.params
+     ergm_sim_estim[degen[i],] <- est.params
+   }
+   else {ergm_degen_estim[i,] = c(NA, NA, NA, NA)}
+ }
+ }
> 
> # compare mean-values
> g3 = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+ simulate(g_sim[[i]]  ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = ergm_sim_estim[i,],         
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  365.72  358.97 2759.26  131.63
> ergm_mv = colMeans(g3)
> 
> ### Compute ERGM Results
> ergm_sim_list_tapered = foreach(i = 1:nsims) %dopar% {
+   # cat("***********************************\n")
+   # cat(paste("estimating sample" ,i, "\n"))
+   # cat("***********************************\n")
+   skip_to_next <- FALSE
+   formula <- g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = 
+     tryCatch(withTimeout(
+                           ergm.tapered(formula, eval.loglik=FALSE,
+                                control=control.ergm.tapered(init = init_params[i,])),
+                timeout = 5*60, onTimeout = "error"),
+                error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
[1] -6.74971087  4.54435528  0.02378694  0.05601063
[1][1] -5.964551847  3.888073483  0.008791392  0.090174056
[1][1] -5.924321287 -5.708177285  3.800249409  3.919058295 -0.009709941  0.005397647  0.248527402  0.118924557 -6.23805176
[1]  4.37167711 -0.01249929  0.19930434

[1] -5.22408550  3.93626325 -0.05714276  0.28716660
[1] -5.971161581  3.994069882 -0.002305673  0.174552457[1][1] -5.5026807381
 -5.8928342  3.9140717  0.0032104  0.1249192
 -5.99754751  3.86595562  0.03610795 -0.20609374
  3.6344934937  0.0008777444  0.0832166930
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2355.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0420.
Precision adequate. Performing one more iteration.
The log-likelihood improved by 0.1063.
Iteration 2 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0382.
Precision adequate. Performing one more iteration.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1091.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1090.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0788.
The log-likelihood improved by 0.0117.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0628.
Increasing target MCMC sample size to 790, ESS to 79.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0232.
Iteration 3 of at most 60:
Increasing target MCMC sample size to 660, ESS to 66.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0403.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0200.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0198.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
The log-likelihood improved by 0.4187.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0185.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0044.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
[1] -6.31030680  4.25728871  0.02388122 -0.16089664
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0670.
Precision adequate twice. Stopping.
Finished MCMLE.
Starting maximum pseudolikelihood estimation (MPLE):
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -5.94915813  3.81447901  0.01677648Optimizing with step length 1.0000.
  0.06928147
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0172.
Increasing target MCMC sample size to 770, ESS to 77.
Optimizing with step length 1.0000.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0675.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0303.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Optimizing with step length 1.0000.
Stopping at the initial estimate.
The log-likelihood improved by 0.0152.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0136.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0339.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0245.
Increasing target MCMC sample size to 1010, ESS to 101.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0189.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
[1] -6.522827398  4.451221649  0.008820432  0.093484660
The log-likelihood improved by 0.0078.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2993.
Increasing target MCMC sample size to 910, ESS to 91.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0117.
Increasing target MCMC sample size to 920, ESS to 92.
Iteration 5 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0235.
Increasing target MCMC sample size to 1010, ESS to 101.
Iteration 5 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0905.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0090.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.26146654  3.88630923 -0.03149330  0.07646377
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0350.
Increasing target MCMC sample size to 710, ESS to 71.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2238.
Increasing target MCMC sample size to 640, ESS to 64.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0346.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3197.
Increasing target MCMC sample size to 970, ESS to 97.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0696.
Increasing target MCMC sample size to 1650, ESS to 165.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0834.
Increasing target MCMC sample size to 1670, ESS to 167.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0137.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -5.500016691  3.685889576 -0.006762705  0.116648945
The log-likelihood improved by 0.0393.
Increasing target MCMC sample size to 1510, ESS to 151.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0117.
Increasing target MCMC sample size to 1170, ESS to 117.
Iteration 6 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0193.
Precision adequate twice. Stopping.
Iteration 1 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -7.537069019  5.990462137 -0.018475385  0.001572531
The log-likelihood improved by 0.0239.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1180.
Increasing target MCMC sample size to 1390, ESS to 139.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0162.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0027.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0291.
Increasing target MCMC sample size to 1540, ESS to 154.
Iteration 7 of at most 60:
[1] -6.58473744  4.34545859  0.03223284 -0.16369290
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
The log-likelihood improved by 0.1076.
Stopping at the initial estimate.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0357.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0206.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
[1] -6.483064418  4.645929313  0.005810204 -0.050775819
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0756.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
The log-likelihood improved by 0.0599.
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0264.
Increasing target MCMC sample size to 1770, ESS to 177.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Iteration 7 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0365.
Increasing target MCMC sample size to 770, ESS to 77.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0164.
Increasing target MCMC sample size to 1560, ESS to 156.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0129.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0286.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -5.97027269  3.94545532  0.01060824 -0.09773543
The log-likelihood improved by 0.2505.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0437.
Increasing target MCMC sample size to 1750, ESS to 175.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0201.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
[1] -4.85830632  3.43925637 -0.03180503  0.07854645
The log-likelihood improved by 0.0488.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0199.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -5.57195368  3.98284044 -0.01995365  0.04858501
The log-likelihood improved by 0.0243.
Increasing target MCMC sample size to 980, ESS to 98.
Iteration 5 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0575.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0904.
Increasing target MCMC sample size to 880, ESS to 88.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0056.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0589.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0732.
Increasing target MCMC sample size to 2040, ESS to 204.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0893.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0138.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0219.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0768.
The log-likelihood improved by 0.0379.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
[1] -6.1718725911  4.2049713951 -0.0007447069  0.0705546131
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0778.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0140.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0492.
Increasing target MCMC sample size to 750, ESS to 75.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0292.
Increasing target MCMC sample size to 1010, ESS to 101.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0440.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0157.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0135.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0480.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0725.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -6.94080842  4.88918228  0.01832073 -0.04563895
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0077.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
[1] -6.16376445  4.08775271  0.02257319 -0.04709527
Starting maximum pseudolikelihood estimation (MPLE):
The log-likelihood improved by 0.0144.
Evaluating the predictor and response matrix.
Increasing target MCMC sample size to 1030, ESS to 103.
Iteration 6 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0733.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0176.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0301.
Precision adequate. Performing one more iteration.
Optimizing with step length 1.0000.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0087.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
The log-likelihood improved by 0.0386.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0122.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -5.076309891  3.164290977  0.009378225 -0.072460779
The log-likelihood improved by 0.0132.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0110.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0621.
Increasing target MCMC sample size to 950, ESS to 95.
Iteration 7 of at most 60:
[1] -6.76153506  4.62384439  0.04381852 -0.40970549
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
[1] -6.062232660  4.330490594 -0.008815286 -0.009627149
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.1068.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0361.
Precision adequate twice. Stopping.
Maximizing the pseudolikelihood.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Finished MPLE.
Optimizing with step length 1.0000.
Stopping at the initial estimate.
The log-likelihood improved by 0.0440.
Precision adequate twice. Stopping.
Finished MCMLE.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0218.
Increasing target MCMC sample size to 1430, ESS to 143.
Iteration 7 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
[1] -6.85757629  4.55968420  0.03368848 -0.04203042
[1] -5.77618986  3.85706324 -0.00530258  0.17929626
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0271.
Starting maximum pseudolikelihood estimation (MPLE):
Precision adequate twice. Stopping.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0489.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
[1]Optimizing with step length 1.0000.
 -7.54307318  5.37664109  0.03253313 -0.12715014
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0028.
Precision adequate twice. Stopping.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MCMLE.
Evaluating the predictor and response matrix.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0432.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -7.01739413  4.96111416  0.02501404 -0.20735597
The log-likelihood improved by 0.0116.
The log-likelihood improved by 0.0054.
Precision adequate. Performing one more iteration.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0387.
Precision adequate. Performing one more iteration.
Starting maximum pseudolikelihood estimation (MPLE):
Iteration 2 of at most 60:
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0093.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0054.
Increasing target MCMC sample size to 720, ESS to 72.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0120.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0735.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0113.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0288.
Increasing target MCMC sample size to 1670, ESS to 167.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0055.
Increasing target MCMC sample size to 1070, ESS to 107.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0149.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0801.
Increasing target MCMC sample size to 2340, ESS to 234.
Iteration 9 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0445.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1748.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1076.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -7.01318963  4.72503458  0.02506731  0.03484528
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0518.
The log-likelihood improved by 0.0082.
Increasing target MCMC sample size to 870, ESS to 87.
Precision adequate twice. Stopping.
Iteration 5 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0610.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -6.109768194  4.235130057  0.008581428 -0.105313333
The log-likelihood improved by 0.0388.
Increasing target MCMC sample size to 770, ESS to 77.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0340.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 5 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0417.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0189.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0105.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
[1] -6.88419389  4.65008823  0.03274907 -0.02926427
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1777.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0995.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0266.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1754.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0133.
Increasing target MCMC sample size to 1530, ESS to 153.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0421.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0536.
Increasing target MCMC sample size to 960, ESS to 96.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0347.
Increasing target MCMC sample size to 1040, ESS to 104.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0496.
Precision adequate. Performing one more iteration.
Iteration 10 of at most 60:
The log-likelihood improved by 0.0397.
Increasing target MCMC sample size to 1140, ESS to 114.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0364.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0855.
Increasing target MCMC sample size to 900, ESS to 90.
Iteration 5 of at most 60:
[1] -5.573058413  3.938346132  0.006267614 -0.141145106
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1064.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
[1] -6.99714384  4.91659788  0.02311467 -0.11084166
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0285.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0702.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0430.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -5.95777110  4.42012747 -0.01587879 -0.06406819
The log-likelihood improved by 0.0311.
Increasing target MCMC sample size to 1540, ESS to 154.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0137.
Increasing target MCMC sample size to 1230, ESS to 123.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0139.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0098.
Increasing target MCMC sample size to 1410, ESS to 141.
Iteration 8 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1023.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2737.
Increasing target MCMC sample size to 840, ESS to 84.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0283.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0108.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -5.345239213  3.672212366 -0.002872306  0.006268605
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0504.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0156.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Increasing target MCMC sample size to 1360, ESS to 136.
Iteration 7 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
[1] -6.22624818  4.01913709  0.03371256 -0.04654523
The log-likelihood improved by 0.0745.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0923.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -5.44316154  3.69460322 -0.01100178  0.05425835
The log-likelihood improved by 0.1002.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0361.
Starting maximum pseudolikelihood estimation (MPLE):
Increasing target MCMC sample size to 1870, ESS to 187.
Evaluating the predictor and response matrix.
Iteration 7 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0059.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -5.42912292  3.73533803 -0.01178095  0.03163594
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1210.
Starting maximum pseudolikelihood estimation (MPLE):
Increasing target MCMC sample size to 650, ESS to 65.
Evaluating the predictor and response matrix.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1797.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0142.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.3240.
Increasing target MCMC sample size to 950, ESS to 95.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
[1] -5.804249561  3.893055812  0.006073862  0.077807932
The log-likelihood improved by 0.0422.
Increasing target MCMC sample size to 1510, ESS to 151.
Iteration 9 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0463.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0519.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0065.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0331.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0375.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -5.339994500  4.356279194 -0.041587977 -0.001216964
The log-likelihood improved by 0.0103.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0222.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0976.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
[1] -6.05665042  3.93528999  0.01584431  0.03426130
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0833.
Increasing target MCMC sample size to 1670, ESS to 167.
Iteration 9 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0171.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -5.453699763  3.304375356  0.009616709  0.172135660
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1224.
Increasing target MCMC sample size to 820, ESS to 82.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0436.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0889.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0162.
Precision adequate. Performing one more iteration.
Iteration 10 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0062.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0236.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -6.48731291  4.27689475  0.02114398  0.08997202
The log-likelihood improved by 0.0559.
Increasing target MCMC sample size to 700, ESS to 70.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0272.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
The log-likelihood improved by 0.1062.
Starting maximum pseudolikelihood estimation (MPLE):
Precision adequate. Performing one more iteration.
Evaluating the predictor and response matrix.
Iteration 4 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.1495.
Increasing target MCMC sample size to 2000, ESS to 200.
Iteration 10 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0761.
Increasing target MCMC sample size to 1200, ESS to 120.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0155.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0202.
Increasing target MCMC sample size to 1170, ESS to 117.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0073.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0650.
Increasing target MCMC sample size to 1960, ESS to 196.
Iteration 9 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0497.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0152.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0690.
Increasing target MCMC sample size to 1870, ESS to 187.
Iteration 11 of at most 60:
The log-likelihood improved by 0.1187.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -6.52661599  4.59702780 -0.01254258  0.25566567
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0043.
Iteration 1 of at most 60:
Increasing target MCMC sample size to 820, ESS to 82.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0269.
Increasing target MCMC sample size to 1210, ESS to 121.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0026.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -6.071764671  4.169874521 -0.008685542  0.151836948
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0695.
Precision adequate. Performing one more iteration.
Iteration 11 of at most 60:
The log-likelihood improved by 0.0132.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Optimizing with step length 1.0000.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0857.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0089.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
[1] -6.128445800  4.224210504  0.008558552  0.046197290
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0151.
Precision adequate. Performing one more iteration.
The log-likelihood improved by 0.0887.
Iteration 10 of at most 60:
Increasing target MCMC sample size to 1720, ESS to 172.
Iteration 6 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0406.
Precision adequate. Performing one more iteration.
Iteration 12 of at most 60:
The log-likelihood improved by 0.0870.
Increasing target MCMC sample size to 1650, ESS to 165.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1740.
Increasing target MCMC sample size to 660, ESS to 66.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0060.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0348.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.8403036683  4.0328868142 -0.0002677645  0.0438241423
Starting maximum pseudolikelihood estimation (MPLE):
[1] -5.613333929  3.829750927  0.009098489 -0.114078938Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0088.
Precision adequate. Performing one more iteration.
The log-likelihood improved by 0.0079.
Iteration 3 of at most 60:
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0497.
The log-likelihood improved by 0.0133.
Precision adequate. Performing one more iteration.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Iteration 7 of at most 60:
[1] -5.88739979  3.89218814  0.02681858 -0.14107001
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2930.
Increasing target MCMC sample size to 890, ESS to 89.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0126.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0080.
Increasing target MCMC sample size to 720, ESS to 72.
Iteration 3 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -6.0434115  4.5232785 -0.0258876  0.0980016
The log-likelihood improved by 0.0121.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -6.53767165  4.17470326  0.05133435 -0.25913837
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0023.
The log-likelihood improved by 0.0441.
Precision adequate twice. Stopping.
Precision adequate twice. Stopping.
Finished MCMLE.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0849.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0120.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Iteration 1 of at most 60:
[1][1] -5.93981470  3.75825411  0.01638676  0.10061576
 -6.163738313  3.883986145  0.031322182  0.009351714
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0164.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0600.
Increasing target MCMC sample size to 810, ESS to 81.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0461.
Increasing target MCMC sample size to 1130, ESS to 113.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0456.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0302.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -6.131018815  4.187974157 -0.003859346  0.191028723
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0383.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0144.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0807.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0263.
The log-likelihood improved by 0.0149.
Optimizing with step length 1.0000.
Precision adequate. Performing one more iteration.
Precision adequate twice. Stopping.
Iteration 4 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1256.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
[1] -6.71744971  4.49854811  0.03717613 -0.11105263
The log-likelihood improved by 0.0490.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0659.
Increasing target MCMC sample size to 820, ESS to 82.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0190.
Increasing target MCMC sample size to 720, ESS to 72.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0386.
Increasing target MCMC sample size to 1130, ESS to 113.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0084.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0222.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0705.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0201.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0197.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
[1] -5.96621203  4.36817744 -0.01574035 -0.03021940
The log-likelihood improved by 0.0431.
Increasing target MCMC sample size to 830, ESS to 83.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0051.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Evaluating the predictor and response matrix.
[1] -6.029341149  4.077889313  0.012601245  0.008326916
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0113.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0408.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
[1] -6.86048275  4.65067480  0.03157285 -0.04062008
Iteration 1 of at most 60:
The log-likelihood improved by 0.0319.
Increasing target MCMC sample size to 1660, ESS to 166.
Iteration 6 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0101.
Increasing target MCMC sample size to 940, ESS to 94.
Iteration 5 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0888.
Increasing target MCMC sample size to 980, ESS to 98.
Iteration 3 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0198.
Increasing target MCMC sample size to 800, ESS to 80.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0543.
The log-likelihood improved by 0.0359.
Precision adequate. Performing one more iteration.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0681.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0327.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0094.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0768.
Increasing target MCMC sample size to 1160, ESS to 116.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0123.
Increasing target MCMC sample size to 820, ESS to 82.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Increasing target MCMC sample size to 1570, ESS to 157.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0297.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0177.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0053.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
[1] -6.118913886  4.492209261 -0.003978554 -0.034010773
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0141.
Increasing target MCMC sample size to 660, ESS to 66.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0558.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -6.54264457  4.41338065  0.01001486  0.13932325
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
[1] -5.80129384  3.67687000  0.02362954 -0.07814748
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0428.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0590.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0392.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0326.
Increasing target MCMC sample size to 1080, ESS to 108.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0398.
Increasing target MCMC sample size to 1030, ESS to 103.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0085.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0117.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.1385.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0998.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0621.
Increasing target MCMC sample size to 1110, ESS to 111.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0184.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0366.
Increasing target MCMC sample size to 750, ESS to 75.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0303.
Increasing target MCMC sample size to 1600, ESS to 160.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0058.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0515.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0040.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
[1] -5.93792886  4.15061223 -0.00434045  0.04930679
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0203.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.1231.
Increasing target MCMC sample size to 1900, ESS to 190.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0361.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0463.
Increasing target MCMC sample size to 1580, ESS to 158.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0369.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
[1] -6.69205810  4.80063850  0.01880189 -0.08023419
The log-likelihood improved by 0.0370.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
[1] -5.55381378  3.66335233 -0.00300742  0.13107712
The log-likelihood improved by 0.1352.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0301.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0915.
Increasing target MCMC sample size to 1940, ESS to 194.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0143.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0492.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0513.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0158.
[1] -5.90563888  4.01137819Precision adequate twice. Stopping.
The log-likelihood improved by 0.0269.
  0.01292945 -0.02293685
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0162.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0088.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.238163189  3.155010574  0.006095131  0.124837814
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0267.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
[1] -5.96032340  3.62354677  0.02663086  0.08698259
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
[1] -5.87676161  3.65934460  0.03161831 -0.01531512
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Stopping at the initial estimate.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0915.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0050.
Precision adequate twice. Stopping.
Optimizing with step length 1.0000.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1178.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
[1] -6.228177865  3.987941705  0.028160754 -0.008660816
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0274.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0095.
Increasing target MCMC sample size to 640, ESS to 64.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1167.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0115.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0396.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0411.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
[1] -6.501722109  4.583838498  0.006843073  0.029034857
The log-likelihood improved by 0.0175.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Optimizing with step length 1.0000.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0431.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0246.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0556.
Increasing target MCMC sample size to 830, ESS to 83.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3014.
Increasing target MCMC sample size to 760, ESS to 76.
Optimizing with step length 1.0000.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0184.
Optimizing with step length 1.0000.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0373.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0638.
Increasing target MCMC sample size to 1490, ESS to 149.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0839.
Increasing target MCMC sample size to 1300, ESS to 130.
Iteration 5 of at most 60:
[1] -6.10261792  4.01463345  0.02646086 -0.06081604
[1] -6.18103933  4.13982320  0.01289809  0.04563638
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0638.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -6.392735286  4.413302852 -0.001133394  0.170225444
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0370.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0174.
Increasing target MCMC sample size to 1730, ESS to 173.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0540.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0145.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0096.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0263.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0115.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
[1] -6.467476808  4.548897498  0.004517014  0.045789727
The log-likelihood improved by 0.1409.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -6.976212060  5.334367745 -0.009063188 -0.124335460
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0235.
Increasing target MCMC sample size to 690, ESS to 69.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0457.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 3 of at most 60:
Iteration 1 of at most 60:
The log-likelihood improved by 0.0166.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0721.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0199.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0825.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0165.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0203.
The log-likelihood improved by 0.0557.
Precision adequate. Performing one more iteration.
Precision adequate twice. Stopping.
Iteration 2 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -6.26977075  4.08068893  0.02968536 -0.04356985
The log-likelihood improved by 0.0896.
Increasing target MCMC sample size to 1710, ESS to 171.
Iteration 7 of at most 60:
[1] -5.93170439  3.65504596  0.02331422  0.10263278
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0516.
Starting maximum pseudolikelihood estimation (MPLE):
Increasing target MCMC sample size to 1200, ESS to 120.
Evaluating the predictor and response matrix.
Iteration 5 of at most 60:
The log-likelihood improved by 0.1190.
Increasing target MCMC sample size to 1190, ESS to 119.
Iteration 5 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0106.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0847.
Increasing target MCMC sample size to 1850, ESS to 185.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0179.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0231.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.4366976  3.9040347 -0.0277099  0.2013999
[1] -6.02572829  4.29993011  0.00204779 -0.04054160
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0132.
Precision adequate twice. Stopping.
Finished MCMLE.
Finished MPLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0134.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1297.
Increasing target MCMC sample size to 1800, ESS to 180.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1278.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0449.
Increasing target MCMC sample size to 1490, ESS to 149.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0068.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0262.
Increasing target MCMC sample size to 810, ESS to 81.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0451.
Precision adequate. Performing one more iteration.
Optimizing with step length 1.0000.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0119.
Increasing target MCMC sample size to 690, ESS to 69.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0654.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0502.
Optimizing with step length 1.0000.
Increasing target MCMC sample size to 720, ESS to 72.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0289.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0484.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0657.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1538.
Increasing target MCMC sample size to 1270, ESS to 127.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0186.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0216.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0132.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -5.93147372  3.94874755  0.01525255 -0.01052162
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0472.
Increasing target MCMC sample size to 1140, ESS to 114.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0194.
Optimizing with step length 1.0000.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0075.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0257.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.2050.
Increasing target MCMC sample size to 2000, ESS to 200.
Iteration 6 of at most 60:
[1] -6.00433637  4.11056939  0.01133369 -0.05181484
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0326.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0126.
Increasing target MCMC sample size to 700, ESS to 70.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0029.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0081.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -6.18500640  4.09604153  0.02439473 -0.07647270
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0456.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0394.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0460.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -6.12995538  3.97622585  0.03738259Optimizing with step length 1.0000.
 -0.18115577
The log-likelihood improved by 0.0131.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -5.1249784  3.5853770 -0.0250103  0.1507161
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0172.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0348.
Increasing target MCMC sample size to 1130, ESS to 113.
Iteration 5 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0122.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0581.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0520.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0701.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0345.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0306.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0033.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0234.
Increasing target MCMC sample size to 730, ESS to 73.
Iteration 3 of at most 60:
[1] -7.024612503  5.010344756  0.021208284 -0.004699709
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
[1] -6.40411648  4.23648000  0.02729968 -0.00613533
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0085.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0333.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0227.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -6.20571240  4.32861008 -0.01568138  0.20750576
[1] -5.30686465  3.55548138 -0.01307703  0.14429385
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0148.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0373.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0552.
Increasing target MCMC sample size to 1060, ESS to 106.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0095.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0721.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0355.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0868.
Increasing target MCMC sample size to 1280, ESS to 128.
Iteration 6 of at most 60:
[1] -5.42295307  4.34221092 -0.05954866 -0.08272102
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0677.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0381.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1014.
Increasing target MCMC sample size to 730, ESS to 73.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0230.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0058.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.41343844  3.51229846  0.00748196  0.02174012
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0340.
Increasing target MCMC sample size to 1550, ESS to 155.
Iteration 7 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2057.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1144.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0290.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0177.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.453233082  3.843903559 -0.018832653  0.006882252
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0642.
Increasing target MCMC sample size to 840, ESS to 84.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0421.
Increasing target MCMC sample size to 1550, ESS to 155.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0035.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0102.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.90601008  4.09902383 -0.08323056  0.07096352
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0153.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0384.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0370.
Precision adequate. Performing one more iteration.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0099.
Increasing target MCMC sample size to 1040, ESS to 104.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0353.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0773.
Increasing target MCMC sample size to 710, ESS to 71.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0829.
Increasing target MCMC sample size to 1650, ESS to 165.
Iteration 9 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0370.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0190.
Increasing target MCMC sample size to 1640, ESS to 164.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0175.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -6.83262103  4.83834576  0.02714355 -0.09234224
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0288.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 5 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0380.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0214.
Precision adequate. Performing one more iteration.
Iteration 10 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0212.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0162.
Increasing target MCMC sample size to 890, ESS to 89.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0167.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0341.
Increasing target MCMC sample size to 900, ESS to 90.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0155.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0059.
Increasing target MCMC sample size to 1380, ESS to 138.
Iteration 7 of at most 60:
[1] -5.91644468  3.81064356  0.02363387 -0.07385777
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0023.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0277.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0052.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0715.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0506.
Increasing target MCMC sample size to 690, ESS to 69.
Iteration 3 of at most 60:
[1] -6.023203656  4.069339435  0.001613986  0.107966990
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0413.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0115.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0035.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0233.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0975.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -5.73049006  4.11385303 -0.01923534  0.09885021
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0583.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0415.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0587.
Increasing target MCMC sample size to 820, ESS to 82.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0371.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1893.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0132.
The log-likelihood improved by 0.0701.
Precision adequate twice. Stopping.
Increasing target MCMC sample size to 1230, ESS to 123.
Finished MCMLE.
Iteration 5 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.037203900  3.252204208 -0.008147352  0.058300442
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0667.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0159.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0110.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0061.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0108.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0360.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
> 
> ergm_sim_estim_tapered = matrix(0, nrow = nsims, ncol = 4)
> for(i in 1:nsims)
+ {
+   if(!is.null(ergm_sim_list_tapered[[i]]))
+   {
+     est.params <- ergm_sim_list_tapered[[i]]$coefficients
+     ergm_sim_estim_tapered[i,] <- est.params
+   }
+   else {ergm_sim_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
> 
> #### DEGENERACIES
> degen_tapered = which(!complete.cases(ergm_sim_estim_tapered))
> # 58 of em
> degen_tapered
integer(0)
> 
> if(length(degen) > 0 ){
+ degen_list_tapered = ergm_sim_list_tapered[[]]
+ ergm_degen_list_tapered = foreach(i = 1:length(degen_tapered)) %dopar% {
+   skip_to_next <- FALSE
+   formula <- g_sim[[degen[i]]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim_tapered = tryCatch(withTimeout(ergm(formula, eval.loglik=FALSE,
+                                         control=control.ergm(init=theta, MCMLE.confidence=0.95
+                                        #   # MCMC.burnin=100000,
+                                        #   # MCMC.interval=1000,
+                                        #   # MCMC.samplesize = 5000,
+                                           )
+   ), timeout = 5*60, onTimeout = "error"),
+   error = function(e) {skip_to_next <<- NULL})
+   ergm_sim_tapered
+ }
+ 
+ ergm_degen_estim_tapered = matrix(0, nrow = length(degen), ncol = 4)
+ for(i in 1:length(degen_tapered))
+ {
+   if(!is.null(ergm_degen_list_tapered[[i]]))
+   {
+     est.params <- ergm_degen_list_tapered[[i]]$coefficients
+     ergm_degen_estim_tapered[i,] <- est.params
+     ergm_sim_estim_tapered[degen_tapered[i],] <- est.params
+   }
+   else {ergm_degen_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
+ }
> 
> ergm_result_tapered = apply(ergm_sim_estim_tapered, 2, median, na.rm = T)
> ergm_result_tapered
[1] -6.05957646  4.07970283  0.01331636  0.02543921
> 
> # compare mean-values
> g3_tapered = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+ #g3_tapered <- simulate(g_sim[[1]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+ simulate_ergm.tapered(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = ergm_sim_estim_tapered[i,],         
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  365.72  358.97 2759.26  131.63
> ergm_mv_tapered = colMeans(g3_tapered)
> ergm_mv_tapered
      Taper(0.000672043010752688)~edges Taper(0.000684931506849315)~nodematch.x 
                                365.506                                 358.722 
     Taper(8.51208716377256e-05)~kstar2      Taper(0.0016025641025641)~triangle 
                               2756.169                                 131.113 
> 
> # Model statistics ‘kstar2’ and ‘triangle’ are not varying. This may indicate 
> # that the observed data occupies an extreme point in the sample space or that 
> # the estimation has reached a dead-end configuration.
> # Warning: Model statistics ‘nodematch.x’ are linear combinations of some set of 
> # preceding statistics at the current stage of the estimation. This may indicate 
> # that the model is nonidentifiable.
> # Error in ergm.MCMLE(init, nw, model, initialfit = (initialfit <- NULL),  : 
> # Unconstrained MCMC sampling did not mix at all. Optimization cannot continue.
> # In addition: Warning message:
> # In ergm_MCMC_sample(s, control, theta = mcmc.init, verbose = max(verbose -  :
> # Unable to reach target effective size in iterations alotted.
> 
> 
> ##################
> #                #
> #     MFERGM     #
> #                #
> ##################
> 
> # Use "theta" on mfergm instead
> tobs <- data.frame(matrix(NA, ncol = 4, nrow = nsims))
> names(tobs) <- c("edges", "x", "kstar2", "triangles")
> for (i in 1:nsims) 
+ {
+   tobs[i,] = g_sim_stats[i,] / (c((n^2)/2, (n^2)/2, (n^3)/2 , (n^3)/2 ))  
+ }
> 
> ### Compute MFERGM Results
> mfergm_estim = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+   pars <- init_params[i,] * c(.5,.5,n,n)
+   addpars <- list(n=n, tobs = tobs[i,], x=x, ninit=1)
+   cd.est <- tryCatch(optimx(pars, fn = loglikmf.model4, 
+                             method = "BFGS", 
+                             control = list(fnscale = -1), addpars = addpars), 
+                      error = function(e) {return(c(NA, NA, NA, NA))})
+   as.numeric(cd.est[1:4])
+ }
> mfergm_estim = matrix(c(mfergm_estim[,1]*2, mfergm_estim[,2]*2, mfergm_estim[,3]/n, mfergm_estim[,4]/n),
+                nrow = nsims)
> mfergm_result_med = apply(mfergm_estim, 2, median, na.rm = T) 
> mfergm_result = apply(mfergm_estim, 2, median, na.rm = T) 
> cbind(theta,mfergm_result_med,mfergm_result)
     theta mfergm_result_med mfergm_result
[1,] -6.00      -5.921448017  -5.921448017
[2,]  4.00       4.213359700   4.213359700
[3,]  0.01       0.006832070   0.006832070
[4,]  0.03       0.003718891   0.003718891
> 
> #### DEGENERACIES
> degen_mfergm = which(!complete.cases(mfergm_estim))
> # 58 of em
> degen_mfergm
[1]  8 21 37
> 
> if(length(degen_mfergm) > 0){
+ # Replace with MPLE
+ for(i in 1:length(degen_mfergm)){
+   mfergm_estim[degen_mfergm[i],] <- init_params[degen_mfergm[i],]
+ }
+ }
> 
> mfergm_estim_bd <- mfergm_estim
> for(i in 1:nsims){
+  a = mfergm_estim_bd[i,] < ergm_q[1,]
+  mfergm_estim_bd[i,a] <- ergm_q[1,a]
+  a = mfergm_estim_bd[i,] > ergm_q[2,]
+  mfergm_estim_bd[i,a] <- ergm_q[2,a]
+ }
> 
> # compare mean values
> g5 = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = init_params[i,],    
+                output = "stats"
+ )
+ }
> MPLE_mv = colMeans(g5)
> MPLE_result = apply(init_params, 2, median, na.rm = T) 
> 
> # compare mean values
> g4 = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = mfergm_estim_bd[i,],    
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  365.72  358.97 2759.26  131.63
> mfergm_mv = colMeans(g4)
> mfergm_mv
      edges nodematch.x      kstar2    triangle 
    454.744     428.623    7778.057    1236.261 
> 
> a <- cbind(theta, ergm_result, ergm_result_tapered, MPLE_result, mfergm_result)
> rownames(a) <- names(ergm_mv)
> colnames(a) <- c("true", "MCMC-MLE","Tapered","MPLE","MFVLE")
> a
             true    MCMC-MLE     Tapered        MPLE        MFVLE
edges       -6.00 -6.04579868 -6.05957646 -6.02446597 -5.921448017
nodematch.x  4.00  4.08533562  4.07970283  4.08422082  4.213359700
kstar2       0.01  0.01081382  0.01331636  0.00856999  0.006832070
triangle     0.03  0.01527323  0.02543921  0.01554592  0.003718891
> 
> # compare mfergm result with "theta"
> theta
[1] -6.00  4.00  0.01  0.03
> ergm_result
[1] -6.04579868  4.08533562  0.01081382  0.01527323
> ergm_result_tapered
[1] -6.05957646  4.07970283  0.01331636  0.02543921
> mfergm_result
[1] -5.921448017  4.213359700  0.006832070  0.003718891
> 
> 
> # results for report
> round(theta, 3) 
[1] -6.00  4.00  0.01  0.03
> round(colMeans(g_sim_stats), 2)
[1]  365.72  358.97 2759.26  131.63
> round(colMeans(init_params), 3)
[1] -6.059  4.143  0.006  0.016
> round(ergm_result, 3) 
[1] -6.046  4.085  0.011  0.015
> round(ergm_mv, 2) 
      edges nodematch.x      kstar2    triangle 
     366.35      359.58     2764.27      132.17 
> round(ergm_result_tapered, 3) 
[1] -6.060  4.080  0.013  0.025
> round(ergm_mv_tapered, 2) 
      Taper(0.000672043010752688)~edges Taper(0.000684931506849315)~nodematch.x 
                                 365.51                                  358.72 
     Taper(8.51208716377256e-05)~kstar2      Taper(0.0016025641025641)~triangle 
                                2756.17                                  131.11 
> round(mfergm_result, 3) 
[1] -5.921  4.213  0.007  0.004
> round(mfergm_mv, 2) 
      edges nodematch.x      kstar2    triangle 
     454.74      428.62     7778.06     1236.26 
> # / c(2,2,1/n,1/n)
> 
> 
> a <- cbind(round(colMeans(g_sim_stats), 2), round(ergm_mv, 2), round(ergm_mv_tapered,2), round(MPLE_mv,2), round(mfergm_mv, 2))
> rownames(a) <- names(ergm_mv)
> colnames(a) <- c("true", "MCMC-MLE","Tapered","MPLE", "MFVLE")
> a
               true MCMC-MLE Tapered    MPLE   MFVLE
edges        365.72   366.35  365.51  365.40  454.74
nodematch.x  358.97   359.58  358.72  358.80  428.62
kstar2      2759.26  2764.27 2756.17 2757.74 7778.06
triangle     131.63   132.17  131.11  132.14 1236.26
> 
> # save.image("mfergm_params1_n100.RData")
> 
> hist(ergm_sim_estim[,4], main = NULL, xlab = "Triangle")
> hist(ergm_sim_estim_tapered[,4], main = NULL, xlab = "Triangle")
> hist(mfergm_estim[,4], main = NULL, xlab = "Triangle")
> 
> 
> outliers <- function(x, field = 1.5, na.rm = TRUE) 
+ {
+   qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm)
+   H <- field * IQR(x, na.rm = na.rm)
+   which(x < (qnt[1] - H) | x > (qnt[2] + H))
+ }
> 
> 
> 
> a  = is.na(ergm_sim_estim[,4])
> b  = is.na(mfergm_estim[,4])
> c = mfergm_estim[(!a)&(!b),]
> c1 = c[,4]
> d = ergm_sim_estim[(!a)&(!b),]
> d1 = d[,4]
> c1[c1 < -2] = d1[c1 < -2]
> plot(c1~d1, col = (c1 == d1) + 1, pch = 16)
> sum(c1 == d1)
[1] 3
> 
> f = c[-Reduce(union, list(outliers(c[,1], 0.6), outliers(c[,2], 0.3), outliers(c[,3], 1.5), outliers(c[,4], 1.5))),]
> 
> 
> 
> gtest_mf = matrix(nrow = nrow(c), ncol = 4)
> for (i in 1:nrow(c))
+ {
+   gtest_mf[i,] = simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1, 
+                           coef = c[i,],        
+                           output = "stats")
+ }
> gtest_mc = matrix(nrow = nrow(d), ncol = 4)
> for (i in 1:nrow(d))
+ {
+   gtest_mc[i,] = simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1, 
+                           coef = d[i,],        
+                           output = "stats")
+ }
> gtest_mc_tapered = matrix(nrow = nrow(d), ncol = 4)
> for (i in 1:nrow(d))
+ {
+   gtest_mc_tapered[i,] = as.vector(simulate_ergm.tapered(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1, 
+                           coef = d[i,],        
+                           output = "stats"))
+ }
> colMeans(gtest_mf)
[1]   664.46   550.43 14397.28  1978.85
> colMeans(gtest_mc)
[1]  365.14  358.52 2739.00  129.00
> colMeans(gtest_mc_tapered)
[1]  365.42  358.79 2744.60  129.93
> 
> summary(ergm_sim_estim)
       V1               V2              V3                  V4          
 Min.   :-7.593   Min.   :3.161   Min.   :-0.076660   Min.   :-0.38897  
 1st Qu.:-6.413   1st Qu.:3.862   1st Qu.:-0.006005   1st Qu.:-0.05238  
 Median :-6.046   Median :4.085   Median : 0.010814   Median : 0.01527  
 Mean   :-6.069   Mean   :4.141   Mean   : 0.006801   Mean   : 0.01408  
 3rd Qu.:-5.686   3rd Qu.:4.389   3rd Qu.: 0.021312   3rd Qu.: 0.09694  
 Max.   :-4.960   Max.   :5.970   Max.   : 0.041611   Max.   : 0.26081  
> summary(gtest_mf)
       V1               V2               V3              V4         
 Min.   :  36.0   Min.   :   0.0   Min.   :    5   Min.   :    0.0  
 1st Qu.: 343.5   1st Qu.: 296.5   1st Qu.: 2420   1st Qu.:   84.0  
 Median : 420.0   Median : 393.0   Median : 3674   Median :  179.5  
 Mean   : 664.5   Mean   : 550.4   Mean   :14397   Mean   : 1978.8  
 3rd Qu.: 814.5   3rd Qu.: 695.0   3rd Qu.:12906   3rd Qu.:  880.0  
 Max.   :2120.0   Max.   :2120.0   Max.   :91028   Max.   :25412.0  
> summary(gtest_mc)
       V1              V2              V3             V4       
 Min.   :310.0   Min.   :304.0   Min.   :1931   Min.   : 65.0  
 1st Qu.:345.0   1st Qu.:339.8   1st Qu.:2394   1st Qu.:102.8  
 Median :361.5   Median :355.0   Median :2647   Median :127.0  
 Mean   :365.1   Mean   :358.5   Mean   :2739   Mean   :129.0  
 3rd Qu.:380.0   3rd Qu.:376.0   3rd Qu.:3055   3rd Qu.:148.0  
 Max.   :441.0   Max.   :430.0   Max.   :4120   Max.   :246.0  
> summary(g_sim_stats)
       V1              V2            V3             V4       
 Min.   :319.0   Min.   :312   Min.   :2061   Min.   : 76.0  
 1st Qu.:352.0   1st Qu.:345   1st Qu.:2546   1st Qu.:114.0  
 Median :366.0   Median :359   Median :2766   Median :135.0  
 Mean   :365.7   Mean   :359   Mean   :2759   Mean   :131.6  
 3rd Qu.:378.0   3rd Qu.:371   3rd Qu.:2965   3rd Qu.:150.0  
 Max.   :410.0   Max.   :404   Max.   :3433   Max.   :188.0  
> 
> 
> gtest_mf_tri = gtest_mf[gtest_mf[,4]<60, 4]
> 
> hist(ergm_sim_estim[,1])
> hist(ergm_sim_estim[,2])
> hist(ergm_sim_estim[,3])
> hist(ergm_sim_estim[,4])
> hist(f[,1])
> hist(f[,2])
> hist(f[,3])
> hist(f[,4])
> 
> 
> gtest_mf_rm = gtest_mf[-Reduce(union, list(outliers(gtest_mf[,1], 0.7), outliers(gtest_mf[,2], 1), 
+                                            outliers(gtest_mf[,3], 0.001), outliers(gtest_mf[,4], 0.001))),]
> hist(gtest_mf[,1])
> hist(gtest_mf[,2])
> hist(gtest_mf[,3])
> hist(gtest_mf[,4])
> 
> hist(ergm_sim_estim_tapered[,1])
> hist(ergm_sim_estim_tapered[,2])
> hist(ergm_sim_estim_tapered[,3])
> hist(ergm_sim_estim_tapered[,4])
> 
> 
> 
> 
> 
> 
> 
> complete_mf_results = mfergm_estim[complete.cases(mfergm_estim),]
> complete_mcmc_results = ergm_sim_estim[complete.cases(ergm_sim_estim),]
> complete_tapered_results = ergm_sim_estim_tapered[complete.cases(ergm_sim_estim_tapered),]
> 
> 
> # Degeneracy
> length(intersect(which(is.na(mfergm_estim[,1])), which(is.na(ergm_sim_estim[,1]))))
[1] 0
> 
> # MFERGM RMSE
> 
> # mf
> outliers1 = outliers((complete_mf_results[,1] - theta[1])^2)
> outliers2 = outliers((complete_mf_results[,2] - theta[2])^2)
> outliers3 = outliers((complete_mf_results[,3] - theta[3])^2)
> outliers4 = outliers((complete_mf_results[,4] - theta[4])^2)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> mf_rmse1 = sqrt(sum(((complete_mf_results[,1] - theta[1])^2)[-outliers1]))
> mf_rmse2 = sqrt(sum(((complete_mf_results[,2] - theta[2])^2)[-outliers2]))
> mf_rmse3 = sqrt(sum(((complete_mf_results[,3] - theta[3])^2)[-outliers3]))
> mf_rmse4 = sqrt(sum(((complete_mf_results[,4] - theta[4])^2)[-outliers4]))
> c(mf_rmse1, mf_rmse2, mf_rmse3, mf_rmse4)
[1] 10.9209310  9.3418029  0.2398147  0.9862750
> 
> # mcmc
> outliers1 = outliers((complete_mcmc_results[,1] - theta[1])^2)
> outliers2 = outliers((complete_mcmc_results[,2] - theta[2])^2)
> outliers3 = outliers((complete_mcmc_results[,3] - theta[3])^2)
> outliers4 = outliers((complete_mcmc_results[,4] - theta[4])^2)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> mcmc_rmse1 = sqrt(sum(((complete_mcmc_results[,1] - theta[1])^2)[-outliers1]))
> mcmc_rmse2 = sqrt(sum(((complete_mcmc_results[,2] - theta[2])^2)[-outliers2]))
> mcmc_rmse3 = sqrt(sum(((complete_mcmc_results[,3] - theta[3])^2)[-outliers3]))
> mcmc_rmse4 = sqrt(sum(((complete_mcmc_results[,4] - theta[4])^2)[-outliers4]))
> c(mcmc_rmse1, mcmc_rmse2, mcmc_rmse3, mcmc_rmse4)
[1] 3.9728848 3.1662057 0.1558789 0.7977499
> 
> plot((complete_mf_results[,1] - theta[1])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,2] - theta[2])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,3] - theta[3])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,4] - theta[4])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,1] - theta[1])^2)[-outliers1], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,2] - theta[2])^2)[-outliers2], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,3] - theta[3])^2)[-outliers3], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,4] - theta[4])^2)[-outliers4], pch = 19, ylab = "", xlab = "Simulated Networks")
> 
> 
> outliers1 = head(order((complete_mf_results[,1] - theta[1])^2, decreasing = T), n = 100)
> outliers2 = head(order((complete_mf_results[,2] - theta[2])^2, decreasing = T), n = 100)
> outliers3 = head(order((complete_mf_results[,3] - theta[3])^2, decreasing = T), n = 100)
> outliers4 = head(order((complete_mf_results[,4] - theta[4])^2, decreasing = T), n = 100)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> 
> 
> plot(density(complete_mf_results[,1]), main = "")
> plot(density(complete_mf_results[,2]), main = "")
> plot(density(complete_mf_results[,3]), main = "")
> plot(density(complete_mf_results[,4]), main = "")
> 
> 
> 
> # MAD
> 
> mcmc_mad = matrix(nrow = nrow(complete_mcmc_results), ncol = 4)
> for (i in 1:nrow(complete_mcmc_results))
+ {
+   mcmc_mad[i,] = abs(complete_mcmc_results[i,] - theta)
+ }
> round(apply(mcmc_mad, 2, median), 3)
[1] 0.338 0.289 0.013 0.074
> 
> mf_mad = matrix(nrow = nrow(complete_mf_results), ncol = 4)
> for (i in 1:nrow(complete_mf_results))
+ {
+   mf_mad[i,] = abs(complete_mf_results[i,] - theta)
+ }
> round(apply(mf_mad, 2, median), 3)
[1] 0.806 0.703 0.021 0.092
> 
> stopImplicitCluster()
> 
> save.image("mfergm_params1_n1000.RData")
> 
> 
> proc.time()
   user  system elapsed 
612.540  36.933 109.814 
