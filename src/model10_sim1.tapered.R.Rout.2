> rm(list=ls())
> my.seed=2
> set.seed(my.seed)
> 
> pdf("model10_sim1.tapered.pdf")
> 
> library(ergm)
Loading required package: network

‘network’ 1.18.0 (2022-10-05), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information


‘ergm’ 4.3-6983 (2022-08-20), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(doRNG)
Loading required package: foreach
Loading required package: rngtools
> library(mfergm)
> library(optimx)     # mfergm likelihood
> library(R.utils)    # set time on ergm
Loading required package: R.oo
Loading required package: R.methodsS3
R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.
R.oo v1.25.0 (2022-06-12 02:20:02 UTC) successfully loaded. See ?R.oo for help.

Attaching package: ‘R.oo’

The following object is masked from ‘package:R.methodsS3’:

    throw

The following objects are masked from ‘package:methods’:

    getClasses, getMethods

The following objects are masked from ‘package:base’:

    attach, detach, load, save

R.utils v2.12.0 (2022-06-28 03:20:05 UTC) successfully loaded. See ?R.utils for help.

Attaching package: ‘R.utils’

The following object is masked from ‘package:utils’:

    timestamp

The following objects are masked from ‘package:base’:

    cat, commandArgs, getOption, isOpen, nullfile, parse, warnings

> library(doParallel) # parallel loops using 'foreach'
Loading required package: iterators
Loading required package: parallel
> 
> #####################################################################
> #                                                                   #
> #     Create High Transitivity ERGM Params (using ERGM fitting)     #
> #                                                                   #
> #####################################################################
> 
> nsims       =  200                               # number of networks simulated
> n           =  100                               # number of nodes
> mv_1 <- c(400.31, 349.88, 3254.42,     126.28)   # mean-value parameters standard model
> mv_1 <- c(393.0512, 341.0188, 3092.0576, 117.4754) # Long-run estimate
> theta       =  c(-2,1,1,1) * c(2,2,1/n,1/n)      # true parameters for model 2
> ##################
> #                #
> #     Set-up     #
> #                #
> ##################
> 
> g <- initialize.network(theta, n, directed = FALSE)
> x <- rbinom(n, 1, 0.5) # attributes
> set.vertex.attribute(g, # the name of the network object
+                      "x", # the name we want to reference the variable by in that object
+                      x # the value we are giving that variable
+ ) 
> 
> formula <- g ~ edges + nodematch("x") + kstar(2) + triangles
> names(mv_1) <- names(summary(formula))
> 
> load("sim10.RData")
> theta
[1] -4.00  2.00  0.01  0.01
> set.seed(my.seed)
> registerDoParallel(10)
> a = foreach(i = 1:10) %dorng% {
+  simulate(sim ~ edges + nodematch("x") + kstar(2) + triangles, 
+                   nsim = nsims,
+                   coef = theta,
+ 		  control=control.simulate.formula(MCMC.burnin=1000000, MCMC.interval=100000)
+                               )
+ }
> sim <- a[[1]][[nsims]]
> g_sim <- NULL
> for(i in 1:10){
+   g_sim <- c(g_sim, a[[i]])
+ }
> rm(a)
> #save(sim, file="sim10.RData")
> 
> # Extract summary stats from 'g_sim'
> g_sim_stats = foreach(i = 1:(nsims), .combine = rbind) %dorng% {
+  as.vector(summary_formula(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles))
+ }
> 
> a = foreach(i = 2:10, .combine = rbind) %dorng% {
+  simulate(sim ~ edges + nodematch("x") + kstar(2) + triangles, 
+                   nsim = nsims,
+                   coef = theta,
+                   output = "stats",
+ 		  control=control.simulate.formula(MCMC.burnin=1000000, MCMC.interval=100000)
+                               )
+ }
> rm(a)
> 
> pairs(g_sim_stats)
> dev.off()
null device 
          1 
> 
> mv_s <- apply(g_sim_stats,2,mean)
> mv_s
[1]  397.135  344.700 3161.690  120.560
> #names(mv_s) <- names(fit$tapering.coefficients)
> names(mv_s) <- c("edges", "x", "kstar2", "triangles")
> cbind(mv_1, mv_s)
                 mv_1     mv_s
edges        393.0512  397.135
nodematch.x  341.0188  344.700
kstar2      3092.0576 3161.690
triangle     117.4754  120.560
> 
> mv_s <- mv_1
> 
> t.test(g_sim_stats[,2], mu=mv_1[2])

	One Sample t-test

data:  g_sim_stats[, 2]
t = 2.4543, df = 199, p-value = 0.01498
alternative hypothesis: true mean is not equal to 341.0188
95 percent confidence interval:
 341.7423 347.6577
sample estimates:
mean of x 
    344.7 

> t.test(g_sim_stats[,3], mu=mv_1[3])

	One Sample t-test

data:  g_sim_stats[, 3]
t = 2.7904, df = 199, p-value = 0.005776
alternative hypothesis: true mean is not equal to 3092.058
95 percent confidence interval:
 3112.482 3210.898
sample estimates:
mean of x 
  3161.69 

> t.test(g_sim_stats[,4], mu=mv_1[4])

	One Sample t-test

data:  g_sim_stats[, 4]
t = 1.8764, df = 199, p-value = 0.06206
alternative hypothesis: true mean is not equal to 117.4754
95 percent confidence interval:
 117.3184 123.8016
sample estimates:
mean of x 
   120.56 

> #q()
> # Initialize the parameters at MPLE
> #init_params = matrix(nrow = nsims, ncol = length(theta))
> init_params = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+   ergm(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles, 
+                estimate = "MPLE")$coefficients
+ }
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 







Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Evaluating log-likelihood at the estimate. 

Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 

Stopping at the initial estimate.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 


Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Finished MPLE.
Finished MPLE.

Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Finished MPLE.

Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.


Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 

Evaluating log-likelihood at the estimate. Finished MPLE.


Stopping at the initial estimate.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Finished MPLE.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.

Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 



Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.

Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 

Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Finished MPLE.
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.

Stopping at the initial estimate.
Finished MPLE.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.

Finished MPLE.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Finished MPLE.

Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 




Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Finished MPLE.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.

Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 


Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Finished MPLE.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.

Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Finished MPLE.


Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Finished MPLE.

Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Finished MPLE.


Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating the predictor and response matrix.

Finished MPLE.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.

Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Finished MPLE.
Stopping at the initial estimate.


Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Finished MPLE.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):

Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Finished MPLE.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.



Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.

Finished MPLE.


Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.

Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 


Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):

Finished MPLE.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 



Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):

Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Finished MPLE.

Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.
Finished MPLE.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 

Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Stopping at the initial estimate.



Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Finished MPLE.

Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Finished MPLE.

Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.
Finished MPLE.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Stopping at the initial estimate.


Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.

Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 

Evaluating log-likelihood at the estimate. 


Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.

Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Finished MPLE.
Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Finished MPLE.

Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 

Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Finished MPLE.
Evaluating the predictor and response matrix.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Finished MPLE.
Maximizing the pseudolikelihood.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Maximizing the pseudolikelihood.


Finished MPLE.

Finished MPLE.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Stopping at the initial estimate.

Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.

Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.

Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Finished MPLE.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Maximizing the pseudolikelihood.

Finished MPLE.
Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.

Evaluating log-likelihood at the estimate. Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.
Starting maximum pseudolikelihood estimation (MPLE):
Stopping at the initial estimate.
Evaluating the predictor and response matrix.

Evaluating log-likelihood at the estimate. 
Stopping at the initial estimate.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.

Evaluating log-likelihood at the estimate. Maximizing the pseudolikelihood.

Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.

Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Finished MPLE.
Evaluating log-likelihood at the estimate. Finished MPLE.

Maximizing the pseudolikelihood.

Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. Stopping at the initial estimate.


Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Evaluating log-likelihood at the estimate. Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. Evaluating log-likelihood at the estimate. 
Evaluating log-likelihood at the estimate. 


> 
> ##########################
> #                        #
> #     ERGM (Default)     #
> #                        #
> ##########################
> 
> ### Compute ERGM Results
> #stopImplicitCluster()
> #registerDoParallel(5)
> 
> ### Compute ERGM Results
> ergm_sim_list_tapered = foreach(i = 1:nsims) %dorng% {
+   # cat("***********************************\n")
+   # cat(paste("estimating sample" ,i, "\n"))
+   # cat("***********************************\n")
+   skip_to_next <- FALSE
+   formula <- g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = 
+     tryCatch(withTimeout(
+                           ergm(formula, eval.loglik=FALSE,
+                                control=control.ergm(init = init_params[i,], MCMC.samplesize=10000)),
+                timeout = 5*60, onTimeout = "error"),
+                error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0106.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0095.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0575.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0037.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0287.
The log-likelihood improved by 0.1372.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
The log-likelihood improved by 0.0773.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
Iteration 1 of at most 60:
Iteration 1 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0267.
The log-likelihood improved by 0.0700.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: < 0.0001. Iteration 1 of at most 60:
Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0024.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0109.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0183.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0366.
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0175.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1921.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0022.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0031.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0764.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0423.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0171.
The log-likelihood improved by 0.0110.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1445.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0191.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0127.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0051.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0122.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0480.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0083.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0014.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0030.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0028.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0114.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0157.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0520.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0234.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0149.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0124.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0639.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0206.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0069.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0036.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0967.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0171.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0121.
The log-likelihood improved by 0.0008.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0738.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0011.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0179.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0302.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0100.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1847.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0604.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0071.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0099.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0045.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0146.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0129.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0011.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0212.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0241.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1453.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0106.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0116.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0078.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2584.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0031.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0378.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0139.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0294.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0230.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0349.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0005.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0050.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0589.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0294.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0027.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Optimizing with step length 1.0000.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0990.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0138.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0053.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1230.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0033.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0094.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0016.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0033.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0080.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0046.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0233.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0095.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0054.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1982.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0146.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0016.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0081.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0243.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0074.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0094.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0231.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0107.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0247.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0094.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0006.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0289.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0070.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0340.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0114.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0040.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0110.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0090.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1358.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0048.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0016.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0069.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0140.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0203.
The log-likelihood improved by 0.0445.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0033.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0014.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0133.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0038.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0146.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0254.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0290.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0551.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0032.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0510.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1034.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0012.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0146.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0455.
Optimizing with step length 1.0000.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0061.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0253.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0195.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0016.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0188.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0068.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0279.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2423.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0122.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0012.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0651.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0249.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0379.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0158.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0094.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0360.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1086.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0028.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0091.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0204.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0244.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1204.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0016.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0170.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0020.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0428.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0047.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0280.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0039.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0022.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0661.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0090.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0088.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0286.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0226.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0038.
The log-likelihood improved by 0.0288.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0176.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0010.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0226.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0072.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0144.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1145.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0277.
The log-likelihood improved by 0.1214.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0063.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0890.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0005.
The log-likelihood improved by 0.1580.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0329.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0068.
The log-likelihood improved by 0.0340.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0035.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0194.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0052.
Convergence test p-value: < 0.0001. The log-likelihood improved by 0.0027.
Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0437.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1163.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0056.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0165.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0098.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0050.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0168.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0157.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0023.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0996.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0014.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0165.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0110.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0243.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0151.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0049.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0014.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0046.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0054.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0369.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0042.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0808.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0263.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0045.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0997.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0470.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0321.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0022.
Convergence test p-value: < 0.0001. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
> 
> ergm_sim_estim_tapered = matrix(0, nrow = nsims, ncol = 4)
> for(i in 1:nsims)
+ {
+   if(!is.null(ergm_sim_list_tapered[[i]]))
+   {
+     est.params <- ergm_sim_list_tapered[[i]]$coefficients
+     ergm_sim_estim_tapered[i,] <- est.params
+   }
+   else {ergm_sim_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
> 
> #### DEGENERACIES
> degen_tapered = which(!complete.cases(ergm_sim_estim_tapered))
> # 58 of em
> degen_tapered
integer(0)
> 
> if(length(degen_tapered) > 0 ){
+ #degen_list_tapered = ergm_sim_list_tapered[[]]
+ #ergm_degen_list_tapered = foreach(i = 1:length(degen_tapered)) %dorng% {
+ #  skip_to_next <- FALSE
+ #  formula <- g_sim[[degen_tapered[i]]] ~ edges + nodematch("x") + kstar(2) + triangles
+ #  ergm_sim_tapered = tryCatch(withTimeout(ergm(formula, eval.loglik=FALSE,
+ #                                        control=control.ergm(init=theta, MCMLE.confidence=0.95
+ #                                       #   # MCMC.burnin=100000,
+ #                                       #   # MCMC.interval=1000,
+ #                                       #   # MCMC.samplesize = 5000,
+ #                                          )
+ #  ), timeout = 5*60, onTimeout = "error"),
+ #  error = function(e) {skip_to_next <<- NULL})
+ #  ergm_sim_tapered
+ #}
+ #ergm_degen_list_tapered
+ 
+ ergm_degen_estim_tapered = matrix(0, nrow = length(degen_tapered), ncol = 4)
+ for(i in 1:length(degen_tapered))
+ {
+  #if(!is.null(ergm_degen_list_tapered[[i]]))
+  #{
+    # est.params <- ergm_degen_list_tapered[[i]]$coefficients
+    # ergm_degen_estim_tapered[i,] <- est.params
+    # ergm_sim_estim_tapered[degen_tapered[i],] <- est.params
+      ergm_sim_estim_tapered[degen_tapered[i],] <- init_params[degen_tapered[i],]
+  #}
+  #else {ergm_degen_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
+ }
> 
> ergm_result_tapered = apply(ergm_sim_estim_tapered, 2, mean, na.rm = T)
> ergm_result_tapered
[1] -3.97025817  2.02677094  0.00811981 -0.01274581
> 
> ergm_sim_estim_tapered
            [,1]     [,2]          [,3]          [,4]
  [1,] -4.123273 2.122821  1.672193e-02  0.0190018737
  [2,] -4.863452 2.393446  5.091072e-02 -0.1115295217
  [3,] -3.544941 1.764089 -1.869496e-02  0.0882669241
  [4,] -3.881428 2.016143  1.372218e-02 -0.2149055598
  [5,] -3.209543 1.640048 -2.120789e-02  0.0008535713
  [6,] -4.319490 2.105970  2.681850e-02 -0.0207689899
  [7,] -4.136046 2.081012  2.071491e-02 -0.0772993295
  [8,] -4.013866 1.860253  1.718643e-02  0.0105472786
  [9,] -3.702188 1.979332  1.429834e-03 -0.0079173652
 [10,] -3.264133 1.804591 -2.825955e-02  0.1828330029
 [11,] -3.744714 2.263860 -2.452658e-02 -0.0128465003
 [12,] -4.277214 2.104861  2.842905e-02 -0.0829765787
 [13,] -3.366605 1.704021 -1.444769e-02  0.1029354944
 [14,] -4.444843 2.389420  3.323821e-02 -0.2983016710
 [15,] -4.013859 2.159617  1.075076e-02 -0.1311641107
 [16,] -4.454324 2.282042  3.411695e-02 -0.1580929448
 [17,] -3.925775 1.955796 -1.417247e-02  0.2839884254
 [18,] -4.243035 2.006190  2.294233e-02  0.0719548227
 [19,] -4.567702 2.399499  4.265166e-02 -0.3306341691
 [20,] -3.930457 2.068183  1.845588e-03 -0.0895872027
 [21,] -4.303790 1.935065  3.885539e-02 -0.0992293509
 [22,] -3.784195 1.776315  6.571715e-04  0.0370223363
 [23,] -4.054574 1.873594  1.148540e-02  0.0961167882
 [24,] -3.999360 2.029151  1.297194e-02 -0.0408076413
 [25,] -3.637448 2.088093 -2.687531e-02  0.1719805601
 [26,] -4.169301 1.892335  3.086740e-02 -0.0396580791
 [27,] -4.295228 2.143451  2.629941e-02 -0.0054586105
 [28,] -4.004709 2.021460  9.525641e-03  0.0288335024
 [29,] -4.205072 2.219057  1.075527e-02 -0.0570096734
 [30,] -4.172096 2.111292  9.732186e-03 -0.0048914821
 [31,] -3.463512 2.125649 -3.936261e-02  0.1614373721
 [32,] -4.337439 2.216535  2.815069e-02 -0.0928032744
 [33,] -3.900562 2.071502  9.715910e-04  0.0711810107
 [34,] -3.937375 1.719284  1.796749e-02  0.0230620590
 [35,] -4.472285 2.265994  3.681523e-02 -0.1691291001
 [36,] -4.280075 2.097221  1.737150e-02 -0.0642502965
 [37,] -3.990204 1.912372  1.059369e-02  0.0703533822
 [38,] -4.085580 1.902414  2.132723e-02 -0.0935679095
 [39,] -4.237337 2.004649  2.996657e-02 -0.1704791712
 [40,] -4.942192 2.413911  5.710412e-02 -0.1637211709
 [41,] -3.761640 2.249964 -2.362569e-02  0.1236131110
 [42,] -4.001628 1.881507  2.558671e-02 -0.0788206378
 [43,] -4.148198 2.072354  1.377864e-02 -0.0050997264
 [44,] -3.874442 2.078877  3.728629e-03 -0.0954208996
 [45,] -3.786860 1.934882 -5.552412e-03  0.1188934726
 [46,] -3.919737 1.728614  1.876581e-02  0.0310387918
 [47,] -3.813106 1.955743 -5.872730e-03  0.1467357484
 [48,] -3.104158 1.707210 -4.229898e-02  0.0080365456
 [49,] -4.354674 2.120333  1.291630e-02  0.0991856298
 [50,] -3.899597 2.041512  9.582258e-03 -0.0743796390
 [51,] -3.677825 1.947727 -1.007776e-02 -0.0584856356
 [52,] -4.018098 1.833703  1.114367e-02  0.1414694359
 [53,] -4.010299 1.950092  1.729183e-02 -0.0152254033
 [54,] -4.142012 1.910243  3.058498e-02 -0.0896265453
 [55,] -4.070545 2.018455  2.682112e-02 -0.0962764593
 [56,] -4.109530 2.140841  1.176240e-02 -0.1251893612
 [57,] -3.895243 1.930070  1.083442e-02  0.0108931234
 [58,] -3.380885 1.884896 -2.738073e-02  0.0125517707
 [59,] -4.097103 1.880729  2.236526e-02 -0.0151975481
 [60,] -3.842644 2.080242 -7.563009e-04 -0.0185653883
 [61,] -3.925971 2.025271  1.371426e-02 -0.1789870039
 [62,] -4.306334 2.095375  2.898800e-02 -0.1599811775
 [63,] -4.128265 1.779920  3.941447e-02 -0.1772823305
 [64,] -4.440988 2.139235  4.006386e-02 -0.1328792075
 [65,] -3.214596 2.028091 -3.851838e-02 -0.0050352308
 [66,] -4.415375 2.239532  3.305118e-02 -0.1744180262
 [67,] -3.879391 2.236384 -6.924085e-03  0.0219680589
 [68,] -3.922410 1.974403  9.091500e-03 -0.0707150964
 [69,] -4.066807 1.846536  2.819823e-02 -0.0452962125
 [70,] -4.204067 1.873683  3.189563e-02 -0.0757864094
 [71,] -4.594414 2.303677  3.868755e-02 -0.1502749935
 [72,] -3.730776 2.106369 -6.042902e-03  0.0412700415
 [73,] -3.429454 1.717050 -1.988321e-02  0.2663792372
 [74,] -4.179610 1.918853  3.075207e-02 -0.0518176477
 [75,] -3.654067 1.814512 -1.859785e-02  0.0717594537
 [76,] -4.318989 1.817305  4.099018e-02 -0.0185280521
 [77,] -4.098287 2.288739  2.007200e-04  0.0478675224
 [78,] -4.002765 2.291596 -8.588484e-05 -0.0268151653
 [79,] -3.560567 1.940503 -5.384611e-03 -0.0275843192
 [80,] -4.041362 2.170627  9.482395e-03 -0.0511206984
 [81,] -3.836929 2.056721 -7.260223e-03  0.0991930706
 [82,] -4.084796 2.068332  1.297920e-02  0.0323433923
 [83,] -4.187803 1.994312  2.820679e-02 -0.0846989473
 [84,] -4.091259 1.925255  2.639910e-02 -0.0881006794
 [85,] -4.304631 1.980037  2.780953e-02  0.0417918940
 [86,] -4.167386 2.311583  6.171577e-04 -0.0131465718
 [87,] -3.819649 2.160654  4.215982e-03 -0.1203864353
 [88,] -4.085522 2.251729 -1.559454e-03 -0.0028733419
 [89,] -4.026429 1.774433  2.627406e-02 -0.0393136800
 [90,] -3.880873 1.983870  9.714256e-03 -0.1254790672
 [91,] -3.612562 1.586793  9.585766e-03 -0.0747650159
 [92,] -4.059253 1.987980  1.712847e-02 -0.0034568395
 [93,] -4.099566 2.106764  1.135368e-02 -0.0026467282
 [94,] -3.654670 1.482248  2.220100e-02 -0.0603807495
 [95,] -3.903618 1.845711  1.374610e-02  0.0110523187
 [96,] -4.807529 2.227268  5.513731e-02 -0.1164854819
 [97,] -3.790564 1.912289  1.557786e-03 -0.0002236567
 [98,] -3.641917 2.122078 -1.341479e-02 -0.1171880702
 [99,] -4.150824 2.316685  3.470903e-03  0.0534543860
[100,] -4.615679 2.248011  4.129667e-02 -0.1493441667
[101,] -4.235179 2.015236  2.397772e-02 -0.0221028241
[102,] -3.478372 1.883153 -1.976597e-02  0.0646298939
[103,] -3.647936 1.848777 -4.641303e-03  0.0769464948
[104,] -3.096798 1.873347 -4.639061e-02  0.0733843835
[105,] -3.523438 2.000660 -2.450889e-02  0.0817597418
[106,] -4.194725 2.266166  9.171810e-03  0.0288780359
[107,] -4.014751 1.722010  1.559495e-02  0.1709079241
[108,] -3.869952 1.772547  9.212185e-03  0.0185670323
[109,] -4.437447 1.890723  4.795901e-02 -0.0658779424
[110,] -4.042410 2.052695  9.312462e-03 -0.0138718102
[111,] -3.875076 1.960077  3.669114e-03  0.0427261118
[112,] -4.232984 2.057855  2.308089e-02 -0.0293808748
[113,] -4.146165 1.954001  2.874081e-02 -0.0933930569
[114,] -4.201269 2.245379  2.271201e-02 -0.1148425138
[115,] -3.872660 2.046270  5.550111e-03 -0.0621862261
[116,] -4.352686 2.034503  3.532532e-02 -0.0438154411
[117,] -4.072789 2.160193  1.845085e-02 -0.1286987072
[118,] -3.847893 1.954481  4.271110e-03 -0.0801029004
[119,] -3.392157 2.097453 -2.541248e-02  0.0028098780
[120,] -4.119685 2.136443  1.504976e-02 -0.1339976280
[121,] -3.508730 1.802746 -1.599032e-02  0.0531911056
[122,] -4.264114 2.136908  2.608219e-02 -0.0740503050
[123,] -3.801805 2.007084  3.461455e-03 -0.0113268599
[124,] -3.712038 1.836891 -3.509761e-03  0.0629693157
[125,] -3.806934 2.148632 -1.216711e-02  0.0395487109
[126,] -4.240105 2.021889  2.874694e-02 -0.0932254338
[127,] -4.155186 2.321345 -5.165163e-03  0.0527220324
[128,] -3.307950 1.970644 -3.185943e-02  0.1245973945
[129,] -3.999351 1.946712  1.097447e-02 -0.0055252655
[130,] -3.304032 1.947459 -4.390550e-02  0.2224221478
[131,] -4.135311 2.174581  5.678614e-03  0.1047150155
[132,] -3.928400 2.227036 -8.477073e-03 -0.0033902109
[133,] -4.090974 1.852103  2.671036e-02 -0.0565707422
[134,] -4.228189 1.997085  3.469586e-02 -0.2030672372
[135,] -3.682116 2.087271 -5.820878e-03 -0.0948909977
[136,] -3.797224 1.896949  6.688539e-03 -0.0582895580
[137,] -4.165845 2.061340  1.954293e-02 -0.1543790959
[138,] -3.641104 1.903041 -6.536409e-03 -0.0119042668
[139,] -4.097108 2.160384  1.115529e-02 -0.0724561664
[140,] -4.525326 2.365776  4.388213e-02 -0.2297289480
[141,] -4.385081 2.377942  1.588952e-02 -0.1659778316
[142,] -3.027227 1.919696 -5.470491e-02  0.1911683105
[143,] -4.457124 2.162947  3.814531e-02 -0.0816619474
[144,] -4.189881 1.954942  2.647061e-02 -0.0572767217
[145,] -3.659273 1.830782 -1.256589e-02  0.1484105313
[146,] -3.786174 1.942675  6.861928e-03  0.0099956492
[147,] -3.718117 2.075444 -1.450852e-02  0.1050834358
[148,] -3.667478 1.800525 -1.095645e-02  0.1491468726
[149,] -3.843169 2.040663 -8.323102e-05  0.0101140238
[150,] -3.783074 1.828477  6.726227e-03 -0.0015190705
[151,] -3.844204 2.445522 -9.778103e-03 -0.0966296257
[152,] -4.014539 1.891398  1.676773e-02 -0.0253646467
[153,] -3.643029 1.878823  1.400567e-03 -0.1320305161
[154,] -3.723788 1.783265  2.467140e-03  0.0224532903
[155,] -4.145110 2.094964  1.716442e-02  0.0295778406
[156,] -4.081548 2.037651  8.822724e-03  0.0793053344
[157,] -3.875097 2.203920 -2.138764e-02  0.2292214038
[158,] -3.617571 2.015239 -2.403149e-02  0.1766551702
[159,] -3.902126 2.062632  5.143801e-03 -0.0102731503
[160,] -3.272258 1.783038 -3.422481e-02  0.1426085601
[161,] -3.480859 1.805708 -4.613320e-03 -0.0791249959
[162,] -4.718388 2.374018  2.769228e-02  0.0623856361
[163,] -4.268787 2.224135  8.096689e-03  0.1247273187
[164,] -3.393981 1.951983 -1.952794e-02  0.0457163110
[165,] -4.394214 2.104723  3.064916e-02 -0.0235612466
[166,] -4.281285 1.974965  3.038822e-02 -0.0311926837
[167,] -4.702219 2.171324  4.973325e-02 -0.0869031196
[168,] -4.237489 1.802802  3.047525e-02  0.0724370946
[169,] -3.822709 1.983961 -1.691171e-02  0.2261718330
[170,] -4.085762 1.663079  3.915696e-02 -0.1430921159
[171,] -3.821777 2.086481  2.049505e-03 -0.2161641257
[172,] -3.678557 1.920324 -8.534293e-03  0.0936154375
[173,] -4.644802 2.506383  3.376493e-02 -0.2470146053
[174,] -3.949024 2.081794 -5.296483e-03  0.0433945981
[175,] -3.852864 2.245946 -2.255508e-02  0.1300301608
[176,] -3.909281 1.918999  8.523183e-03 -0.0128849004
[177,] -4.306286 2.158051  2.589961e-02 -0.1267262756
[178,] -3.834000 1.844522  6.772187e-03  0.0749433922
[179,] -3.331397 2.083671 -3.159744e-02  0.0551287194
[180,] -3.799385 2.102687 -2.067547e-03 -0.0434796580
[181,] -3.994080 2.234571 -1.932605e-03  0.0537920459
[182,] -3.600601 1.974491 -7.493674e-03  0.0491288206
[183,] -3.685178 1.875284  2.249543e-03 -0.0884464598
[184,] -2.963417 1.806336 -5.872092e-02  0.2737230822
[185,] -4.038128 2.202593  9.807337e-03 -0.0329485889
[186,] -3.990715 1.977671  1.400111e-02 -0.0027112772
[187,] -4.249780 2.358183  1.373356e-02 -0.0512035195
[188,] -4.577212 2.263326  3.790035e-02 -0.0982534862
[189,] -4.344685 2.053721  4.011933e-02 -0.1517365134
[190,] -4.221703 2.137884  2.023067e-02 -0.0224779658
[191,] -3.612999 2.141203 -7.164466e-03 -0.0684667589
[192,] -3.678132 2.255352 -1.559494e-02 -0.0419604041
[193,] -3.897708 1.938039  2.328203e-03  0.0095155871
[194,] -4.287690 2.189382  2.301627e-02 -0.0778086140
[195,] -3.748425 2.137735 -1.663837e-02  0.0809350668
[196,] -3.563102 1.911825 -7.785192e-03  0.0589914646
[197,] -4.385482 1.851998  4.494075e-02 -0.0923044406
[198,] -4.435619 2.132539  2.441535e-02  0.0869480352
[199,] -3.709206 1.835904 -1.440745e-02  0.1970529873
[200,] -3.729225 1.883253 -3.805026e-03  0.1184183503
> 
> # compare mean-values
> ergm_mv_est_tapered = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+ #ergm_mv_est_tapered <- simulate(g_sim[[1]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+ simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                control=control.simulate.formula(MCMC.burnin=100000, MCMC.interval=10000),
+                coef = ergm_sim_estim_tapered[i,],         
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  397.135  344.700 3161.690  120.560
> ergm_mv_tapered = colMeans(ergm_mv_est_tapered)
> ergm_mv_tapered
      edges nodematch.x      kstar2    triangle 
   396.5035    344.3060   3149.9985    120.1250 
> 
> # Model statistics ‘kstar2’ and ‘triangle’ are not varying. This may indicate 
> # that the observed data occupies an extreme point in the sample space or that 
> # the estimation has reached a dead-end configuration.
> # Warning: Model statistics ‘nodematch.x’ are linear combinations of some set of 
> # preceding statistics at the current stage of the estimation. This may indicate 
> # that the model is nonidentifiable.
> # Error in ergm.MCMLE(init, nw, model, initialfit = (initialfit <- NULL),  : 
> # Unconstrained MCMC sampling did not mix at all. Optimization cannot continue.
> # In addition: Warning message:
> # In ergm_MCMC_sample(s, control, theta = mcmc.init, verbose = max(verbose -  :
> # Unable to reach target effective size in iterations alotted.
> 
> 
> ##################
> #                #
> #     MFERGM     #
> #                #
> ##################
> 
> # Use "theta" on mfergm instead
> tobs <- data.frame(matrix(NA, ncol = 4, nrow = nsims))
> names(tobs) <- c("edges", "x", "kstar2", "triangles")
> for (i in 1:nsims) 
+ {
+   tobs[i,] = g_sim_stats[i,] / (c((n^2)/2, (n^2)/2, (n^3)/2 , (n^3)/2 ))  
+ }
> 
> ### Compute MFERGM Results
> mfergm_estim <- NULL
> # Double loop to reduce memory use
> for(j in 1:(nsims/100)){
+  mfergm_estim_j = foreach(i = (100*(j-1)+(1:100)), .combine = rbind) %dorng% {
+   pars <- init_params[i,] * c(.5,.5,n,n)
+   addpars <- list(n=n, tobs = tobs[i,], x=x, ninit=1)
+   cd.est <- tryCatch(optimx(pars, fn = loglikmf.model5, 
+                             method = "BFGS", 
+                             control = list(fnscale = -1), addpars = addpars), 
+                      error = function(e) {return(c(NA, NA, NA, NA))})
+   as.numeric(cd.est[1:4])
+  }
+  mfergm_estim <- rbind(mfergm_estim, mfergm_estim_j)
+ }
> mfergm_estim = matrix(c(mfergm_estim[,1]*2, mfergm_estim[,2]*2, mfergm_estim[,3]/n, mfergm_estim[,4]/n),
+                nrow = nsims)
> mfergm_result_med = apply(mfergm_estim, 2, median, na.rm = T) 
> mfergm_result = apply(mfergm_estim, 2, mean, na.rm = T) 
> cbind(theta,mfergm_result_med,mfergm_result)
     theta mfergm_result_med mfergm_result
[1,] -4.00        -4.0401079    -2.2250065
[2,]  2.00         2.1271870   -11.5043976
[3,]  0.01         0.0078425    -0.2264944
[4,]  0.01        -0.0254191    -0.3664237
> 
> #### DEGENERACIES
> degen_mfergm = which(!complete.cases(mfergm_estim))
> # 58 of em
> degen_mfergm
[1]  58 141
> 
> if(length(degen_mfergm) > 0){
+ # Replace with MPLE
+ for(i in 1:length(degen_mfergm)){
+   mfergm_estim[degen_mfergm[i],] <- init_params[degen_mfergm[i],]
+ }
+ }
> 
> # compare mean values
> mf_mv_est = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                control=control.simulate.formula(MCMC.burnin=100000, MCMC.interval=10000),
+                coef =  mfergm_estim[i,],    
+                output = "stats"
+ )
+ }
> mfergm_mv = colMeans(mf_mv_est)
> mfergm_mv
      edges nodematch.x      kstar2    triangle 
    821.280     621.929   27597.307    5721.264 
> 
> # compare mean values
> MPLE_mv_est = foreach(i = 1:nsims, .combine = rbind) %dorng% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = init_params[i,],    
+                control=control.simulate.formula(MCMC.burnin=100000, MCMC.interval=10000),
+                output = "stats"
+ )
+ }
> stopImplicitCluster()
> colMeans(g_sim_stats)
[1]  397.135  344.700 3161.690  120.560
> MPLE_mv = colMeans(MPLE_mv_est)
> MPLE_result = apply(init_params, 2, mean, na.rm = T) 
> 
> mean_est <- cbind(theta, ergm_result_tapered, MPLE_result, mfergm_result)
> rownames(mean_est) <- names(ergm_mv_tapered)
> colnames(mean_est) <- c("true", "MCMC-MLE","MPLE","MFVLE")
> mean_est
             true    MCMC-MLE         MPLE       MFVLE
edges       -4.00 -3.97025817 -3.969904450  -2.2250065
nodematch.x  2.00  2.02677094  2.025076837 -11.5043976
kstar2       0.01  0.00811981  0.008030968  -0.2264944
triangle     0.01 -0.01274581 -0.009955218  -0.3664237
> 
> mean_mv_est <- cbind(round(colMeans(g_sim_stats), 2), round(ergm_mv_tapered,2), round(MPLE_mv,2), round(mfergm_mv, 2))
> rownames(mean_mv_est) <- names(ergm_mv_tapered)
> colnames(mean_mv_est) <- c("true", "MCMC-MLE","MPLE", "MFVLE")
> mean_mv_est
               true MCMC-MLE    MPLE    MFVLE
edges        397.14   396.50  397.06   821.28
nodematch.x  344.70   344.31  344.80   621.93
kstar2      3161.69  3150.00 3163.38 27597.31
triangle     120.56   120.12  121.74  5721.26
> 
> hist(ergm_sim_estim_tapered[,4], main = NULL, xlab = "Triangle")
> hist(mfergm_estim[,4], main = NULL, xlab = "Triangle")
> 
> 
> outliers <- function(x, field = 1.5, na.rm = TRUE) 
+ {
+   qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm)
+   H <- field * IQR(x, na.rm = na.rm)
+   which(x < (qnt[1] - H) | x > (qnt[2] + H))
+ }
> 
> 
> 
> a  = is.na(ergm_sim_estim_tapered[,4])
> b  = is.na(mfergm_estim[,4])
> c = mfergm_estim[(!a)&(!b),]
> c1 = c[,4]
> d = ergm_sim_estim_tapered[(!a)&(!b),]
> d1 = d[,4]
> c1[c1 < -2] = d1[c1 < -2]
> plot(c1~d1, col = (c1 == d1) + 1, pch = 16)
> sum(c1 == d1)
[1] 5
> 
> f = c[-Reduce(union, list(outliers(c[,1], 0.6), outliers(c[,2], 0.3), outliers(c[,3], 1.5), outliers(c[,4], 1.5))),]
> 
> 
> 
> gtest_mf = matrix(nrow = nrow(c), ncol = 4)
> for (i in 1:nrow(c))
+ {
+   gtest_mf[i,] = simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1,
+                           coef = c[i,],        
+                           output = "stats")
+ }
> gtest_mc_tapered = matrix(nrow = nrow(d), ncol = 4)
> for (i in 1:nrow(d))
+ {
+   gtest_mc_tapered[i,] = as.vector(simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1,
+                           coef = d[i,],        
+                           output = "stats"))
+ }
> colMeans(gtest_mf)
[1]   728.630   571.175 18534.230  2966.915
> colMeans(gtest_mc_tapered)
[1]  397.245  344.080 3162.925  120.765
> 
> summary(ergm_sim_estim_tapered)
       V1               V2              V3                  V4          
 Min.   :-4.942   Min.   :1.482   Min.   :-0.058721   Min.   :-0.33063  
 1st Qu.:-4.202   1st Qu.:1.896   1st Qu.:-0.005834   1st Qu.:-0.08525  
 Median :-4.000   Median :2.022   Median : 0.009584   Median :-0.01302  
 Mean   :-3.970   Mean   :2.027   Mean   : 0.008120   Mean   :-0.01275  
 3rd Qu.:-3.747   3rd Qu.:2.141   3rd Qu.: 0.025945   3rd Qu.: 0.05354  
 Max.   :-2.963   Max.   :2.506   Max.   : 0.057104   Max.   : 0.28399  
> summary(gtest_mf)
       V1               V2               V3               V4         
 Min.   :   1.0   Min.   :   0.0   Min.   :     0   Min.   :    0.0  
 1st Qu.: 380.0   1st Qu.: 321.5   1st Qu.:  2919   1st Qu.:  103.0  
 Median : 472.5   Median : 383.5   Median :  4404   Median :  171.5  
 Mean   : 728.6   Mean   : 571.2   Mean   : 18534   Mean   : 2966.9  
 3rd Qu.: 832.2   3rd Qu.: 663.8   3rd Qu.: 13903   3rd Qu.:  784.0  
 Max.   :4059.0   Max.   :2097.0   Max.   :326054   Max.   :89041.0  
> summary(gtest_mc_tapered)
       V1              V2              V3             V4       
 Min.   :309.0   Min.   :257.0   Min.   :1919   Min.   : 55.0  
 1st Qu.:378.8   1st Qu.:325.0   1st Qu.:2862   1st Qu.: 99.0  
 Median :397.5   Median :345.5   Median :3176   Median :117.0  
 Mean   :397.2   Mean   :344.1   Mean   :3163   Mean   :120.8  
 3rd Qu.:416.0   3rd Qu.:362.0   3rd Qu.:3464   3rd Qu.:141.0  
 Max.   :495.0   Max.   :433.0   Max.   :4806   Max.   :219.0  
> summary(g_sim_stats)
       V1              V2              V3             V4       
 Min.   :335.0   Min.   :285.0   Min.   :2198   Min.   : 69.0  
 1st Qu.:382.0   1st Qu.:330.0   1st Qu.:2923   1st Qu.:103.0  
 Median :397.0   Median :344.0   Median :3138   Median :120.0  
 Mean   :397.1   Mean   :344.7   Mean   :3162   Mean   :120.6  
 3rd Qu.:411.0   3rd Qu.:358.0   3rd Qu.:3397   3rd Qu.:136.0  
 Max.   :451.0   Max.   :397.0   Max.   :4098   Max.   :192.0  
> 
> 
> gtest_mf_tri = gtest_mf[gtest_mf[,4]<60, 4]
> 
> hist(ergm_sim_estim_tapered[,1])
> hist(ergm_sim_estim_tapered[,2])
> hist(ergm_sim_estim_tapered[,3])
> hist(ergm_sim_estim_tapered[,4])
> hist(f[,1])
> hist(f[,2])
> hist(f[,3])
> hist(f[,4])
> 
> 
> gtest_mf_rm = gtest_mf[-Reduce(union, list(outliers(gtest_mf[,1], 0.7), outliers(gtest_mf[,2], 1), 
+                                            outliers(gtest_mf[,3], 0.001), outliers(gtest_mf[,4], 0.001))),]
> hist(gtest_mf[,1])
> hist(gtest_mf[,2])
> hist(gtest_mf[,3])
> hist(gtest_mf[,4])
> 
> hist(ergm_sim_estim_tapered[,1])
> hist(ergm_sim_estim_tapered[,2])
> hist(ergm_sim_estim_tapered[,3])
> hist(ergm_sim_estim_tapered[,4])
> 
> # First natural params
> complete_mf_results = mfergm_estim[complete.cases(mfergm_estim),]
> complete_tapered_results = ergm_sim_estim_tapered[complete.cases(ergm_sim_estim_tapered),]
> complete_MPLE_results = init_params[complete.cases(init_params),]
> 
> bdrmse <- function(comp, theta, degen){
+  outliers1 = union(outliers((comp[,1] - theta[1])^2), degen)
+  outliers2 = union(outliers((comp[,2] - theta[2])^2), degen)
+  outliers3 = union(outliers((comp[,3] - theta[3])^2), degen)
+  outliers4 = union(outliers((comp[,4] - theta[4])^2), degen)
+  rmse1 <- ((comp[,1] - theta[1])^2)
+  rmse1[outliers1] <- max(rmse1[-outliers1])
+  rmse2 <- ((comp[,2] - theta[2])^2)
+  rmse2[outliers2] <- max(rmse2[-outliers2])
+  rmse3 <- ((comp[,3] - theta[3])^2)
+  rmse3[outliers3] <- max(rmse3[-outliers3])
+  rmse4 <- ((comp[,4] - theta[4])^2)
+  rmse4[outliers4] <- max(rmse4[-outliers4])
+  c(sqrt(mean(rmse1)), sqrt(mean(rmse2)), sqrt(mean(rmse3)), sqrt(mean(rmse4)) ) 
+ }
> bdmad <- function(comp, theta, degen){
+  outliers1 = union(outliers(abs(comp[,1] - theta[1])),degen)
+  outliers2 = union(outliers(abs(comp[,2] - theta[2])),degen)
+  outliers3 = union(outliers(abs(comp[,3] - theta[3])),degen)
+  outliers4 = union(outliers(abs(comp[,4] - theta[4])),degen)
+  mad1 <- (abs(comp[,1] - theta[1]))
+  mad1[outliers1] <- max(mad1[-outliers1])
+  mad2 <- (abs(comp[,2] - theta[2]))
+  mad2[outliers2] <- max(mad2[-outliers2])
+  mad3 <- (abs(comp[,3] - theta[3]))
+  mad3[outliers3] <- max(mad3[-outliers3])
+  mad4 <- (abs(comp[,4] - theta[4]))
+  mad4[outliers4] <- max(mad4[-outliers4])
+  c((mean(mad1)), (mean(mad2)), (mean(mad3)), (mean(mad4)) ) 
+ }
> 
> # Degeneracy
> length(intersect(which(is.na(mfergm_estim[,1])), which(is.na(ergm_sim_estim_tapered[,1]))))
[1] 0
> 
> # RMSE
> 
> MPLE_rmse <- bdrmse(complete_MPLE_results, theta,degen=NULL)
> mf_rmse <- bdrmse(complete_mf_results, theta, degen_mfergm)
> tapered_rmse <- bdrmse(complete_tapered_results, theta, degen_tapered)
> 
> # MAD
> MPLE_mad <- bdmad(complete_MPLE_results, theta,degen=NULL)
> mf_mad <- bdmad(complete_mf_results, theta, degen_mfergm)
> tapered_mad <- bdmad(complete_tapered_results, theta, degen_tapered)
> 
> RMSE_natural_parameter <- cbind(round(tapered_rmse, 3), round(MPLE_rmse, 3), round(mf_rmse, 3))
> rownames(RMSE_natural_parameter) <- names(mv_1)
> colnames(RMSE_natural_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the RMSE of natural parameter estimates
> RMSE_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.303 0.320 1.789
nodematch.x    0.170 0.169 2.404
kstar2         0.020 0.021 0.035
triangle       0.100 0.100 0.116
> 
> MAD_natural_parameter <- cbind(round(tapered_mad, 3), round(MPLE_mad, 3), round(mf_mad, 3))
> rownames(MAD_natural_parameter) <- names(mv_1)
> colnames(MAD_natural_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the MAD of natural parameter estimates
> MAD_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.271 0.283 1.527
nodematch.x    0.146 0.145 2.156
kstar2         0.017 0.018 0.031
triangle       0.086 0.086 0.100
> 
> 
> outliers1 = outliers((complete_tapered_results[,1] - theta[1])^2)
> outliers2 = outliers((complete_tapered_results[,2] - theta[2])^2)
> outliers3 = outliers((complete_tapered_results[,3] - theta[3])^2)
> outliers4 = outliers((complete_tapered_results[,4] - theta[4])^2)
> plot((complete_mf_results[,1] - theta[1])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,2] - theta[2])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,3] - theta[3])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,4] - theta[4])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,1] - theta[1])^2)[-outliers1], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,2] - theta[2])^2)[-outliers2], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,3] - theta[3])^2)[-outliers3], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,4] - theta[4])^2)[-outliers4], pch = 19, ylab = "", xlab = "Simulated Networks")
> 
> 
> outliers1 = head(order((complete_mf_results[,1] - theta[1])^2, decreasing = T), n = 100)
> outliers2 = head(order((complete_mf_results[,2] - theta[2])^2, decreasing = T), n = 100)
> outliers3 = head(order((complete_mf_results[,3] - theta[3])^2, decreasing = T), n = 100)
> outliers4 = head(order((complete_mf_results[,4] - theta[4])^2, decreasing = T), n = 100)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> 
> 
> plot(density(complete_mf_results[,1]), main = "")
> plot(density(complete_mf_results[,2]), main = "")
> plot(density(complete_mf_results[,3]), main = "")
> plot(density(complete_mf_results[,4]), main = "")
> 
> 
> # Now the mean values
> complete_mf_results = mf_mv_est[complete.cases(mf_mv_est),]
> complete_tapered_results = ergm_mv_est_tapered[complete.cases(ergm_mv_est_tapered),]
> complete_MPLE_results = MPLE_mv_est[complete.cases(MPLE_mv_est),]
> 
> 
> # Degeneracy
> length(intersect(which(is.na(mf_mv_est[,1])), which(is.na(ergm_mv_est_tapered[,1]))))
[1] 0
> 
> # MFERGM RMSE
> 
> outliers1 = outliers((complete_tapered_results[,1] - mv_s[1])^2)
> outliers2 = outliers((complete_tapered_results[,2] - mv_s[2])^2)
> outliers3 = outliers((complete_tapered_results[,3] - mv_s[3])^2)
> outliers4 = outliers((complete_tapered_results[,4] - mv_s[4])^2)
> plot((complete_mf_results[,1] - mv_s[1])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,2] - mv_s[2])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,3] - mv_s[3])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,4] - mv_s[4])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,1] - mv_s[1])^2)[-outliers1], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,2] - mv_s[2])^2)[-outliers2], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,3] - mv_s[3])^2)[-outliers3], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,4] - mv_s[4])^2)[-outliers4], pch = 19, ylab = "", xlab = "Simulated Networks")
> 
> plot(density(complete_mf_results[,1]), main = "")
> plot(density(complete_mf_results[,2]), main = "")
> plot(density(complete_mf_results[,3]), main = "")
> plot(density(complete_mf_results[,4]), main = "")
> 
> # RMSE
> 
> MPLE_rmse <- bdrmse(complete_MPLE_results, mv_s, degen=NULL)
> mf_rmse <- bdrmse(complete_mf_results, mv_s, degen_mfergm)
> tapered_rmse <- bdrmse(complete_tapered_results, mv_s, degen_tapered)
> 
> # MAD
> MPLE_mad <- bdmad(complete_MPLE_results, mv_s, degen=NULL)
> mf_mad <- bdmad(complete_mf_results, mv_s, degen_mfergm)
> tapered_mad <- bdmad(complete_tapered_results, mv_s, degen_tapered)
> 
> RMSE_mean_value_parameter <- cbind(round(tapered_rmse, 3), round(MPLE_rmse, 3), round(mf_rmse, 3))
> rownames(RMSE_mean_value_parameter) <- names(mv_1)
> colnames(RMSE_mean_value_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the RMSE of mean-value parameter estimates
> RMSE_mean_value_parameter
            MCMC-MLE    MPLE     MFVLE
edges         28.314  28.044   400.414
nodematch.x   26.810  26.682   298.429
kstar2       449.627 451.818 10014.254
triangle      29.865  29.917   617.782
> 
> MAD_mean_value_parameter <- cbind(round(tapered_mad, 3), round(MPLE_mad, 3), round(mf_mad, 3))
> rownames(MAD_mean_value_parameter) <- names(mv_1)
> colnames(MAD_mean_value_parameter) <- c("MCMC-MLE","MPLE", "MFVLE")
> # These are the MAD of mean-value parameter estimates
> MAD_mean_value_parameter
            MCMC-MLE    MPLE    MFVLE
edges         24.020  24.073  314.891
nodematch.x   22.752  22.685  270.093
kstar2       382.860 384.082 8252.060
triangle      25.494  25.873  512.440
> 
> plot(mfergm_estim[,4],ergm_sim_estim_tapered[,4])
> 
> save.image("mfergm_params10_n1000.RData")
> 
> # Summary
> # These are the RMSE of natural parameter estimates
> RMSE_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.303 0.320 1.789
nodematch.x    0.170 0.169 2.404
kstar2         0.020 0.021 0.035
triangle       0.100 0.100 0.116
> # These are the MAD of natural parameter estimates
> MAD_natural_parameter
            MCMC-MLE  MPLE MFVLE
edges          0.271 0.283 1.527
nodematch.x    0.146 0.145 2.156
kstar2         0.017 0.018 0.031
triangle       0.086 0.086 0.100
> # These are the RMSE of mean-value parameter estimates
> RMSE_mean_value_parameter
            MCMC-MLE    MPLE     MFVLE
edges         28.314  28.044   400.414
nodematch.x   26.810  26.682   298.429
kstar2       449.627 451.818 10014.254
triangle      29.865  29.917   617.782
> # These are the RMSE of mean-value parameter estimates
> MAD_mean_value_parameter
            MCMC-MLE    MPLE    MFVLE
edges         24.020  24.073  314.891
nodematch.x   22.752  22.685  270.093
kstar2       382.860 384.082 8252.060
triangle      25.494  25.873  512.440
> 
> proc.time()
    user   system  elapsed 
1938.096   76.398  286.295 
