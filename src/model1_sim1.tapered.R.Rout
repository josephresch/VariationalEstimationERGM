> rm(list=ls())
> my.seed=1000
> set.seed(my.seed)
> 
> pdf("model1_sim1.tapered.pdf")
> 
> library(ergm.tapered)
Loading required package: ergm
Loading required package: network

‘network’ 1.18.0 (2022-10-05), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information


‘ergm’ 4.3-6983 (2022-08-20), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(mfergm)
> library(optimx)     # mfergm likelihood
> library(R.utils)    # set time on ergm
Loading required package: R.oo
Loading required package: R.methodsS3
R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.
R.oo v1.25.0 (2022-06-12 02:20:02 UTC) successfully loaded. See ?R.oo for help.

Attaching package: ‘R.oo’

The following object is masked from ‘package:R.methodsS3’:

    throw

The following objects are masked from ‘package:methods’:

    getClasses, getMethods

The following objects are masked from ‘package:base’:

    attach, detach, load, save

R.utils v2.12.0 (2022-06-28 03:20:05 UTC) successfully loaded. See ?R.utils for help.

Attaching package: ‘R.utils’

The following object is masked from ‘package:utils’:

    timestamp

The following objects are masked from ‘package:base’:

    cat, commandArgs, getOption, isOpen, nullfile, parse, warnings

> library(doParallel) # parallel loops using 'foreach'
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
> 
> #####################################################################
> #                                                                   #
> #     Create High Transitivity ERGM Params (using ERGM fitting)     #
> #                                                                   #
> #####################################################################
> 
> nsims       =  100                              # number of networks simulated
> n           =  100                                # number of nodes
> #theta       =  c(-3,2,1,3) * c(2,2,1/n,1/n)      # true parameters for model 2
> theta       =  c(-2,1,1,1) * c(2,2,1/n,1/n)      # true parameters for model 1
> 
> 
> ##################
> #                #
> #     Set-up     #
> #                #
> ##################
> 
> g <- initialize.network(theta, n, directed = FALSE)
> x <- rbinom(n, 1, 0.5) # attributes
> set.vertex.attribute(g, # the name of the network object
+                      "x", # the name we want to reference the variable by in that object
+                      x # the value we are giving that variable
+ ) 
> 
> # Simulated networks 'g_sim' used for both ERGM and MFERGM
> g_sim <- simulate(g ~ edges + nodematch("x") + kstar(2) + triangles, 
+                   nsim = nsims,
+                   coef = theta
+ )
> 
> # Extract summary stats from 'g_sim'
> g_sim_stats = matrix(nrow = nsims, ncol = 4)
> for (i in 1:nsims)
+ {
+   g_sim_stats[i,] = summary_formula(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles)
+ }
> 
> 
> # asdf_index = g_sim_stats[,1] > mean(g_sim_stats[,1]) - sd(g_sim_stats[,1]) & g_sim_stats[,1] < mean(g_sim_stats[,1]) + sd(g_sim_stats[,1]) &
> #              g_sim_stats[,2] > mean(g_sim_stats[,2]) - sd(g_sim_stats[,2]) & g_sim_stats[,2] < mean(g_sim_stats[,2]) + sd(g_sim_stats[,2]) &
> #              g_sim_stats[,3] > mean(g_sim_stats[,3]) - sd(g_sim_stats[,3]) & g_sim_stats[,3] < mean(g_sim_stats[,3]) + sd(g_sim_stats[,3]) &
> #              g_sim_stats[,4] > mean(g_sim_stats[,4]) - sd(g_sim_stats[,4]) & g_sim_stats[,4] < mean(g_sim_stats[,4]) + sd(g_sim_stats[,4])
> # 
> # asdf = g_sim_stats[asdf_index,]
> # g_sim_stats = asdf
> # nsims = nrow(asdf)
> # g_sim = g_sim[which(asdf_index)]
> 
> 
> 
> # Initialize the parameters at MPLE
> init_params = matrix(nrow = nsims, ncol = length(theta))
> for (i in 1:nsims)
+ {
+   init_params[i,] = ergm(g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles, 
+                          estimate = "MPLE")$coefficients
+ }
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Evaluating log-likelihood at the estimate. 
> 
> 
> ##########################
> #                        #
> #     ERGM (Default)     #
> #                        #
> ##########################
> 
> ### Compute ERGM Results
> #registerDoParallel(detectCores())
> registerDoParallel(10)
> ergm_sim_list = foreach(i = 1:nsims) %dopar% {
+   # cat("***********************************\n")
+   # cat(paste("estimating sample" ,i, "\n"))
+   # cat("***********************************\n")
+   skip_to_next <- FALSE
+   formula <- g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = 
+     tryCatch(withTimeout(
+                           ergm(formula, eval.loglik=FALSE,
+                                control=control.ergm(init = init_params[i,], MCMLE.confidence=0.95)),
+                timeout = 5*60, onTimeout = "error"),
+                error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0450.
The log-likelihood improved by 0.0414.
The log-likelihood improved by 0.0234.
Convergence test p-value: 0.0963. Not converged with 95% confidence; increasing sample size.
The log-likelihood improved by 0.0461.
Iteration 2 of at most 60:
Convergence test p-value: 0.1553. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.1113. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Convergence test p-value: 0.0692. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0277.
Convergence test p-value: 0.2968. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0281.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3552. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0510.
The log-likelihood improved by 0.0362.
Convergence test p-value: 0.0075. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0026.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0123. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0206. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0073.
Convergence test p-value: 0.0327. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1636.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1079.
The log-likelihood improved by 0.0211.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: 0.0322. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0250.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0312.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0402.
Iteration 1 of at most 60:
Convergence test p-value: 0.0907. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.5076. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0931.
Convergence test p-value: 0.0941. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2078.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2017.
Estimating equations are not within tolerance region.
Estimating equations did not move closer to tolerance region more than 1 time(s) in 4 steps; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0097.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1581. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.1226. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0790.
Convergence test p-value: 0.5765. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0583.
Convergence test p-value: 0.0531. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0454.
The log-likelihood improved by 0.0909.
Convergence test p-value: 0.0935. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.6823. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0048.
Convergence test p-value: 0.0312. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0115.
Convergence test p-value: 0.4882. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0663.
Convergence test p-value: 0.5287. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0502.
Convergence test p-value: 0.3106. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0422.
Convergence test p-value: 0.1800. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0184.
Convergence test p-value: 0.0147. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0091.
Convergence test p-value: 0.0126. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0349.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Convergence test p-value: 0.1384. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0224.
The log-likelihood improved by 0.0880.
Convergence test p-value: 0.0013. Converged with 95% confidence.
Finished MCMLE.
Convergence test p-value: 0.0095. This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0121.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1122.
Estimating equations are not within tolerance region.
Convergence test p-value: 0.0333. Iteration 2 of at most 60:
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0717.
Convergence test p-value: 0.0155. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0191.
The log-likelihood improved by 0.0717.
Convergence test p-value: 0.4995. Not converged with 95% confidence; increasing sample size.
Convergence test p-value: 0.2165. Iteration 3 of at most 60:
Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0220.
Convergence test p-value: 0.0436. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0846.
Convergence test p-value: 0.2903. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0087.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0548. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0541.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2793. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0134.
Convergence test p-value: 0.0053. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0306.
Convergence test p-value: 0.1082. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0736.
The log-likelihood improved by 0.0324.
Convergence test p-value: 0.1099. Convergence test p-value: 0.0895. Not converged with 95% confidence; increasing sample size.
Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Iteration 5 of at most 60:
The log-likelihood improved by 0.0166.
Convergence test p-value: 0.1259. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0782.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3231. Not converged with 95% confidence; increasing sample size.
The log-likelihood improved by 0.2291.
Iteration 3 of at most 60:
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0595.
Optimizing with step length 1.0000.
Convergence test p-value: 0.4496. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0805.
Convergence test p-value: 0.2236. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0079.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0195. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0311.
Convergence test p-value: 0.2737. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2153.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0647.
Convergence test p-value: 0.6776. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0998.
Convergence test p-value: 0.3091. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0547.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0939. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0262.
Convergence test p-value: 0.0807. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0742.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0260. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0171.
Convergence test p-value: 0.0260. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0135.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.2016. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0197.
Convergence test p-value: 0.0327. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0390.
The log-likelihood improved by 0.0240.
Convergence test p-value: 0.2316. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Convergence test p-value: 0.1997. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1549.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0054.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0503.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.2474. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0217.
Convergence test p-value: 0.0223. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0251.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3723. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0173.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0961.
Convergence test p-value: 0.0616. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0354.
The log-likelihood improved by 0.0403.
Convergence test p-value: 0.2867. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.3056. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0265.
Convergence test p-value: 0.1143. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0829.
The log-likelihood improved by 0.0146.
Convergence test p-value: 0.1960. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Convergence test p-value: 0.0383. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0565.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0036. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0284.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0408. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0096.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0019. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0337.
Convergence test p-value: 0.5506. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0232.
Convergence test p-value: 0.0575. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0978.
Convergence test p-value: 0.2771. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0259.
Convergence test p-value: 0.1733. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0659.
The log-likelihood improved by 0.0233.
The log-likelihood improved by 0.0003.
Convergence test p-value: 0.1491. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0298. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0389.
The log-likelihood improved by 0.0385.
Convergence test p-value: 0.0156. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0461. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1868.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0433.
Convergence test p-value: 0.0606. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0490.
Convergence test p-value: 0.0797. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
The log-likelihood improved by 0.0271.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0379. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0397. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0123.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0316. Converged with 95% confidence.
Optimizing with step length 1.0000.
Finished MCMLE.
The log-likelihood improved by 0.0031.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0016.
Convergence test p-value: 0.1981. Not converged with 95% confidence; increasing sample size.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 2 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.1528. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0349.
Convergence test p-value: 0.3928. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0265.
Convergence test p-value: 0.4712. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0356.
Convergence test p-value: 0.0013. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0185.
Convergence test p-value: 0.2425. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0482.
The log-likelihood improved by 0.0220.
Convergence test p-value: 0.1636. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.4206.
Optimizing with step length 1.0000.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: 0.0025. Optimizing with step length 1.0000.
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0358.
The log-likelihood improved by 0.0235.
Convergence test p-value: 0.3051. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.2155. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0136.
Convergence test p-value: 0.1787. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0350.
Convergence test p-value: 0.0730. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0960.
Convergence test p-value: 0.4982. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0399.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0566. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0376.
The log-likelihood improved by 0.0263.
Convergence test p-value: 0.3797. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0835.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0717. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.0007. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0313.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0239. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0115.
Convergence test p-value: 0.1212. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0120.
Convergence test p-value: 0.0045. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0587.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.1316. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0775.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2976. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0627.
The log-likelihood improved by 0.0966.
Convergence test p-value: 0.0182. Converged with 95% confidence.
Convergence test p-value: 0.2798. Finished MCMLE.
Not converged with 95% confidence; increasing sample size.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0149.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0284. Optimizing with step length 1.0000.
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0308.
Convergence test p-value: 0.2580. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0205.
Convergence test p-value: 0.0114. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0250.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0230. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0091.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0172. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0207.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.0458. Iteration 1 of at most 60:
Converged with 95% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0158.
Convergence test p-value: 0.0006. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0107.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2718. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0144.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0221. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2167.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0704.
Convergence test p-value: 0.2625. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0934.
Convergence test p-value: 0.4112. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0940.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0724. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0181.
Convergence test p-value: 0.0081. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0442.
The log-likelihood improved by 0.0411.
Convergence test p-value: 0.2451. Not converged with 95% confidence; increasing sample size.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 2 of at most 60:
Convergence test p-value: 0.4077. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0294.
The log-likelihood improved by 0.2223.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0013.
Convergence test p-value: 0.2192. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.0033. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0493.
Convergence test p-value: 0.0379. Converged with 95% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1146.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0298.
The log-likelihood improved by 0.0194.
Convergence test p-value: 0.1037. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.0005. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0619.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.5509. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0526.
The log-likelihood improved by 0.0254.
Convergence test p-value: 0.2203. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.1154. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0117.
Convergence test p-value: 0.0698. Not converged with 95% confidence; increasing sample size.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0600.
Convergence test p-value: 0.0754. Not converged with 95% confidence; increasing sample size.
Optimizing with step length 1.0000.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0509.
Convergence test p-value: 0.1131. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0552.
Convergence test p-value: 0.0566. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0158.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0282. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1032.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0270.
Convergence test p-value: 0.4008. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0376.
Convergence test p-value: 0.0322. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0435.
Convergence test p-value: 0.0109. Optimizing with step length 1.0000.
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0542.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.2108. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0547.
The log-likelihood improved by 0.0197.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0242.
Convergence test p-value: 0.4129. Convergence test p-value: 0.1500. Not converged with 95% confidence; increasing sample size.
Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Iteration 3 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Convergence test p-value: 0.1303. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0357.
Convergence test p-value: 0.1308. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0182.
Convergence test p-value: 0.2521. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0095.
Convergence test p-value: 0.0284. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0095.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0263. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0326.
The log-likelihood improved by 0.0310.
Convergence test p-value: 0.0814. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.0007. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0289.
Convergence test p-value: 0.3846. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0774.
Optimizing with step length 1.0000.
Convergence test p-value: 0.4102. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0301.
The log-likelihood improved by 0.0062.
Convergence test p-value: 0.2384. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Convergence test p-value: 0.0976. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0452.
The log-likelihood improved by 0.0046.
Convergence test p-value: 0.0320. Convergence test p-value: 0.0242. Converged with 95% confidence.
Converged with 95% confidence.
Finished MCMLE.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0030.
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.0825. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2462.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0078.
Convergence test p-value: 0.2821. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0589.
Convergence test p-value: 0.4062. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0118.
Convergence test p-value: 0.1755. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0076.
Convergence test p-value: 0.0514. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0709.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1400. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0125.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0005. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0256.
Convergence test p-value: 0.0643. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0129.
Convergence test p-value: 0.0038. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0438.
Convergence test p-value: 0.2468. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0143.
The log-likelihood improved by 0.0132.
The log-likelihood improved by 0.0416.
Convergence test p-value: 0.0026. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.5818. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0293.
Convergence test p-value: 0.2171. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.0848. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0158.
Iteration 1 of at most 60:
Convergence test p-value: 0.1346. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0158.
Convergence test p-value: 0.3606. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0292.
Convergence test p-value: 0.1364. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0149.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0020. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0399.
Optimizing with step length 1.0000.
Convergence test p-value: 0.1446. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0382.
Convergence test p-value: 0.2997. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0649.
Convergence test p-value: 0.0430. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0049.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0086.
Convergence test p-value: 0.0042. Converged with 95% confidence.
Iteration 1 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0076. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0682.
Convergence test p-value: 0.0981. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0077.
Convergence test p-value: 0.0227. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0578.
Iteration 1 of at most 60:
Convergence test p-value: 0.4858. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0362.
The log-likelihood improved by 0.0262.
Convergence test p-value: 0.2613. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Convergence test p-value: 0.0470. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0100.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3550.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
The log-likelihood improved by 0.0997.
The log-likelihood improved by 0.0627.
The log-likelihood improved by 0.0265.
The log-likelihood improved by 0.0140.
Convergence test p-value: 0.3835. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.2883. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Convergence test p-value: 0.0007. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0251. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0235.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0161. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0048.
Convergence test p-value: 0.3238. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0827.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3595. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0377.
The log-likelihood improved by 0.2359.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Convergence test p-value: 0.0186. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0170.
Convergence test p-value: 0.1339. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0307.
Convergence test p-value: 0.5385. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0909.
Convergence test p-value: 0.1713. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0203.
Convergence test p-value: 0.3219. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0548.
The log-likelihood improved by 0.0615.
The log-likelihood improved by 0.0270.
Convergence test p-value: 0.2873. Convergence test p-value: 0.0110. Converged with 95% confidence.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.2287.
Convergence test p-value: 0.0061. Not converged with 95% confidence; increasing sample size.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Iteration 3 of at most 60:
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0054.
Convergence test p-value: 0.2137. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0248.
Convergence test p-value: 0.2584. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0626.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1138.
Estimating equations are not within tolerance region.
Convergence test p-value: 0.7711. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0364.
Convergence test p-value: 0.2180. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0075.
Convergence test p-value: 0.0167. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0120.
Convergence test p-value: 0.0644. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0779.
Convergence test p-value: 0.0183. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0534.
Convergence test p-value: 0.6190. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0795.
Convergence test p-value: 0.0110. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0540.
Convergence test p-value: 0.2235. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0258.
The log-likelihood improved by 0.0435.
Convergence test p-value: 0.0059. Convergence test p-value: 0.3281. Converged with 95% confidence.
Not converged with 95% confidence; increasing sample size.
Finished MCMLE.
Iteration 5 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2716.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0279.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0325. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0370.
Convergence test p-value: 0.4276. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0366.
Convergence test p-value: 0.0021. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0391.
Convergence test p-value: 0.0233. Starting Monte Carlo maximum likelihood estimation (MCMLE):
Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0668.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Convergence test p-value: 0.6044. Optimizing with step length 1.0000.
Not converged with 95% confidence; increasing sample size.
Iteration 1 of at most 60:
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0104.
The log-likelihood improved by 0.0504.
Convergence test p-value: 0.0016. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.3003. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0084.
Convergence test p-value: 0.1720. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0707.
Convergence test p-value: 0.0105. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.1057. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0169.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0592.
Convergence test p-value: 0.0886. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Convergence test p-value: 0.1640. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0568.
Convergence test p-value: 0.3352. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0424.
Convergence test p-value: 0.0272. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0264.
Optimizing with step length 1.0000.
Convergence test p-value: 0.0842. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0038.
Convergence test p-value: 0.0031. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0708.
Convergence test p-value: 0.0455. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0306.
Convergence test p-value: 0.0007. Converged with 95% confidence.
Finished MCMLE.
The log-likelihood improved by 0.0244.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Convergence test p-value: 0.0419. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0327.
The log-likelihood improved by 0.0580.
Convergence test p-value: 0.0472. Converged with 95% confidence.
Convergence test p-value: 0.0714. Finished MCMLE.
Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0151.
Convergence test p-value: < 0.0001. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0455.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Convergence test p-value: 0.3309. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0226.
Convergence test p-value: 0.1005. Not converged with 95% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2893.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0072.
Convergence test p-value: 0.1829. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0665.
Convergence test p-value: 0.4342. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0155.
Convergence test p-value: 0.0900. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1507.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0088.
Convergence test p-value: 0.0290. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0288.
Convergence test p-value: 0.0455. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0116.
Convergence test p-value: 0.0877. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0231.
Convergence test p-value: 0.0163. Converged with 95% confidence.
Optimizing with step length 1.0000.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0520.
The log-likelihood improved by 0.0399.
Convergence test p-value: 0.0651. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Convergence test p-value: 0.0646. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0629.
Convergence test p-value: 0.0251. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0239.
Convergence test p-value: 0.0032. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0423.
Convergence test p-value: 0.2517. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0576.
Optimizing with step length 1.0000.
Convergence test p-value: 0.3855. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0577.
Convergence test p-value: 0.4215. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0026.
Convergence test p-value: 0.1157. Not converged with 95% confidence; increasing sample size.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1677.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0802.
Convergence test p-value: 0.3533. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0455.
Convergence test p-value: 0.0441. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0605.
Convergence test p-value: 0.0322. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1437.
Estimating equations are not within tolerance region.
Estimating equations did not move closer to tolerance region more than 1 time(s) in 4 steps; increasing sample size.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0293.
Convergence test p-value: 0.0039. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0318.
Convergence test p-value: 0.0096. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.3040.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0450.
Convergence test p-value: 0.5474. Not converged with 95% confidence; increasing sample size.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0029.
Convergence test p-value: 0.0008. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0172.
Convergence test p-value: 0.2161. Not converged with 95% confidence; increasing sample size.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0192.
Convergence test p-value: 0.0104. Converged with 95% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
> 
> 
> ergm_sim_estim = matrix(0, nrow = nsims, ncol = 4)
> for(i in 1:nsims)
+ {
+   if(!is.null(ergm_sim_list[[i]]))
+   {
+     est.params <- ergm_sim_list[[i]]$coefficients
+     ergm_sim_estim[i,] <- est.params
+   }
+   else {ergm_sim_estim[i,] = c(NA, NA, NA, NA)}
+ }
> 
> ergm_result = apply(ergm_sim_estim, 2, median, na.rm = T)
> ergm_result
[1] -4.000031996  2.095680368  0.005165524  0.037217360
> theta
[1] -4.00  2.00  0.01  0.01
> ergm_q = apply(ergm_sim_estim, 2, quantile, c(0.01,0.99), na.rm = T)
> 
> #### DEGENERACIES
> degen = which(!complete.cases(ergm_sim_estim))
> # 58 of em
> degen
integer(0)
> 
> if(length(degen) > 0 ){
+ degen_list = ergm_sim_list[[]]
+ ergm_degen_list = foreach(i = 1:length(degen)) %dopar% {
+   skip_to_next <- FALSE
+   formula <- g_sim[[degen[i]]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = tryCatch(withTimeout(ergm(formula, eval.loglik=FALSE,
+                                         control=control.ergm(init=theta, MCMLE.confidence=0.95
+                                        #   # MCMC.burnin=100000,
+                                        #   # MCMC.interval=1000,
+                                        #   # MCMC.samplesize = 5000,
+                                           )
+   ), timeout = 5*60, onTimeout = "error"),
+   error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
+ 
+ ergm_degen_estim = matrix(0, nrow = length(degen), ncol = 4)
+ for(i in 1:length(degen))
+ {
+   if(!is.null(ergm_degen_list[[i]]))
+   {
+     est.params <- ergm_degen_list[[i]]$coefficients
+     ergm_degen_estim[i,] <- est.params
+     ergm_sim_estim[degen[i],] <- est.params
+   }
+   else {ergm_degen_estim[i,] = c(NA, NA, NA, NA)}
+ }
+ }
> 
> # compare mean-values
> g3 = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+ simulate(g_sim[[i]]  ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = ergm_sim_estim[i,],         
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  405.95  357.73 3346.61  135.27
> ergm_mv = colMeans(g3)
> 
> ### Compute ERGM Results
> ergm_sim_list_tapered = foreach(i = 1:nsims) %dopar% {
+   # cat("***********************************\n")
+   # cat(paste("estimating sample" ,i, "\n"))
+   # cat("***********************************\n")
+   skip_to_next <- FALSE
+   formula <- g_sim[[i]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim = 
+     tryCatch(withTimeout(
+                           ergm.tapered(formula, eval.loglik=FALSE,
+                                control=control.ergm.tapered(init = init_params[i,])),
+                timeout = 5*60, onTimeout = "error"),
+                error = function(e) {skip_to_next <<- NULL})
+   ergm_sim
+ }
[1] -4.31735821  2.14238612  0.02727916 -0.10238738
[1] -4.10929154  1.98319374[1]  0.01409081 -3.77160780  2.09097287 -0.01794933  0.13635093  0.05533747

[1] -3.882732058  1.956374063[1] -3.858830204  1.815826700 -0.000195615[1] -4.35915393  2.26895337  0.02296235 -0.17213466[1][1] -3.945615685  2.160383582 -0.006666581  0.046445782  0.006318387  0.008256241

 -3.64663451[1]  1.86155445 -4.24255676  2.14237183 -0.00913301  0.01319074  0.03451691

  0.196550766
  0.15555486[1]
 -4.030738999  2.132458820 -0.000928486  0.126751121
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Maximizing the pseudolikelihood.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Finished MPLE.
Finished MPLE.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0407.
The log-likelihood improved by 0.0410.
The log-likelihood improved by 0.0052.
Precision adequate. Performing one more iteration.
Precision adequate. Performing one more iteration.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Iteration 2 of at most 60:
Iteration 2 of at most 60:
The log-likelihood improved by 0.0525.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0422.
The log-likelihood improved by 0.0522.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1939.
Increasing target MCMC sample size to 640, ESS to 64.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0177.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0146.
Increasing target MCMC sample size to 670, ESS to 67.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0227.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0228.
Increasing target MCMC sample size to 660, ESS to 66.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0177.
Increasing target MCMC sample size to 700, ESS to 70.
The log-likelihood improved by 0.0100.
Iteration 3 of at most 60:
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0015.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -3.89209693  2.26621724 -0.02477562  0.17645548
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0113.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0269.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0014.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -4.36265962  2.21708334  0.01907933  0.02303468
[1] -3.7690716241  2.0461744229  0.0005678037 -0.1439624872
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0149.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Maximizing the pseudolikelihood.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Finished MPLE.
Stopping at the initial estimate.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0510.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -4.30203991  2.08100422  0.03059057 -0.08787550
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0856.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0077.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.8332577761  1.7667046808  0.0001944069  0.1180454867
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0049.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0198.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
[1] -4.34232959  2.26254048  0.02649694 -0.20418585
The log-likelihood improved by 0.0031.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0088.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0357.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0246.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0050.
Increasing target MCMC sample size to 1210, ESS to 121.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1362.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0299.
Increasing target MCMC sample size to 1090, ESS to 109.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0242.
Increasing target MCMC sample size to 690, ESS to 69.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0333.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0739.
Increasing target MCMC sample size to 860, ESS to 86.
Iteration 3 of at most 60:
[1] -4.18485395  2.12211225  0.01477447 -0.01866412
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0532.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0642.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0735.
Increasing target MCMC sample size to 2030, ESS to 203.
The log-likelihood improved by 0.0084.
Iteration 6 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0249.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0143.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0324.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0152.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0157.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0174.
The log-likelihood improved by 0.0107.
Precision adequate twice. Stopping.
Precision adequate. Performing one more iteration.
Finished MCMLE.
Iteration 2 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.19259075  1.79074180 -0.02792776  0.10221451
[1] -3.849995317  1.865864864  0.005389353  0.070497332
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0017.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Optimizing with step length 1.0000.
Evaluating the predictor and response matrix.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.1281.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0044.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
[1] -4.38353980  2.14893846  0.03457538 -0.32025076
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Iteration 1 of at most 60:
The log-likelihood improved by 0.0089.
Increasing target MCMC sample size to 910, ESS to 91.
Iteration 7 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0138.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0176.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -4.1092576  2.0832614  0.0131954  0.0411697
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0531.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0391.
Increasing target MCMC sample size to 900, ESS to 90.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0296.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1082.
The log-likelihood improved by 0.0585.
Precision adequate. Performing one more iteration.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
[1] -4.33769577  2.12130649  0.02849586 -0.05807071
The log-likelihood improved by 0.0300.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0212.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0382.
Increasing target MCMC sample size to 1660, ESS to 166.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0624.
Increasing target MCMC sample size to 1670, ESS to 167.
Iteration 6 of at most 60:
[1] -4.45831890  2.14576080  0.03528906 -0.09407912
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0306.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0322.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0240.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -3.43578507  2.03013270 -0.03628531  0.07761394
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0947.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0164.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0343.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.1694.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0233.
Precision adequate twice. Stopping.
Finished MCMLE.
[1] -4.1201100  1.9268932  0.0202271 -0.0163573
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0498.
Increasing target MCMC sample size to 710, ESS to 71.
Optimizing with step length 1.0000.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0188.
Precision adequate. Performing one more iteration.
Finished MPLE.
Stopping at the initial estimate.
Iteration 9 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
[1] -4.03710288  1.97410130  0.01181926  0.04235846
The log-likelihood improved by 0.0474.
Increasing target MCMC sample size to 1130, ESS to 113.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0352.
Increasing target MCMC sample size to 770, ESS to 77.
Iteration 3 of at most 60:
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0392.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.2281.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0236.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0559.
Increasing target MCMC sample size to 1890, ESS to 189.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0747.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0747.
Optimizing with step length 1.0000.
Increasing target MCMC sample size to 1850, ESS to 185.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0118.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0179.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0354.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0290.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0065.
Increasing target MCMC sample size to 1010, ESS to 101.
Iteration 5 of at most 60:
[1] -4.100842407  2.167529045  0.002677685  0.084540317
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0057.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0101.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Increasing target MCMC sample size to 710, ESS to 71.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0152.
Increasing target MCMC sample size to 850, ESS to 85.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0130.
Increasing target MCMC sample size to 1100, ESS to 110.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
[1] -3.898446384  2.101898233 -0.002390607 -0.039674979
The log-likelihood improved by 0.0861.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0435.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
[1] -4.072382263  2.198154335  0.003651912  0.013826482Starting Monte Carlo maximum likelihood estimation (MCMLE):

Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0460.
Increasing target MCMC sample size to 1620, ESS to 162.
Iteration 6 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0152.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0508.
Increasing target MCMC sample size to 1520, ESS to 152.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0645.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0238.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0702.
Precision adequate. Performing one more iteration.
The log-likelihood improved by 0.0755.
Iteration 2 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0294.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0112.
Increasing target MCMC sample size to 750, ESS to 75.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0109.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0338.
Increasing target MCMC sample size to 760, ESS to 76.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0280.
Increasing target MCMC sample size to 980, ESS to 98.
Iteration 5 of at most 60:
[1] -3.32172896  1.87172858 -0.01847706  0.04716372
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0266.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0446.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0118.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0297.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0343.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0204.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0490.
Increasing target MCMC sample size to 1120, ESS to 112.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0522.
Optimizing with step length 1.0000.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0237.
Precision adequate twice. Stopping.
Optimizing with step length 1.0000.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0391.
Increasing target MCMC sample size to 940, ESS to 94.
The log-likelihood improved by 0.1406.
Iteration 5 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -3.75507274  1.97628870 -0.00597774  0.11099803
The log-likelihood improved by 0.0154.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
[1] -3.931421161  2.144581325  0.005400499 -0.122448250
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0327.
Increasing target MCMC sample size to 640, ESS to 64.
Iteration 3 of at most 60:
[1] -4.21276445  2.05731399  0.01914995  0.02972002
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0138.
Increasing target MCMC sample size to 1710, ESS to 171.
Iteration 8 of at most 60:
The log-likelihood improved by 0.1548.
Increasing target MCMC sample size to 1790, ESS to 179.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0174.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -4.061108167  2.184496132  0.009393101 -0.106689057
The log-likelihood improved by 0.0238.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0473.
Increasing target MCMC sample size to 1880, ESS to 188.
Iteration 6 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Optimizing with step length 1.0000.
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0241.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0199.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0145.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.05206619  1.81208662  0.01842711  0.09495172
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1946.
Increasing target MCMC sample size to 1150, ESS to 115.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0566.
Increasing target MCMC sample size to 700, ESS to 70.
Iteration 3 of at most 60:
The log-likelihood improved by 0.1053.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1658.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0106.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0199.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
The log-likelihood improved by 0.0636.
[1] -3.99572685  1.98630776  0.01757025 -0.03762782
Increasing target MCMC sample size to 2060, ESS to 206.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0037.
Starting maximum pseudolikelihood estimation (MPLE):
Increasing target MCMC sample size to 730, ESS to 73.
Evaluating the predictor and response matrix.
Iteration 3 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0506.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1117.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0236.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0466.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0220.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -4.04576384  1.76145582  0.02107673  0.03381317
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0023.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.2393.
Increasing target MCMC sample size to 840, ESS to 84.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0096.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0210.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0175.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 1 of at most 60:
[1] -4.56958604  2.21666569  0.04193842 -0.16385681
[1] -3.62831169  1.97086303 -0.02405991  0.25248164
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0013.
Precision adequate twice. Stopping.
The log-likelihood improved by 0.0713.
Finished MCMLE.
Increasing target MCMC sample size to 850, ESS to 85.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
[1]Optimizing with step length 1.0000.
 -4.41081469  2.18652605  0.02215766  0.03994147
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0043.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0139.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0113.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
[1] -4.074749776  2.091139508  0.007905607  0.035280532
Optimizing with step length 1.0000.
[1] -3.5589807  2.0220280 -0.0186922  0.0923478
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0088.
Precision adequate twice. Stopping.
Finished MPLE.
Finished MCMLE.
Stopping at the initial estimate.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0058.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
[1] -4.23435522  2.41973400  0.01442438 -0.16438490
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0470.
Starting maximum pseudolikelihood estimation (MPLE):
Precision adequate. Performing one more iteration.
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Iteration 4 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
The log-likelihood improved by 0.0217.
Stopping at the initial estimate.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0066.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0368.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1463.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0162.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0284.
The log-likelihood improved by 0.0093.
Increasing target MCMC sample size to 1060, ESS to 106.
Increasing target MCMC sample size to 760, ESS to 76.
Iteration 5 of at most 60:
Iteration 3 of at most 60:
[1] -3.32424211  1.86596853 -0.02596802  0.17912669
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0024.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1371.
Precision adequate. Performing one more iteration.
The log-likelihood improved by 0.0283.
Iteration 2 of at most 60:
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 3 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -3.58248722  2.16120493 -0.02489282  0.08506161
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0600.
Increasing target MCMC sample size to 750, ESS to 75.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0264.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0038.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0224.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0065.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.1529.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1097.
Increasing target MCMC sample size to 1820, ESS to 182.
[1] -3.911536877  2.263635102 -0.001362641 -0.033312953
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0125.
Increasing target MCMC sample size to 740, ESS to 74.
Finished MPLE.
Iteration 3 of at most 60:
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0887.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0149.
The log-likelihood improved by 0.0259.
Precision adequate twice. Stopping.
Increasing target MCMC sample size to 1030, ESS to 103.
Finished MCMLE.
Iteration 5 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0334.
Increasing target MCMC sample size to 950, ESS to 95.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0699.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -3.76447658  2.08739606 -0.02066461  0.13563893
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0063.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0084.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0120.
Increasing target MCMC sample size to 760, ESS to 76.
Iteration 3 of at most 60:
[1] -3.58808676  2.00024838 -0.03185536  0.22048107
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0377.
Increasing target MCMC sample size to 1500, ESS to 150.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1030.
Increasing target MCMC sample size to 2060, ESS to 206.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0165.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0895.
Increasing target MCMC sample size to 1300, ESS to 130.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0441.
Increasing target MCMC sample size to 1040, ESS to 104.
Iteration 6 of at most 60:
The log-likelihood improved by 0.1661.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.1131.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0135.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.038078651  2.096565945  0.003153148  0.013710514
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0533.
Increasing target MCMC sample size to 880, ESS to 88.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0341.
Increasing target MCMC sample size to 760, ESS to 76.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0264.
Increasing target MCMC sample size to 1740, ESS to 174.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0081.
Increasing target MCMC sample size to 1540, ESS to 154.
Optimizing with step length 1.0000.
Iteration 7 of at most 60:
The log-likelihood improved by 0.1001.
Increasing target MCMC sample size to 2180, ESS to 218.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0075.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0853.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0240.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0006.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0872.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0663.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0109.
Increasing target MCMC sample size to 720, ESS to 72.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0705.
Increasing target MCMC sample size to 910, ESS to 91.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0056.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0209.
Increasing target MCMC sample size to 970, ESS to 97.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0153.
Increasing target MCMC sample size to 660, ESS to 66.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0173.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
[1] -4.42541318  2.28354975  0.02809293 -0.16195727
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0056.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.09856801  1.94634852  0.01678607  0.05019874
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0066.
Optimizing with step length 1.0000.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.1426.
Increasing target MCMC sample size to 2000, ESS to 200.
Optimizing with step length 1.0000.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0668.
Increasing target MCMC sample size to 1750, ESS to 175.
Iteration 6 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0532.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0111.
Precision adequate. Performing one more iteration.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0061.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -3.715794824  1.984382837 -0.003632302  0.048790883
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0400.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0286.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0061.
Increasing target MCMC sample size to 850, ESS to 85.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0090.
Increasing target MCMC sample size to 660, ESS to 66.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
[1] -3.60929721  2.07950384 -0.02484793  0.18079566
The log-likelihood improved by 0.0399.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0110.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -4.22569416  2.13452254  0.01792656 -0.09780644
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0091.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
The log-likelihood improved by 0.0431.
Increasing target MCMC sample size to 800, ESS to 80.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0451.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0199.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0168.
Increasing target MCMC sample size to 990, ESS to 99.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0711.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0142.
The log-likelihood improved by 0.0099.
Precision adequate twice. Stopping.
Precision adequate. Performing one more iteration.
Finished MCMLE.
Iteration 4 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0364.
Increasing target MCMC sample size to 900, ESS to 90.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0626.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -4.204132312  2.093333616  0.017841237  0.009506875The log-likelihood improved by 0.0555.

Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.1501.
Increasing target MCMC sample size to 1060, ESS to 106.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0145.
Increasing target MCMC sample size to 1910, ESS to 191.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0128.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -3.45066899  1.76692158 -0.00877342  0.06581505
The log-likelihood improved by 0.1521.
Increasing target MCMC sample size to 1790, ESS to 179.
Iteration 7 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0073.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1455.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -3.8029329904  1.8992613158  0.0006521448  0.0461815693
The log-likelihood improved by 0.0262.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0047.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -4.22933963  2.08205634  0.01806889 -0.01440705
The log-likelihood improved by 0.0061.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0097.
Increasing target MCMC sample size to 830, ESS to 83.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0212.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -3.55612450  1.96701929 -0.02133181  0.09655751
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0237.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0484.
Precision adequate. Performing one more iteration.
Optimizing with step length 1.0000.
Iteration 9 of at most 60:
The log-likelihood improved by 0.0630.
Optimizing with step length 1.0000.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0156.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1021.
Increasing target MCMC sample size to 2010, ESS to 201.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0634.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -4.54190918  2.04930684  0.04656899 -0.09263873
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
The log-likelihood improved by 0.0561.
Stopping at the initial estimate.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0194.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -4.008825649  1.963125282  0.014485190 -0.005773752
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0427.
Optimizing with step length 1.0000.
Precision adequate twice. Stopping.
Finished MCMLE.
Maximizing the pseudolikelihood.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0127.
Increasing target MCMC sample size to 700, ESS to 70.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0033.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -3.974588322  2.288635355  0.005183076 -0.122527544
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0241.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.40478068  1.80272997 -0.03369297  0.28638544
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0312.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0193.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0413.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -3.51492406  1.83028733 -0.01906728  0.16645792
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
[1] -4.19139155  1.89102527  0.01408973  0.17004252
Finished MPLE.
The log-likelihood improved by 0.0219.
Stopping at the initial estimate.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0074.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0270.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0140.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0244.
Increasing target MCMC sample size to 1020, ESS to 102.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0476.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0084.
The log-likelihood improved by 0.0159.
Precision adequate. Performing one more iteration.
Precision adequate twice. Stopping.
Iteration 2 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0175.
Increasing target MCMC sample size to 810, ESS to 81.
Iteration 3 of at most 60:
[1] -4.46504944  2.35471799  0.03268622 -0.24141533
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0313.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0070.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0129.
Increasing target MCMC sample size to 890, ESS to 89.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0453.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0927.
Increasing target MCMC sample size to 800, ESS to 80.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0543.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0339.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.51452345  2.17063339 -0.01842642  0.01199486
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0097.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0091.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Optimizing with step length 1.0000.
Iteration 1 of at most 60:
The log-likelihood improved by 0.0300.
Increasing target MCMC sample size to 1120, ESS to 112.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0256.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0271.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -3.28149172  1.89805493 -0.02885442  0.10833265
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0087.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0606.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0704.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0385.
Increasing target MCMC sample size to 1020, ESS to 102.
Iteration 5 of at most 60:
The log-likelihood improved by 0.0637.
Increasing target MCMC sample size to 2200, ESS to 220.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
[1] -3.843907e+00  1.928958e+00  9.564638e-05  7.672666e-02
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0932.
The log-likelihood improved by 0.0084.
Increasing target MCMC sample size to 1150, ESS to 115.
Precision adequate twice. Stopping.
Iteration 7 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
The log-likelihood improved by 0.0019.
Stopping at the initial estimate.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.17880488  2.10779498  0.02439474 -0.08133853
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -3.993090399  2.132990944  0.004006424 -0.044637873
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Optimizing with step length 1.0000.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0247.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0134.
Increasing target MCMC sample size to 950, ESS to 95.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 5 of at most 60:
The log-likelihood improved by 0.0008.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -3.3303025  1.8916429 -0.0229163  0.1507443
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0229.
Increasing target MCMC sample size to 1650, ESS to 165.
Iteration 8 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0113.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0139.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 3 of at most 60:
The log-likelihood improved by 0.1429.
Increasing target MCMC sample size to 2060, ESS to 206.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0216.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0600.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0849.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0301.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0254.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0083.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -4.053174962  2.136247902 -0.003050991  0.151147849
The log-likelihood improved by 0.0100.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
[1] -3.30245235  2.04600738 -0.03367410  0.07175727
[1] -4.41524361  2.42171990  0.01617040 -0.08735991
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Optimizing with step length 1.0000.
Maximizing the pseudolikelihood.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Finished MPLE.
Stopping at the initial estimate.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0779.
Increasing target MCMC sample size to 1080, ESS to 108.
Iteration 5 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0036.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0651.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2012.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0497.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0535.
Increasing target MCMC sample size to 900, ESS to 90.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0685.
Increasing target MCMC sample size to 1700, ESS to 170.
Iteration 6 of at most 60:
The log-likelihood improved by 0.1136.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0009.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.3625.
Increasing target MCMC sample size to 780, ESS to 78.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0161.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -5.0207244  2.5412814  0.0645392 -0.3065236
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0109.
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Increasing target MCMC sample size to 690, ESS to 69.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0081.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.68221441  1.95725720 -0.01520547  0.13175632
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0133.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0274.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0092.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0175.
Precision adequate twice. Stopping.
Iteration 1 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0364.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
[1] -3.693880736  1.875756066  0.006042142 -0.080830637
The log-likelihood improved by 0.1009.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0973.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Optimizing with step length 1.0000.
Stopping at the initial estimate.
The log-likelihood improved by 0.0101.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0241.
The log-likelihood improved by 0.0023.
Increasing target MCMC sample size to 890, ESS to 89.
Precision adequate twice. Stopping.
Iteration 5 of at most 60:
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0152.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0311.
The log-likelihood improved by 0.0141.
Precision adequate. Performing one more iteration.
Increasing target MCMC sample size to 670, ESS to 67.
Iteration 2 of at most 60:
Iteration 3 of at most 60:
[1] -4.14381845  2.14464377  0.01839456 -0.05945317
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0122.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0434.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0052.
Increasing target MCMC sample size to 730, ESS to 73.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0213.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0405.
Increasing target MCMC sample size to 1680, ESS to 168.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0299.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
[1] -4.0096521962  2.2419940047 -0.0002985868  0.0097868687
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
The log-likelihood improved by 0.0178.
Stopping at the initial estimate.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0160.
Increasing target MCMC sample size to 880, ESS to 88.
Iteration 5 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.1305.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
[1] -4.12707791  2.19735343  0.01636275 -0.01381345
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0221.
Precision adequate. Performing one more iteration.
Maximizing the pseudolikelihood.
Iteration 4 of at most 60:
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0382.
Increasing target MCMC sample size to 1880, ESS to 188.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0781.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0540.
Increasing target MCMC sample size to 920, ESS to 92.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1]The log-likelihood improved by 0.1069.
 -3.886276178  2.053922904 -0.001580424  0.040111145
Increasing target MCMC sample size to 1870, ESS to 187.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0326.
Increasing target MCMC sample size to 1140, ESS to 114.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0203.
Precision adequate. Performing one more iteration.
Starting maximum pseudolikelihood estimation (MPLE):
Iteration 2 of at most 60:
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0781.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0348.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0788.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0466.
Increasing target MCMC sample size to 810, ESS to 81.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0059.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0268.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
[1] -4.21807922  2.00163717  0.01369164  0.17003895
The log-likelihood improved by 0.0246.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0114.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Precision adequate. Performing one more iteration.
Iteration 9 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0125.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0065.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.5527768  2.0966803 -0.0324916  0.1573612
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0113.
Increasing target MCMC sample size to 1130, ESS to 113.
Iteration 5 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0056.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0081.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
[1] -3.815087696  1.882982715 -0.005590025  0.138781615
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0153.
Precision adequate twice. Stopping.
Finished MCMLE.
Maximizing the pseudolikelihood.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0379.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
[1] -4.47131107  2.31345860  0.02474392 -0.06353509
[1] -4.050244775  2.126535256  0.009280939 -0.002800643
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.2722.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0124.
Precision adequate twice. Stopping.
Finished MCMLE.
The log-likelihood improved by 0.0575.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0412.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.97176969  1.89220862  0.01525742  0.03920452
Optimizing with step length 1.0000.
[1] -4.16493357  2.25873871  0.02251904 -0.22552341
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.3192.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Optimizing with step length 1.0000.
Stopping at the initial estimate.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0423.
Increasing target MCMC sample size to 750, ESS to 75.
Iteration 3 of at most 60:
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0132.
Increasing target MCMC sample size to 1620, ESS to 162.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0446.
Increasing target MCMC sample size to 710, ESS to 71.
Iteration 3 of at most 60:
The log-likelihood improved by 0.1461.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0184.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0399.
Increasing target MCMC sample size to 740, ESS to 74.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1265.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1365.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 2 of at most 60:
The log-likelihood improved by 0.0947.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0247.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -3.96848087  1.99500455  0.01818931 -0.11151635
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0210.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0909.
Increasing target MCMC sample size to 800, ESS to 80.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0213.
Increasing target MCMC sample size to 830, ESS to 83.
Iteration 3 of at most 60:
The log-likelihood improved by 0.0229.
Precision adequate twice. Stopping.
The log-likelihood improved by 0.0828.
Finished MCMLE.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.59761991  2.02218723 -0.01321255  0.06814804
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0329.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0106.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0458.
Precision adequate twice. Stopping.
Optimizing with step length 1.0000.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0512.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -4.09331667  2.07947603  0.01579364 -0.09892632
The log-likelihood improved by 0.0396.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
The log-likelihood improved by 0.0179.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0570.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0353.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0391.
Increasing target MCMC sample size to 1130, ESS to 113.
The log-likelihood improved by 0.0534.
Iteration 5 of at most 60:
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -4.44885287  2.40941719  0.02747569 -0.19799435
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0489.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
The log-likelihood improved by 0.0663.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
[1] -3.87547482  2.22113676 -0.02385189  0.15884217
The log-likelihood improved by 0.0534.
Increasing target MCMC sample size to 1860, ESS to 186.
Iteration 6 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0280.
Increasing target MCMC sample size to 670, ESS to 67.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
The log-likelihood improved by 0.0279.
Precision adequate twice. Stopping.
Finished MCMLE.
Iteration 1 of at most 60:
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1]Optimizing with step length 1.0000.
 -3.46985145  2.17296087 -0.03809342  0.03369945
The log-likelihood improved by 0.0188.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0130.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0337.
Increasing target MCMC sample size to 790, ESS to 79.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0204.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0141.
Increasing target MCMC sample size to 1010, ESS to 101.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0930.
Increasing target MCMC sample size to 2170, ESS to 217.
Iteration 7 of at most 60:
The log-likelihood improved by 0.0441.
Increasing target MCMC sample size to 770, ESS to 77.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0171.
Increasing target MCMC sample size to 1500, ESS to 150.
Iteration 6 of at most 60:
The log-likelihood improved by 0.0068.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0066.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0271.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
The log-likelihood improved by 0.0721.
Precision adequate. Performing one more iteration.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0023.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.67835091  2.21188299 -0.01050378 -0.13190447
Optimizing with step length 1.0000.
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
The log-likelihood improved by 0.0208.
Increasing target MCMC sample size to 920, ESS to 92.
Iteration 5 of at most 60:
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0381.
Increasing target MCMC sample size to 950, ESS to 95.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0046.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0280.
Precision adequate. Performing one more iteration.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0126.
Increasing target MCMC sample size to 1440, ESS to 144.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0036.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2560.
Increasing target MCMC sample size to 650, ESS to 65.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0231.
Precision adequate. Performing one more iteration.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0033.
Increasing target MCMC sample size to 1570, ESS to 157.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0291.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.21151649  2.22826556  0.01054156  0.03358406
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Optimizing with step length 1.0000.
Finished MPLE.
Stopping at the initial estimate.
The log-likelihood improved by 0.0505.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0249.
Precision adequate. Performing one more iteration.
Iteration 8 of at most 60:
The log-likelihood improved by 0.0047.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.0062.
Precision adequate twice. Stopping.
Finished MCMLE.
Optimizing with step length 1.0000.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
The log-likelihood improved by 0.1320.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
[1] -4.64016951  2.30506632  0.02958614  0.02299764
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0082.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0310.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0023.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0173.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0380.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -4.41491737  2.34733926  0.02655090 -0.07971675
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1672.
Increasing target MCMC sample size to 680, ESS to 68.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0274.
Precision adequate. Performing one more iteration.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0281.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
[1] -3.65730743  2.19927742 -0.03352885  0.11600837
Starting maximum pseudolikelihood estimation (MPLE):
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stopping at the initial estimate.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.2237.
Precision adequate. Performing one more iteration.
Iteration 2 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0103.
Precision adequate twice. Stopping.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
> 
> ergm_sim_estim_tapered = matrix(0, nrow = nsims, ncol = 4)
> for(i in 1:nsims)
+ {
+   if(!is.null(ergm_sim_list_tapered[[i]]))
+   {
+     est.params <- ergm_sim_list_tapered[[i]]$coefficients
+     ergm_sim_estim_tapered[i,] <- est.params
+   }
+   else {ergm_sim_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
> 
> #### DEGENERACIES
> degen_tapered = which(!complete.cases(ergm_sim_estim_tapered))
> # 58 of em
> degen_tapered
integer(0)
> 
> if(length(degen) > 0 ){
+ degen_list_tapered = ergm_sim_list_tapered[[]]
+ ergm_degen_list_tapered = foreach(i = 1:length(degen_tapered)) %dopar% {
+   skip_to_next <- FALSE
+   formula <- g_sim[[degen[i]]] ~ edges + nodematch("x") + kstar(2) + triangles
+   ergm_sim_tapered = tryCatch(withTimeout(ergm(formula, eval.loglik=FALSE,
+                                         control=control.ergm(init=theta, MCMLE.confidence=0.95
+                                        #   # MCMC.burnin=100000,
+                                        #   # MCMC.interval=1000,
+                                        #   # MCMC.samplesize = 5000,
+                                           )
+   ), timeout = 5*60, onTimeout = "error"),
+   error = function(e) {skip_to_next <<- NULL})
+   ergm_sim_tapered
+ }
+ 
+ ergm_degen_estim_tapered = matrix(0, nrow = length(degen), ncol = 4)
+ for(i in 1:length(degen_tapered))
+ {
+   if(!is.null(ergm_degen_list_tapered[[i]]))
+   {
+     est.params <- ergm_degen_list_tapered[[i]]$coefficients
+     ergm_degen_estim_tapered[i,] <- est.params
+     ergm_sim_estim_tapered[degen_tapered[i],] <- est.params
+   }
+   else {ergm_degen_estim_tapered[i,] = c(NA, NA, NA, NA)}
+ }
+ }
> 
> ergm_result_tapered = apply(ergm_sim_estim_tapered, 2, median, na.rm = T)
> ergm_result_tapered
[1] -4.040024332  2.090388906  0.008597485  0.046487140
> 
> # compare mean-values
> g3_tapered = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+ #g3_tapered <- simulate(g_sim[[1]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+ simulate_ergm.tapered(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = ergm_sim_estim_tapered[i,],         
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  405.95  357.73 3346.61  135.27
> ergm_mv_tapered = colMeans(g3_tapered)
> ergm_mv_tapered
       Taper(0.00061576354679803)~edges Taper(0.000708215297450425)~nodematch.x 
                                406.104                                 357.801 
     Taper(7.34645900675874e-05)~kstar2     Taper(0.00159235668789809)~triangle 
                               3348.568                                 135.401 
> 
> # Model statistics ‘kstar2’ and ‘triangle’ are not varying. This may indicate 
> # that the observed data occupies an extreme point in the sample space or that 
> # the estimation has reached a dead-end configuration.
> # Warning: Model statistics ‘nodematch.x’ are linear combinations of some set of 
> # preceding statistics at the current stage of the estimation. This may indicate 
> # that the model is nonidentifiable.
> # Error in ergm.MCMLE(init, nw, model, initialfit = (initialfit <- NULL),  : 
> # Unconstrained MCMC sampling did not mix at all. Optimization cannot continue.
> # In addition: Warning message:
> # In ergm_MCMC_sample(s, control, theta = mcmc.init, verbose = max(verbose -  :
> # Unable to reach target effective size in iterations alotted.
> 
> 
> ##################
> #                #
> #     MFERGM     #
> #                #
> ##################
> 
> # Use "theta" on mfergm instead
> tobs <- data.frame(matrix(NA, ncol = 4, nrow = nsims))
> names(tobs) <- c("edges", "x", "kstar2", "triangles")
> for (i in 1:nsims) 
+ {
+   tobs[i,] = g_sim_stats[i,] / (c((n^2)/2, (n^2)/2, (n^3)/2 , (n^3)/2 ))  
+ }
> 
> ### Compute MFERGM Results
> mfergm_estim = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+   pars <- init_params[i,] * c(.5,.5,n,n)
+   addpars <- list(n=n, tobs = tobs[i,], x=x, ninit=1)
+   cd.est <- tryCatch(optimx(pars, fn = loglikmf.model4, 
+                             method = "BFGS", 
+                             control = list(fnscale = -1), addpars = addpars), 
+                      error = function(e) {return(c(NA, NA, NA, NA))})
+   as.numeric(cd.est[1:4])
+ }
> mfergm_estim = matrix(c(mfergm_estim[,1]*2, mfergm_estim[,2]*2, mfergm_estim[,3]/n, mfergm_estim[,4]/n),
+                nrow = nsims)
> mfergm_result_med = apply(mfergm_estim, 2, median, na.rm = T) 
> mfergm_result = apply(mfergm_estim, 2, median, na.rm = T) 
> cbind(theta,mfergm_result_med,mfergm_result)
     theta mfergm_result_med mfergm_result
[1,] -4.00      -4.056282208  -4.056282208
[2,]  2.00       2.089986230   2.089986230
[3,]  0.01      -0.002518959  -0.002518959
[4,]  0.01       0.017207589   0.017207589
> 
> #### DEGENERACIES
> degen_mfergm = which(!complete.cases(mfergm_estim))
> # 58 of em
> degen_mfergm
[1]  9 14 32 35 74 99
> 
> if(length(degen_mfergm) > 0){
+ # Replace with MPLE
+ for(i in 1:length(degen_mfergm)){
+   mfergm_estim[degen_mfergm[i],] <- init_params[degen_mfergm[i],]
+ }
+ }
> 
> mfergm_estim_bd <- mfergm_estim
> for(i in 1:nsims){
+  a = mfergm_estim_bd[i,] < ergm_q[1,]
+  mfergm_estim_bd[i,a] <- ergm_q[1,a]
+  a = mfergm_estim_bd[i,] > ergm_q[2,]
+  mfergm_estim_bd[i,a] <- ergm_q[2,a]
+ }
> 
> # compare mean values
> g5 = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = init_params[i,],    
+                output = "stats"
+ )
+ }
> MPLE_mv = colMeans(g5)
> MPLE_result = apply(init_params, 2, median, na.rm = T) 
> 
> # compare mean values
> g4 = foreach(i = 1:nsims, .combine = rbind) %dopar% {
+  simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles,
+                nsim = 10,
+                coef = mfergm_estim_bd[i,],    
+                output = "stats"
+ )
+ }
> colMeans(g_sim_stats)
[1]  405.95  357.73 3346.61  135.27
> mfergm_mv = colMeans(g4)
> mfergm_mv
      edges nodematch.x      kstar2    triangle 
    417.351     363.823    4213.977     241.299 
> 
> a <- cbind(theta, ergm_result, ergm_result_tapered, MPLE_result, mfergm_result)
> rownames(a) <- names(ergm_mv)
> colnames(a) <- c("true", "MCMC-MLE","Tapered","MPLE","MFVLE")
> a
             true     MCMC-MLE      Tapered        MPLE        MFVLE
edges       -4.00 -4.000031996 -4.040024332 -4.00923892 -4.056282208
nodematch.x  2.00  2.095680368  2.090388906  2.09105619  2.089986230
kstar2       0.01  0.005165524  0.008597485  0.00572132 -0.002518959
triangle     0.01  0.037217360  0.046487140  0.03375631  0.017207589
> 
> # compare mfergm result with "theta"
> theta
[1] -4.00  2.00  0.01  0.01
> ergm_result
[1] -4.000031996  2.095680368  0.005165524  0.037217360
> ergm_result_tapered
[1] -4.040024332  2.090388906  0.008597485  0.046487140
> mfergm_result
[1] -4.056282208  2.089986230 -0.002518959  0.017207589
> 
> 
> # results for report
> round(theta, 3) 
[1] -4.00  2.00  0.01  0.01
> round(colMeans(g_sim_stats), 2)
[1]  405.95  357.73 3346.61  135.27
> round(colMeans(init_params), 3)
[1] -3.971  2.080  0.004  0.015
> round(ergm_result, 3) 
[1] -4.000  2.096  0.005  0.037
> round(ergm_mv, 2) 
      edges nodematch.x      kstar2    triangle 
     406.72      358.00     3357.26      135.12 
> round(ergm_result_tapered, 3) 
[1] -4.040  2.090  0.009  0.046
> round(ergm_mv_tapered, 2) 
       Taper(0.00061576354679803)~edges Taper(0.000708215297450425)~nodematch.x 
                                 406.10                                  357.80 
     Taper(7.34645900675874e-05)~kstar2     Taper(0.00159235668789809)~triangle 
                                3348.57                                  135.40 
> round(mfergm_result, 3) 
[1] -4.056  2.090 -0.003  0.017
> round(mfergm_mv, 2) 
      edges nodematch.x      kstar2    triangle 
     417.35      363.82     4213.98      241.30 
> # / c(2,2,1/n,1/n)
> 
> 
> a <- cbind(round(colMeans(g_sim_stats), 2), round(ergm_mv, 2), round(ergm_mv_tapered,2), round(MPLE_mv,2), round(mfergm_mv, 2))
> rownames(a) <- names(ergm_mv)
> colnames(a) <- c("true", "MCMC-MLE","Tapered","MPLE", "MFVLE")
> a
               true MCMC-MLE Tapered    MPLE   MFVLE
edges        405.95   406.72  406.10  406.39  417.35
nodematch.x  357.73   358.00  357.80  358.15  363.82
kstar2      3346.61  3357.26 3348.57 3344.66 4213.98
triangle     135.27   135.12  135.40  134.27  241.30
> 
> # save.image("mfergm_params1_n100.RData")
> 
> hist(ergm_sim_estim[,4], main = NULL, xlab = "Triangle")
> hist(ergm_sim_estim_tapered[,4], main = NULL, xlab = "Triangle")
> hist(mfergm_estim[,4], main = NULL, xlab = "Triangle")
> 
> 
> outliers <- function(x, field = 1.5, na.rm = TRUE) 
+ {
+   qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm)
+   H <- field * IQR(x, na.rm = na.rm)
+   which(x < (qnt[1] - H) | x > (qnt[2] + H))
+ }
> 
> 
> 
> a  = is.na(ergm_sim_estim[,4])
> b  = is.na(mfergm_estim[,4])
> c = mfergm_estim[(!a)&(!b),]
> c1 = c[,4]
> d = ergm_sim_estim[(!a)&(!b),]
> d1 = d[,4]
> c1[c1 < -2] = d1[c1 < -2]
> plot(c1~d1, col = (c1 == d1) + 1, pch = 16)
> sum(c1 == d1)
[1] 1
> 
> f = c[-Reduce(union, list(outliers(c[,1], 0.6), outliers(c[,2], 0.3), outliers(c[,3], 1.5), outliers(c[,4], 1.5))),]
> 
> 
> 
> gtest_mf = matrix(nrow = nrow(c), ncol = 4)
> for (i in 1:nrow(c))
+ {
+   gtest_mf[i,] = simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1, 
+                           coef = c[i,],        
+                           output = "stats")
+ }
> gtest_mc = matrix(nrow = nrow(d), ncol = 4)
> for (i in 1:nrow(d))
+ {
+   gtest_mc[i,] = simulate(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1, 
+                           coef = d[i,],        
+                           output = "stats")
+ }
> gtest_mc_tapered = matrix(nrow = nrow(d), ncol = 4)
> for (i in 1:nrow(d))
+ {
+   gtest_mc_tapered[i,] = as.vector(simulate_ergm.tapered(g_sim[[i]] ~ edges+nodematch("x")+ kstar(2) + triangles, 
+                           nsim = 1, 
+                           coef = d[i,],        
+                           output = "stats"))
+ }
> colMeans(gtest_mf)
[1]   752.91   572.75 19620.41  3149.22
> colMeans(gtest_mc)
[1]  406.52  359.51 3354.07  136.08
> colMeans(gtest_mc_tapered)
[1]  406.98  357.92 3351.44  134.39
> 
> summary(ergm_sim_estim)
       V1               V2              V3                  V4          
 Min.   :-4.878   Min.   :1.751   Min.   :-0.049325   Min.   :-0.31613  
 1st Qu.:-4.221   1st Qu.:1.963   1st Qu.:-0.009490   1st Qu.:-0.08302  
 Median :-4.000   Median :2.096   Median : 0.005166   Median : 0.03722  
 Mean   :-3.977   Mean   :2.078   Mean   : 0.004317   Mean   : 0.01634  
 3rd Qu.:-3.722   3rd Qu.:2.178   3rd Qu.: 0.020818   3rd Qu.: 0.09709  
 Max.   :-3.249   Max.   :2.507   Max.   : 0.055943   Max.   : 0.29589  
> summary(gtest_mf)
       V1               V2               V3               V4          
 Min.   :  31.0   Min.   :   0.0   Min.   :    12   Min.   :    0.00  
 1st Qu.: 391.8   1st Qu.: 305.0   1st Qu.:  3208   1st Qu.:   94.75  
 Median : 489.5   Median : 384.5   Median :  4751   Median :  182.50  
 Mean   : 752.9   Mean   : 572.8   Mean   : 19620   Mean   : 3149.22  
 3rd Qu.: 804.5   3rd Qu.: 681.0   3rd Qu.: 12824   3rd Qu.:  799.50  
 Max.   :3114.0   Max.   :2159.0   Max.   :192240   Max.   :40378.00  
> summary(gtest_mc)
       V1              V2              V3             V4       
 Min.   :334.0   Min.   :294.0   Min.   :2298   Min.   : 57.0  
 1st Qu.:384.0   1st Qu.:340.8   1st Qu.:2968   1st Qu.:106.8  
 Median :401.0   Median :353.5   Median :3232   Median :129.0  
 Mean   :406.5   Mean   :359.5   Mean   :3354   Mean   :136.1  
 3rd Qu.:430.2   3rd Qu.:379.0   3rd Qu.:3699   3rd Qu.:161.0  
 Max.   :490.0   Max.   :431.0   Max.   :5020   Max.   :255.0  
> summary(g_sim_stats)
       V1              V2              V3             V4       
 Min.   :355.0   Min.   :310.0   Min.   :2546   Min.   : 68.0  
 1st Qu.:390.0   1st Qu.:346.0   1st Qu.:3097   1st Qu.:117.0  
 Median :402.0   Median :354.0   Median :3297   Median :133.0  
 Mean   :405.9   Mean   :357.7   Mean   :3347   Mean   :135.3  
 3rd Qu.:422.2   3rd Qu.:372.0   3rd Qu.:3568   3rd Qu.:151.2  
 Max.   :466.0   Max.   :411.0   Max.   :4382   Max.   :210.0  
> 
> 
> gtest_mf_tri = gtest_mf[gtest_mf[,4]<60, 4]
> 
> hist(ergm_sim_estim[,1])
> hist(ergm_sim_estim[,2])
> hist(ergm_sim_estim[,3])
> hist(ergm_sim_estim[,4])
> hist(f[,1])
> hist(f[,2])
> hist(f[,3])
> hist(f[,4])
> 
> 
> gtest_mf_rm = gtest_mf[-Reduce(union, list(outliers(gtest_mf[,1], 0.7), outliers(gtest_mf[,2], 1), 
+                                            outliers(gtest_mf[,3], 0.001), outliers(gtest_mf[,4], 0.001))),]
> hist(gtest_mf[,1])
> hist(gtest_mf[,2])
> hist(gtest_mf[,3])
> hist(gtest_mf[,4])
> 
> hist(ergm_sim_estim_tapered[,1])
> hist(ergm_sim_estim_tapered[,2])
> hist(ergm_sim_estim_tapered[,3])
> hist(ergm_sim_estim_tapered[,4])
> 
> 
> 
> 
> 
> 
> 
> complete_mf_results = mfergm_estim[complete.cases(mfergm_estim),]
> complete_mcmc_results = ergm_sim_estim[complete.cases(ergm_sim_estim),]
> complete_tapered_results = ergm_sim_estim_tapered[complete.cases(ergm_sim_estim_tapered),]
> 
> 
> # Degeneracy
> length(intersect(which(is.na(mfergm_estim[,1])), which(is.na(ergm_sim_estim[,1]))))
[1] 0
> 
> # MFERGM RMSE
> 
> # mf
> outliers1 = outliers((complete_mf_results[,1] - theta[1])^2)
> outliers2 = outliers((complete_mf_results[,2] - theta[2])^2)
> outliers3 = outliers((complete_mf_results[,3] - theta[3])^2)
> outliers4 = outliers((complete_mf_results[,4] - theta[4])^2)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> mf_rmse1 = sqrt(sum(((complete_mf_results[,1] - theta[1])^2)[-outliers1]))
> mf_rmse2 = sqrt(sum(((complete_mf_results[,2] - theta[2])^2)[-outliers2]))
> mf_rmse3 = sqrt(sum(((complete_mf_results[,3] - theta[3])^2)[-outliers3]))
> mf_rmse4 = sqrt(sum(((complete_mf_results[,4] - theta[4])^2)[-outliers4]))
> c(mf_rmse1, mf_rmse2, mf_rmse3, mf_rmse4)
[1] 18.2435311 18.7226323  0.3826807  0.8850204
> 
> # mcmc
> outliers1 = outliers((complete_mcmc_results[,1] - theta[1])^2)
> outliers2 = outliers((complete_mcmc_results[,2] - theta[2])^2)
> outliers3 = outliers((complete_mcmc_results[,3] - theta[3])^2)
> outliers4 = outliers((complete_mcmc_results[,4] - theta[4])^2)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> mcmc_rmse1 = sqrt(sum(((complete_mcmc_results[,1] - theta[1])^2)[-outliers1]))
> mcmc_rmse2 = sqrt(sum(((complete_mcmc_results[,2] - theta[2])^2)[-outliers2]))
> mcmc_rmse3 = sqrt(sum(((complete_mcmc_results[,3] - theta[3])^2)[-outliers3]))
> mcmc_rmse4 = sqrt(sum(((complete_mcmc_results[,4] - theta[4])^2)[-outliers4]))
> c(mcmc_rmse1, mcmc_rmse2, mcmc_rmse3, mcmc_rmse4)
[1] 3.0809328 1.4715597 0.1466943 0.9442586
> 
> plot((complete_mf_results[,1] - theta[1])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,2] - theta[2])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,3] - theta[3])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot((complete_mf_results[,4] - theta[4])^2, pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,1] - theta[1])^2)[-outliers1], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,2] - theta[2])^2)[-outliers2], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,3] - theta[3])^2)[-outliers3], pch = 19, ylab = "", xlab = "Simulated Networks")
> plot(((complete_mf_results[,4] - theta[4])^2)[-outliers4], pch = 19, ylab = "", xlab = "Simulated Networks")
> 
> 
> outliers1 = head(order((complete_mf_results[,1] - theta[1])^2, decreasing = T), n = 100)
> outliers2 = head(order((complete_mf_results[,2] - theta[2])^2, decreasing = T), n = 100)
> outliers3 = head(order((complete_mf_results[,3] - theta[3])^2, decreasing = T), n = 100)
> outliers4 = head(order((complete_mf_results[,4] - theta[4])^2, decreasing = T), n = 100)
> outliers_all = intersect(intersect(intersect(outliers1, outliers2), outliers3), outliers4)
> 
> 
> plot(density(complete_mf_results[,1]), main = "")
> plot(density(complete_mf_results[,2]), main = "")
> plot(density(complete_mf_results[,3]), main = "")
> plot(density(complete_mf_results[,4]), main = "")
> 
> 
> 
> # MAD
> 
> mcmc_mad = matrix(nrow = nrow(complete_mcmc_results), ncol = 4)
> for (i in 1:nrow(complete_mcmc_results))
+ {
+   mcmc_mad[i,] = abs(complete_mcmc_results[i,] - theta)
+ }
> round(apply(mcmc_mad, 2, median), 3)
[1] 0.264 0.134 0.014 0.090
> 
> mf_mad = matrix(nrow = nrow(complete_mf_results), ncol = 4)
> for (i in 1:nrow(complete_mf_results))
+ {
+   mf_mad[i,] = abs(complete_mf_results[i,] - theta)
+ }
> round(apply(mf_mad, 2, median), 3)
[1] 0.560 0.686 0.022 0.085
> 
> stopImplicitCluster()
> 
> save.image("mfergm_params1_n1000.RData")
> 
> 
> proc.time()
   user  system elapsed 
614.446  26.706 103.923 
